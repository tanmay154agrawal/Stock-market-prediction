{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cF39m33dWwa4"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import KFold"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ticker = \"^NSEI\"\n",
        "\n",
        "# Define the date range for the historical data\n",
        "start_date = \"2014-01-01\"\n",
        "end_date = \"2018-12-31\"\n",
        "\n",
        "# Retrieve historical data using yfinance\n",
        "data = yf.download(ticker, start=start_date, end=end_date)\n",
        "\n",
        "# Print the first few rows of the dataset\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qN9BUvKvXoXA",
        "outputId": "e916caa5-1223-4a6d-f0f1-ff23464fc114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "                   Open         High          Low        Close    Adj Close  \\\n",
            "Date                                                                          \n",
            "2014-01-02  6301.250000  6358.299805  6211.299805  6221.149902  6221.149902   \n",
            "2014-01-03  6194.549805  6221.700195  6171.250000  6211.149902  6211.149902   \n",
            "2014-01-06  6220.850098  6224.700195  6170.250000  6191.450195  6191.450195   \n",
            "2014-01-07  6203.899902  6221.500000  6144.750000  6162.250000  6162.250000   \n",
            "2014-01-08  6178.049805  6192.100098  6160.350098  6174.600098  6174.600098   \n",
            "\n",
            "            Volume  \n",
            "Date                \n",
            "2014-01-02  158100  \n",
            "2014-01-03  139000  \n",
            "2014-01-06  118300  \n",
            "2014-01-07  138600  \n",
            "2014-01-08  146900  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(data.index, data['Adj Close'])\n",
        "plt.title('NIFTY 50 Adjusted Close Prices (2014-2018)')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Price')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "8C7lBrG1XtqX",
        "outputId": "9be41cee-51e6-414d-a156-a87ca35dbc82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=data.drop(['Adj Close'],axis=1)"
      ],
      "metadata": {
        "id": "gkW1MW_9XyGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = data[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
        "\n",
        "# Scale the features using Min-Max Scaler\n",
        "scaler = MinMaxScaler()\n",
        "scaled_features = scaler.fit_transform(features)\n",
        "\n"
      ],
      "metadata": {
        "id": "Px4Ytd6j078z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_oc = data[['Open', 'Close']]\n",
        "\n",
        "# Scale the features using Min-Max Scaler\n",
        "scaler_oc = MinMaxScaler()\n",
        "scaled_features_oc = scaler_oc.fit_transform(features_oc)"
      ],
      "metadata": {
        "id": "p0cRLaS90BUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_ocl = data[['Open','Low', 'Close']]\n",
        "\n",
        "# Scale the features using Min-Max Scaler\n",
        "scaler_ocl = MinMaxScaler()\n",
        "scaled_features_ocl = scaler_ocl.fit_transform(features_ocl)"
      ],
      "metadata": {
        "id": "4b5Fa0cV4uBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_oclh = data[['Open','Low','High','Close']]\n",
        "\n",
        "# Scale the features using Min-Max Scaler\n",
        "scaler_oclh = MinMaxScaler()\n",
        "scaled_features_oclh = scaler_oclh.fit_transform(features_oclh)"
      ],
      "metadata": {
        "id": "mjPJgquN7g1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features1=data['Close']\n",
        "features1=np.array(features1)\n",
        "scaler3 = MinMaxScaler()\n",
        "scaled_features3 = scaler3.fit_transform(features1.reshape(-1,1))\n",
        "\n"
      ],
      "metadata": {
        "id": "IGC_-vLvZJct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized=pd.DataFrame()"
      ],
      "metadata": {
        "id": "raLbqXtwYWVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized = data.copy()\n",
        "normalized[['Open', 'High', 'Low', 'Close', 'Volume']] = scaled_features\n"
      ],
      "metadata": {
        "id": "DLbIxEPt0u12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_oc = data.copy()\n",
        "normalized_oc[['Open', 'Close']] = scaled_features_oc"
      ],
      "metadata": {
        "id": "e9podonx0VQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_ocl = data.copy()\n",
        "normalized_ocl[['Open','Low', 'Close']] = scaled_features_ocl"
      ],
      "metadata": {
        "id": "WuTTip3o47p-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_oclh = data.copy()\n",
        "normalized_oclh[['Open','Low','High', 'Close']] = scaled_features_oclh"
      ],
      "metadata": {
        "id": "9Jtu8XsQ73ZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_oc=normalized_oc.drop(['High','Low','Volume'],axis=1)"
      ],
      "metadata": {
        "id": "nChBWwnwYtR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_ocl=normalized_ocl.drop(['High','Volume'],axis=1)"
      ],
      "metadata": {
        "id": "xhdVtO1s5Erl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_oclh=normalized_oclh.drop(['Volume'],axis=1)"
      ],
      "metadata": {
        "id": "qyRyNfY48Bbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "eSN1QlVHYw9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = train_test_split(normalized, test_size=0.2, shuffle=False)"
      ],
      "metadata": {
        "id": "RUoypi06Y8ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_oc, test_data_oc = train_test_split(normalized_oc, test_size=0.2, shuffle=False)"
      ],
      "metadata": {
        "id": "0FWYxoJ80gdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_ocl, test_data_ocl = train_test_split(normalized_ocl, test_size=0.2, shuffle=False)"
      ],
      "metadata": {
        "id": "mjA2k7nx5L-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_oclh, test_data_oclh = train_test_split(normalized_oclh, test_size=0.2, shuffle=False)"
      ],
      "metadata": {
        "id": "Sw-pOiEb8GmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import SimpleRNN, Dropout, Dense\n"
      ],
      "metadata": {
        "id": "ggRSiKmJZBTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences(data, sequence_length):\n",
        "    sequences = []\n",
        "    targets = []\n",
        "    for i in range(len(data) - sequence_length):\n",
        "        sequences.append(data[i:i+sequence_length])\n",
        "        targets.append(data[i+sequence_length][3])\n",
        "    return np.array(sequences), np.array(targets)\n"
      ],
      "metadata": {
        "id": "oujJivZAbJZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_oclh.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "IekYgEu014IH",
        "outputId": "5c25720f-6fec-4cf3-a8f9-1c46e363292f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Open      High       Low     Close\n",
              "Date                                              \n",
              "2014-01-02  0.060930  0.059296  0.048120  0.038387\n",
              "2014-01-03  0.042547  0.035508  0.041188  0.036644\n",
              "2014-01-06  0.047078  0.036030  0.041015  0.033211\n",
              "2014-01-07  0.044158  0.035473  0.036601  0.028122\n",
              "2014-01-08  0.039704  0.030353  0.039301  0.030274"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-5299ba4e-bfb2-4e81-87d8-2fbdacb7e2e7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2014-01-02</th>\n",
              "      <td>0.060930</td>\n",
              "      <td>0.059296</td>\n",
              "      <td>0.048120</td>\n",
              "      <td>0.038387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-03</th>\n",
              "      <td>0.042547</td>\n",
              "      <td>0.035508</td>\n",
              "      <td>0.041188</td>\n",
              "      <td>0.036644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-06</th>\n",
              "      <td>0.047078</td>\n",
              "      <td>0.036030</td>\n",
              "      <td>0.041015</td>\n",
              "      <td>0.033211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-07</th>\n",
              "      <td>0.044158</td>\n",
              "      <td>0.035473</td>\n",
              "      <td>0.036601</td>\n",
              "      <td>0.028122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-08</th>\n",
              "      <td>0.039704</td>\n",
              "      <td>0.030353</td>\n",
              "      <td>0.039301</td>\n",
              "      <td>0.030274</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5299ba4e-bfb2-4e81-87d8-2fbdacb7e2e7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-371e1df1-cca5-4b49-8a9f-ae9b4d72d83d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-371e1df1-cca5-4b49-8a9f-ae9b4d72d83d')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-371e1df1-cca5-4b49-8a9f-ae9b4d72d83d button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5299ba4e-bfb2-4e81-87d8-2fbdacb7e2e7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5299ba4e-bfb2-4e81-87d8-2fbdacb7e2e7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences_oc(data, sequence_length):\n",
        "    sequences = []\n",
        "    targets = []\n",
        "    for i in range(len(data) - sequence_length):\n",
        "        sequences.append(data[i:i+sequence_length])\n",
        "        targets.append(data[i+sequence_length][1])\n",
        "    return np.array(sequences), np.array(targets)"
      ],
      "metadata": {
        "id": "WzFE9I6010hM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences_ocl(data, sequence_length):\n",
        "    sequences = []\n",
        "    targets = []\n",
        "    for i in range(len(data) - sequence_length):\n",
        "        sequences.append(data[i:i+sequence_length])\n",
        "        targets.append(data[i+sequence_length][2])\n",
        "    return np.array(sequences), np.array(targets)"
      ],
      "metadata": {
        "id": "0YV5Q3F25RFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences_oclh(data, sequence_length):\n",
        "    sequences = []\n",
        "    targets = []\n",
        "    for i in range(len(data) - sequence_length):\n",
        "        sequences.append(data[i:i+sequence_length])\n",
        "        targets.append(data[i+sequence_length][3])\n",
        "    return np.array(sequences), np.array(targets)"
      ],
      "metadata": {
        "id": "FcKl-Mal8Mtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 10"
      ],
      "metadata": {
        "id": "bk9C9pUYZuJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.values.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGNqnUltcmoC",
        "outputId": "85c192f4-a045-4843-f42e-ad66d578892e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(976, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = create_sequences(train_data.values, sequence_length)\n",
        "X_test, y_test = create_sequences(test_data.values, sequence_length)"
      ],
      "metadata": {
        "id": "POnns5LxZx-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_oc, y_train_oc = create_sequences_oc(train_data_oc.values, sequence_length)\n",
        "X_test_oc, y_test_oc = create_sequences_oc(test_data_oc.values, sequence_length)"
      ],
      "metadata": {
        "id": "9FcGMMvQ0rlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_ocl, y_train_ocl = create_sequences_ocl(train_data_ocl.values, sequence_length)\n",
        "X_test_ocl, y_test_ocl = create_sequences_ocl(test_data_ocl.values, sequence_length)"
      ],
      "metadata": {
        "id": "2p3syCj15WIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_oclh, y_train_oclh = create_sequences_oclh(train_data_oclh.values, sequence_length)\n",
        "X_test_oclh, y_test_oclh = create_sequences_oclh(test_data_oclh.values, sequence_length)"
      ],
      "metadata": {
        "id": "H7oeQOy08SeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 5\n",
        "\n",
        "# Initialize k-fold cross-validation\n",
        "kf = KFold(n_splits=k)"
      ],
      "metadata": {
        "id": "uJQJFTi2ra4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(SimpleRNN(units=64, input_shape=(sequence_length, 5), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(SimpleRNN(units=64))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dense(units=1))\n"
      ],
      "metadata": {
        "id": "-rUKA8kUZ66l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_oc = Sequential()\n",
        "model_oc.add(SimpleRNN(units=64, input_shape=(sequence_length, 2), return_sequences=True))\n",
        "model_oc.add(Dropout(0.2))\n",
        "model_oc.add(SimpleRNN(units=64))\n",
        "model_oc.add(Dropout(0.2))\n",
        "model_oc.add(Dense(units=32, activation='relu'))\n",
        "model_oc.add(Dense(units=1))"
      ],
      "metadata": {
        "id": "kECoH3jb00Vs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ocl = Sequential()\n",
        "model_ocl.add(SimpleRNN(units=64, input_shape=(sequence_length, 3), return_sequences=True))\n",
        "model_ocl.add(Dropout(0.2))\n",
        "model_ocl.add(SimpleRNN(units=64))\n",
        "model_ocl.add(Dropout(0.2))\n",
        "model_ocl.add(Dense(units=32, activation='relu'))\n",
        "model_ocl.add(Dense(units=1))"
      ],
      "metadata": {
        "id": "QhKuAMvl5fjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_oclh = Sequential()\n",
        "model_oclh.add(SimpleRNN(units=64, input_shape=(sequence_length, 4), return_sequences=True))\n",
        "model_oclh.add(Dropout(0.2))\n",
        "model_oclh.add(SimpleRNN(units=64))\n",
        "model_oclh.add(Dropout(0.2))\n",
        "model_oclh.add(Dense(units=32, activation='relu'))\n",
        "model_oclh.add(Dense(units=1))"
      ],
      "metadata": {
        "id": "3p-eZ3mR8sYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mean_squared_error', optimizer='adam')"
      ],
      "metadata": {
        "id": "pddBlNBqaBjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_oc.compile(loss='mean_squared_error', optimizer='adam')"
      ],
      "metadata": {
        "id": "u7_adgKv08ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ocl.compile(loss='mean_squared_error', optimizer='adam')"
      ],
      "metadata": {
        "id": "D4uoNDPS5oW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_oclh.compile(loss='mean_squared_error', optimizer='adam')"
      ],
      "metadata": {
        "id": "Q4x0BR288zF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuodX7vEan37",
        "outputId": "aa11c7c7-7577-4a80-c261-9371f7d89ef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, 10, 64)            4480      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 10, 64)            0         \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,849\n",
            "Trainable params: 14,849\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for fold, (train_index, val_index) in enumerate(kf.split(X_train, y_train)):\n",
        "#     print(f\"Fold {fold+1}/{k}\")\n",
        "\n",
        "#     X_train1, X_val = X_train[train_index], X_train[val_index]\n",
        "#     y_train1, y_val = y_train[train_index], y_train[val_index]\n",
        "\n",
        "#     # Train the model on the training data from all the folds\n",
        "# model.fit(X_train, y_train, epochs=300, batch_size=16, validation_data=(X_test, y_test))\n",
        "\n",
        "    # # Evaluate the model on the validation set for the current fold\n",
        "    # val_loss = model.evaluate(X_val, y_val)\n",
        "    # print(\"Validation Loss:\", val_loss)\n",
        "    # print(\"-\" * 100)"
      ],
      "metadata": {
        "id": "kX781WYusTHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "kJR7uIZN-GYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
        "\n",
        "# Train the model with ModelCheckpoint callback\n",
        "history = model.fit(X_train, y_train, epochs=500, batch_size=16, validation_data=(X_test, y_test), callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWNBnseG9mCS",
        "outputId": "56cf5108-2962-4054-e7d7-ca541c3adf43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0631\n",
            "Epoch 1: val_loss improved from inf to 0.04430, saving model to best_model.h5\n",
            "61/61 [==============================] - 7s 33ms/step - loss: 0.0620 - val_loss: 0.0443\n",
            "Epoch 2/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0136\n",
            "Epoch 2: val_loss improved from 0.04430 to 0.01983, saving model to best_model.h5\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 0.0136 - val_loss: 0.0198\n",
            "Epoch 3/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0060\n",
            "Epoch 3: val_loss improved from 0.01983 to 0.01131, saving model to best_model.h5\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.0060 - val_loss: 0.0113\n",
            "Epoch 4/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0050\n",
            "Epoch 4: val_loss improved from 0.01131 to 0.00237, saving model to best_model.h5\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.0050 - val_loss: 0.0024\n",
            "Epoch 5/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0052\n",
            "Epoch 5: val_loss did not improve from 0.00237\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.0052 - val_loss: 0.0044\n",
            "Epoch 6/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0033\n",
            "Epoch 6: val_loss did not improve from 0.00237\n",
            "61/61 [==============================] - 1s 25ms/step - loss: 0.0033 - val_loss: 0.0064\n",
            "Epoch 7/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0032\n",
            "Epoch 7: val_loss did not improve from 0.00237\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.0032 - val_loss: 0.0054\n",
            "Epoch 8/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0032\n",
            "Epoch 8: val_loss did not improve from 0.00237\n",
            "61/61 [==============================] - 1s 22ms/step - loss: 0.0032 - val_loss: 0.0070\n",
            "Epoch 9/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0028\n",
            "Epoch 9: val_loss did not improve from 0.00237\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.0028 - val_loss: 0.0101\n",
            "Epoch 10/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0028\n",
            "Epoch 10: val_loss did not improve from 0.00237\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.0028 - val_loss: 0.0044\n",
            "Epoch 11/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0022\n",
            "Epoch 11: val_loss did not improve from 0.00237\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 0.0022 - val_loss: 0.0034\n",
            "Epoch 12/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0022\n",
            "Epoch 12: val_loss did not improve from 0.00237\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 0.0023 - val_loss: 0.0042\n",
            "Epoch 13/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0021\n",
            "Epoch 13: val_loss did not improve from 0.00237\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0021 - val_loss: 0.0057\n",
            "Epoch 14/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0022\n",
            "Epoch 14: val_loss did not improve from 0.00237\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0022 - val_loss: 0.0099\n",
            "Epoch 15/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0022\n",
            "Epoch 15: val_loss did not improve from 0.00237\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0022 - val_loss: 0.0058\n",
            "Epoch 16/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0019\n",
            "Epoch 16: val_loss did not improve from 0.00237\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 0.0019 - val_loss: 0.0045\n",
            "Epoch 17/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0018\n",
            "Epoch 17: val_loss did not improve from 0.00237\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 0.0018 - val_loss: 0.0059\n",
            "Epoch 18/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0019\n",
            "Epoch 18: val_loss did not improve from 0.00237\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.0019 - val_loss: 0.0057\n",
            "Epoch 19/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0017\n",
            "Epoch 19: val_loss did not improve from 0.00237\n",
            "61/61 [==============================] - 2s 25ms/step - loss: 0.0017 - val_loss: 0.0046\n",
            "Epoch 20/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0016\n",
            "Epoch 20: val_loss did not improve from 0.00237\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.0016 - val_loss: 0.0040\n",
            "Epoch 21/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0017\n",
            "Epoch 21: val_loss did not improve from 0.00237\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 0.0017 - val_loss: 0.0053\n",
            "Epoch 22/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0017\n",
            "Epoch 22: val_loss did not improve from 0.00237\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.0017 - val_loss: 0.0061\n",
            "Epoch 23/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0017\n",
            "Epoch 23: val_loss did not improve from 0.00237\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0085\n",
            "Epoch 24/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0018\n",
            "Epoch 24: val_loss did not improve from 0.00237\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0056\n",
            "Epoch 25/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.0016\n",
            "Epoch 25: val_loss improved from 0.00237 to 0.00205, saving model to best_model.h5\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.0016 - val_loss: 0.0021\n",
            "Epoch 26/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0019\n",
            "Epoch 26: val_loss did not improve from 0.00205\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0035\n",
            "Epoch 27/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0015\n",
            "Epoch 27: val_loss did not improve from 0.00205\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0065\n",
            "Epoch 28/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0013\n",
            "Epoch 28: val_loss did not improve from 0.00205\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0088\n",
            "Epoch 29/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0014\n",
            "Epoch 29: val_loss did not improve from 0.00205\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0022\n",
            "Epoch 30/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0015\n",
            "Epoch 30: val_loss did not improve from 0.00205\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0037\n",
            "Epoch 31/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0014\n",
            "Epoch 31: val_loss did not improve from 0.00205\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0037\n",
            "Epoch 32/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0013\n",
            "Epoch 32: val_loss did not improve from 0.00205\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0034\n",
            "Epoch 33/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0013\n",
            "Epoch 33: val_loss did not improve from 0.00205\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0024\n",
            "Epoch 34/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0014\n",
            "Epoch 34: val_loss did not improve from 0.00205\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0048\n",
            "Epoch 35/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0012\n",
            "Epoch 35: val_loss did not improve from 0.00205\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0066\n",
            "Epoch 36/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0013\n",
            "Epoch 36: val_loss did not improve from 0.00205\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0027\n",
            "Epoch 37/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0013\n",
            "Epoch 37: val_loss did not improve from 0.00205\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0013 - val_loss: 0.0038\n",
            "Epoch 38/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0012\n",
            "Epoch 38: val_loss did not improve from 0.00205\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 0.0012 - val_loss: 0.0022\n",
            "Epoch 39/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0014\n",
            "Epoch 39: val_loss improved from 0.00205 to 0.00205, saving model to best_model.h5\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 40/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0011\n",
            "Epoch 40: val_loss did not improve from 0.00205\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 0.0061\n",
            "Epoch 41/500\n",
            "54/61 [=========================>....] - ETA: 0s - loss: 0.0013\n",
            "Epoch 41: val_loss did not improve from 0.00205\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0062\n",
            "Epoch 42/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0011\n",
            "Epoch 42: val_loss did not improve from 0.00205\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.0012 - val_loss: 0.0026\n",
            "Epoch 43/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0012\n",
            "Epoch 43: val_loss did not improve from 0.00205\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0022\n",
            "Epoch 44/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0012\n",
            "Epoch 44: val_loss did not improve from 0.00205\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0024\n",
            "Epoch 45/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0013\n",
            "Epoch 45: val_loss did not improve from 0.00205\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0071\n",
            "Epoch 46/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0012\n",
            "Epoch 46: val_loss did not improve from 0.00205\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0047\n",
            "Epoch 47/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0012\n",
            "Epoch 47: val_loss improved from 0.00205 to 0.00161, saving model to best_model.h5\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0016\n",
            "Epoch 48/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0012\n",
            "Epoch 48: val_loss did not improve from 0.00161\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0030\n",
            "Epoch 49/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0013\n",
            "Epoch 49: val_loss did not improve from 0.00161\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0031\n",
            "Epoch 50/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.0012\n",
            "Epoch 50: val_loss did not improve from 0.00161\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0073\n",
            "Epoch 51/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0011\n",
            "Epoch 51: val_loss did not improve from 0.00161\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0025\n",
            "Epoch 52/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 9.5125e-04\n",
            "Epoch 52: val_loss did not improve from 0.00161\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 9.7237e-04 - val_loss: 0.0032\n",
            "Epoch 53/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0013\n",
            "Epoch 53: val_loss did not improve from 0.00161\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0039\n",
            "Epoch 54/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 9.8665e-04\n",
            "Epoch 54: val_loss did not improve from 0.00161\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 9.9929e-04 - val_loss: 0.0039\n",
            "Epoch 55/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0010\n",
            "Epoch 55: val_loss did not improve from 0.00161\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0016\n",
            "Epoch 56/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 9.6469e-04\n",
            "Epoch 56: val_loss did not improve from 0.00161\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 9.5688e-04 - val_loss: 0.0032\n",
            "Epoch 57/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 9.4663e-04\n",
            "Epoch 57: val_loss did not improve from 0.00161\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 9.4460e-04 - val_loss: 0.0032\n",
            "Epoch 58/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0010\n",
            "Epoch 58: val_loss did not improve from 0.00161\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 0.0010 - val_loss: 0.0029\n",
            "Epoch 59/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 9.5936e-04\n",
            "Epoch 59: val_loss did not improve from 0.00161\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 9.5936e-04 - val_loss: 0.0023\n",
            "Epoch 60/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0010\n",
            "Epoch 60: val_loss did not improve from 0.00161\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 0.0010 - val_loss: 0.0045\n",
            "Epoch 61/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 9.1986e-04\n",
            "Epoch 61: val_loss did not improve from 0.00161\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 9.4364e-04 - val_loss: 0.0017\n",
            "Epoch 62/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 8.7636e-04\n",
            "Epoch 62: val_loss did not improve from 0.00161\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 8.7260e-04 - val_loss: 0.0062\n",
            "Epoch 63/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0010\n",
            "Epoch 63: val_loss did not improve from 0.00161\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0023\n",
            "Epoch 64/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 9.7033e-04\n",
            "Epoch 64: val_loss did not improve from 0.00161\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 9.5966e-04 - val_loss: 0.0055\n",
            "Epoch 65/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 8.7681e-04\n",
            "Epoch 65: val_loss did not improve from 0.00161\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 8.7147e-04 - val_loss: 0.0024\n",
            "Epoch 66/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 8.7736e-04\n",
            "Epoch 66: val_loss did not improve from 0.00161\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 8.7549e-04 - val_loss: 0.0036\n",
            "Epoch 67/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 8.8860e-04\n",
            "Epoch 67: val_loss did not improve from 0.00161\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 9.0354e-04 - val_loss: 0.0026\n",
            "Epoch 68/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 9.8186e-04\n",
            "Epoch 68: val_loss did not improve from 0.00161\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 9.7479e-04 - val_loss: 0.0027\n",
            "Epoch 69/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0010\n",
            "Epoch 69: val_loss did not improve from 0.00161\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0020\n",
            "Epoch 70/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 8.5607e-04\n",
            "Epoch 70: val_loss did not improve from 0.00161\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 8.7683e-04 - val_loss: 0.0041\n",
            "Epoch 71/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 9.4913e-04\n",
            "Epoch 71: val_loss did not improve from 0.00161\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 9.4583e-04 - val_loss: 0.0018\n",
            "Epoch 72/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0010    \n",
            "Epoch 72: val_loss did not improve from 0.00161\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 9.9839e-04 - val_loss: 0.0032\n",
            "Epoch 73/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 7.9692e-04\n",
            "Epoch 73: val_loss did not improve from 0.00161\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 7.9500e-04 - val_loss: 0.0060\n",
            "Epoch 74/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 9.2455e-04\n",
            "Epoch 74: val_loss did not improve from 0.00161\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 9.5247e-04 - val_loss: 0.0086\n",
            "Epoch 75/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0011\n",
            "Epoch 75: val_loss did not improve from 0.00161\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0051\n",
            "Epoch 76/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 8.9336e-04\n",
            "Epoch 76: val_loss did not improve from 0.00161\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 8.8881e-04 - val_loss: 0.0050\n",
            "Epoch 77/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 8.5087e-04\n",
            "Epoch 77: val_loss did not improve from 0.00161\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 8.3599e-04 - val_loss: 0.0037\n",
            "Epoch 78/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 8.1508e-04\n",
            "Epoch 78: val_loss did not improve from 0.00161\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 8.1722e-04 - val_loss: 0.0031\n",
            "Epoch 79/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 7.9241e-04\n",
            "Epoch 79: val_loss improved from 0.00161 to 0.00150, saving model to best_model.h5\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 7.9305e-04 - val_loss: 0.0015\n",
            "Epoch 80/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 8.9179e-04\n",
            "Epoch 80: val_loss did not improve from 0.00150\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 8.8397e-04 - val_loss: 0.0044\n",
            "Epoch 81/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 7.5607e-04\n",
            "Epoch 81: val_loss improved from 0.00150 to 0.00142, saving model to best_model.h5\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 7.5607e-04 - val_loss: 0.0014\n",
            "Epoch 82/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 9.0727e-04\n",
            "Epoch 82: val_loss did not improve from 0.00142\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 8.9953e-04 - val_loss: 0.0039\n",
            "Epoch 83/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 7.4208e-04\n",
            "Epoch 83: val_loss did not improve from 0.00142\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 7.6000e-04 - val_loss: 0.0040\n",
            "Epoch 84/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 8.8445e-04\n",
            "Epoch 84: val_loss did not improve from 0.00142\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 8.7026e-04 - val_loss: 0.0050\n",
            "Epoch 85/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 7.3069e-04\n",
            "Epoch 85: val_loss did not improve from 0.00142\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 7.2143e-04 - val_loss: 0.0014\n",
            "Epoch 86/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 7.4596e-04\n",
            "Epoch 86: val_loss did not improve from 0.00142\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 7.4763e-04 - val_loss: 0.0042\n",
            "Epoch 87/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 7.5235e-04\n",
            "Epoch 87: val_loss did not improve from 0.00142\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 7.9551e-04 - val_loss: 0.0025\n",
            "Epoch 88/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.0012\n",
            "Epoch 88: val_loss did not improve from 0.00142\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0065\n",
            "Epoch 89/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 7.8858e-04\n",
            "Epoch 89: val_loss did not improve from 0.00142\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 8.0205e-04 - val_loss: 0.0041\n",
            "Epoch 90/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 6.8127e-04\n",
            "Epoch 90: val_loss did not improve from 0.00142\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 7.2082e-04 - val_loss: 0.0046\n",
            "Epoch 91/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 8.4072e-04\n",
            "Epoch 91: val_loss did not improve from 0.00142\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 8.5516e-04 - val_loss: 0.0061\n",
            "Epoch 92/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 7.0278e-04\n",
            "Epoch 92: val_loss did not improve from 0.00142\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 7.0278e-04 - val_loss: 0.0052\n",
            "Epoch 93/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 8.7856e-04\n",
            "Epoch 93: val_loss did not improve from 0.00142\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 8.7770e-04 - val_loss: 0.0045\n",
            "Epoch 94/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 7.1100e-04\n",
            "Epoch 94: val_loss did not improve from 0.00142\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 7.0014e-04 - val_loss: 0.0033\n",
            "Epoch 95/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 7.4881e-04\n",
            "Epoch 95: val_loss did not improve from 0.00142\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 7.3381e-04 - val_loss: 0.0027\n",
            "Epoch 96/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 6.4786e-04\n",
            "Epoch 96: val_loss did not improve from 0.00142\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 6.4250e-04 - val_loss: 0.0042\n",
            "Epoch 97/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 6.8130e-04\n",
            "Epoch 97: val_loss did not improve from 0.00142\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 6.8576e-04 - val_loss: 0.0038\n",
            "Epoch 98/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 6.7439e-04\n",
            "Epoch 98: val_loss did not improve from 0.00142\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 6.6929e-04 - val_loss: 0.0023\n",
            "Epoch 99/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 6.6887e-04\n",
            "Epoch 99: val_loss improved from 0.00142 to 0.00120, saving model to best_model.h5\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 6.8494e-04 - val_loss: 0.0012\n",
            "Epoch 100/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 7.6708e-04\n",
            "Epoch 100: val_loss did not improve from 0.00120\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 7.6318e-04 - val_loss: 0.0019\n",
            "Epoch 101/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 7.6132e-04\n",
            "Epoch 101: val_loss did not improve from 0.00120\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 7.5917e-04 - val_loss: 0.0022\n",
            "Epoch 102/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 7.7249e-04\n",
            "Epoch 102: val_loss did not improve from 0.00120\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 7.7563e-04 - val_loss: 0.0036\n",
            "Epoch 103/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 7.3778e-04\n",
            "Epoch 103: val_loss did not improve from 0.00120\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 7.3778e-04 - val_loss: 0.0028\n",
            "Epoch 104/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 6.6978e-04\n",
            "Epoch 104: val_loss did not improve from 0.00120\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 6.6978e-04 - val_loss: 0.0049\n",
            "Epoch 105/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 7.6824e-04\n",
            "Epoch 105: val_loss did not improve from 0.00120\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 7.7286e-04 - val_loss: 0.0045\n",
            "Epoch 106/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 8.5783e-04\n",
            "Epoch 106: val_loss did not improve from 0.00120\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 8.5783e-04 - val_loss: 0.0068\n",
            "Epoch 107/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0010\n",
            "Epoch 107: val_loss did not improve from 0.00120\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0038\n",
            "Epoch 108/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 8.7701e-04\n",
            "Epoch 108: val_loss did not improve from 0.00120\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 8.9181e-04 - val_loss: 0.0046\n",
            "Epoch 109/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 8.1164e-04\n",
            "Epoch 109: val_loss did not improve from 0.00120\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 8.1164e-04 - val_loss: 0.0030\n",
            "Epoch 110/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 7.3804e-04\n",
            "Epoch 110: val_loss did not improve from 0.00120\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 7.3804e-04 - val_loss: 0.0022\n",
            "Epoch 111/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 6.8082e-04\n",
            "Epoch 111: val_loss did not improve from 0.00120\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 6.7467e-04 - val_loss: 0.0046\n",
            "Epoch 112/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 6.6734e-04\n",
            "Epoch 112: val_loss did not improve from 0.00120\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 6.5506e-04 - val_loss: 0.0026\n",
            "Epoch 113/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 7.5071e-04\n",
            "Epoch 113: val_loss did not improve from 0.00120\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 7.8606e-04 - val_loss: 0.0022\n",
            "Epoch 114/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 6.8164e-04\n",
            "Epoch 114: val_loss did not improve from 0.00120\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 6.7588e-04 - val_loss: 0.0043\n",
            "Epoch 115/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 5.6936e-04\n",
            "Epoch 115: val_loss did not improve from 0.00120\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 5.6904e-04 - val_loss: 0.0017\n",
            "Epoch 116/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 5.8021e-04\n",
            "Epoch 116: val_loss did not improve from 0.00120\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 5.7758e-04 - val_loss: 0.0028\n",
            "Epoch 117/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 5.9399e-04\n",
            "Epoch 117: val_loss did not improve from 0.00120\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 6.0830e-04 - val_loss: 0.0058\n",
            "Epoch 118/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 5.7337e-04\n",
            "Epoch 118: val_loss did not improve from 0.00120\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 5.7185e-04 - val_loss: 0.0039\n",
            "Epoch 119/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 5.5255e-04\n",
            "Epoch 119: val_loss did not improve from 0.00120\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 5.4483e-04 - val_loss: 0.0046\n",
            "Epoch 120/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 6.5566e-04\n",
            "Epoch 120: val_loss did not improve from 0.00120\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 6.5439e-04 - val_loss: 0.0019\n",
            "Epoch 121/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 7.1503e-04\n",
            "Epoch 121: val_loss improved from 0.00120 to 0.00103, saving model to best_model.h5\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 6.9722e-04 - val_loss: 0.0010\n",
            "Epoch 122/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 7.7377e-04\n",
            "Epoch 122: val_loss did not improve from 0.00103\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 7.6996e-04 - val_loss: 0.0014\n",
            "Epoch 123/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 6.7858e-04\n",
            "Epoch 123: val_loss did not improve from 0.00103\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 6.7715e-04 - val_loss: 0.0020\n",
            "Epoch 124/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 6.1832e-04\n",
            "Epoch 124: val_loss did not improve from 0.00103\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 6.1802e-04 - val_loss: 0.0014\n",
            "Epoch 125/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 6.8652e-04\n",
            "Epoch 125: val_loss did not improve from 0.00103\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 6.8652e-04 - val_loss: 0.0017\n",
            "Epoch 126/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 5.2112e-04\n",
            "Epoch 126: val_loss did not improve from 0.00103\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 5.2899e-04 - val_loss: 0.0033\n",
            "Epoch 127/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 6.3933e-04\n",
            "Epoch 127: val_loss did not improve from 0.00103\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 6.3933e-04 - val_loss: 0.0024\n",
            "Epoch 128/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 6.8653e-04\n",
            "Epoch 128: val_loss did not improve from 0.00103\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 6.8653e-04 - val_loss: 0.0030\n",
            "Epoch 129/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 7.1443e-04\n",
            "Epoch 129: val_loss did not improve from 0.00103\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 7.1156e-04 - val_loss: 0.0013\n",
            "Epoch 130/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 6.3449e-04\n",
            "Epoch 130: val_loss improved from 0.00103 to 0.00084, saving model to best_model.h5\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 6.3312e-04 - val_loss: 8.4162e-04\n",
            "Epoch 131/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 6.9514e-04\n",
            "Epoch 131: val_loss did not improve from 0.00084\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 6.9460e-04 - val_loss: 0.0014\n",
            "Epoch 132/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 5.8603e-04\n",
            "Epoch 132: val_loss did not improve from 0.00084\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 5.8603e-04 - val_loss: 0.0012\n",
            "Epoch 133/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 6.1549e-04\n",
            "Epoch 133: val_loss did not improve from 0.00084\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 6.0232e-04 - val_loss: 0.0018\n",
            "Epoch 134/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 5.7822e-04\n",
            "Epoch 134: val_loss did not improve from 0.00084\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 5.7822e-04 - val_loss: 0.0026\n",
            "Epoch 135/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 6.8828e-04\n",
            "Epoch 135: val_loss did not improve from 0.00084\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 6.7878e-04 - val_loss: 0.0011\n",
            "Epoch 136/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 5.9473e-04\n",
            "Epoch 136: val_loss did not improve from 0.00084\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 5.8260e-04 - val_loss: 0.0039\n",
            "Epoch 137/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 6.0893e-04\n",
            "Epoch 137: val_loss did not improve from 0.00084\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 6.1650e-04 - val_loss: 0.0033\n",
            "Epoch 138/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 6.3901e-04\n",
            "Epoch 138: val_loss did not improve from 0.00084\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 6.3345e-04 - val_loss: 0.0023\n",
            "Epoch 139/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 6.7244e-04\n",
            "Epoch 139: val_loss did not improve from 0.00084\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 6.7059e-04 - val_loss: 0.0019\n",
            "Epoch 140/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 5.2012e-04\n",
            "Epoch 140: val_loss did not improve from 0.00084\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 5.2437e-04 - val_loss: 0.0048\n",
            "Epoch 141/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 6.3251e-04\n",
            "Epoch 141: val_loss did not improve from 0.00084\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 6.1530e-04 - val_loss: 0.0013\n",
            "Epoch 142/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 5.9738e-04\n",
            "Epoch 142: val_loss did not improve from 0.00084\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 6.0066e-04 - val_loss: 0.0038\n",
            "Epoch 143/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 5.2997e-04\n",
            "Epoch 143: val_loss did not improve from 0.00084\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 5.2997e-04 - val_loss: 0.0013\n",
            "Epoch 144/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 5.2354e-04\n",
            "Epoch 144: val_loss did not improve from 0.00084\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 5.2141e-04 - val_loss: 0.0014\n",
            "Epoch 145/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 5.4805e-04\n",
            "Epoch 145: val_loss did not improve from 0.00084\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 5.4805e-04 - val_loss: 0.0025\n",
            "Epoch 146/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 5.6922e-04\n",
            "Epoch 146: val_loss did not improve from 0.00084\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 5.7251e-04 - val_loss: 0.0013\n",
            "Epoch 147/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 6.0006e-04\n",
            "Epoch 147: val_loss did not improve from 0.00084\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 6.0629e-04 - val_loss: 0.0042\n",
            "Epoch 148/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 6.3924e-04\n",
            "Epoch 148: val_loss did not improve from 0.00084\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 6.5299e-04 - val_loss: 0.0057\n",
            "Epoch 149/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 5.9896e-04\n",
            "Epoch 149: val_loss improved from 0.00084 to 0.00073, saving model to best_model.h5\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 5.9712e-04 - val_loss: 7.3084e-04\n",
            "Epoch 150/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 6.4488e-04\n",
            "Epoch 150: val_loss did not improve from 0.00073\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 6.3771e-04 - val_loss: 0.0013\n",
            "Epoch 151/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 5.6187e-04\n",
            "Epoch 151: val_loss did not improve from 0.00073\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 5.6187e-04 - val_loss: 0.0021\n",
            "Epoch 152/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 5.7877e-04\n",
            "Epoch 152: val_loss did not improve from 0.00073\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 5.7742e-04 - val_loss: 0.0015\n",
            "Epoch 153/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 5.8759e-04\n",
            "Epoch 153: val_loss did not improve from 0.00073\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 5.8759e-04 - val_loss: 0.0020\n",
            "Epoch 154/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 6.2794e-04\n",
            "Epoch 154: val_loss did not improve from 0.00073\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 6.1353e-04 - val_loss: 0.0013\n",
            "Epoch 155/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 5.5608e-04\n",
            "Epoch 155: val_loss did not improve from 0.00073\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 5.5617e-04 - val_loss: 0.0016\n",
            "Epoch 156/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 5.1850e-04\n",
            "Epoch 156: val_loss did not improve from 0.00073\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 5.1850e-04 - val_loss: 0.0021\n",
            "Epoch 157/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.9037e-04\n",
            "Epoch 157: val_loss did not improve from 0.00073\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.8485e-04 - val_loss: 0.0012\n",
            "Epoch 158/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.9449e-04\n",
            "Epoch 158: val_loss did not improve from 0.00073\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.9449e-04 - val_loss: 9.6720e-04\n",
            "Epoch 159/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 5.0776e-04\n",
            "Epoch 159: val_loss did not improve from 0.00073\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 5.3309e-04 - val_loss: 0.0031\n",
            "Epoch 160/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 5.4493e-04\n",
            "Epoch 160: val_loss did not improve from 0.00073\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 5.4493e-04 - val_loss: 0.0038\n",
            "Epoch 161/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 5.2195e-04\n",
            "Epoch 161: val_loss did not improve from 0.00073\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 5.2471e-04 - val_loss: 7.9071e-04\n",
            "Epoch 162/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 4.9773e-04\n",
            "Epoch 162: val_loss did not improve from 0.00073\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.9306e-04 - val_loss: 0.0022\n",
            "Epoch 163/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 5.2382e-04\n",
            "Epoch 163: val_loss did not improve from 0.00073\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 5.3100e-04 - val_loss: 0.0015\n",
            "Epoch 164/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 4.3317e-04\n",
            "Epoch 164: val_loss did not improve from 0.00073\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.2598e-04 - val_loss: 9.9230e-04\n",
            "Epoch 165/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 5.0116e-04\n",
            "Epoch 165: val_loss did not improve from 0.00073\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 5.0720e-04 - val_loss: 0.0030\n",
            "Epoch 166/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.3665e-04\n",
            "Epoch 166: val_loss did not improve from 0.00073\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.3552e-04 - val_loss: 0.0029\n",
            "Epoch 167/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.6002e-04\n",
            "Epoch 167: val_loss did not improve from 0.00073\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 4.6002e-04 - val_loss: 0.0038\n",
            "Epoch 168/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 5.3313e-04\n",
            "Epoch 168: val_loss did not improve from 0.00073\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 5.3313e-04 - val_loss: 0.0015\n",
            "Epoch 169/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 4.9295e-04\n",
            "Epoch 169: val_loss did not improve from 0.00073\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.8183e-04 - val_loss: 0.0034\n",
            "Epoch 170/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.7291e-04\n",
            "Epoch 170: val_loss did not improve from 0.00073\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.7558e-04 - val_loss: 0.0012\n",
            "Epoch 171/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.2520e-04\n",
            "Epoch 171: val_loss did not improve from 0.00073\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.2939e-04 - val_loss: 0.0023\n",
            "Epoch 172/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.3449e-04\n",
            "Epoch 172: val_loss did not improve from 0.00073\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.3466e-04 - val_loss: 0.0012\n",
            "Epoch 173/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.4279e-04\n",
            "Epoch 173: val_loss did not improve from 0.00073\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.4279e-04 - val_loss: 0.0015\n",
            "Epoch 174/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 7.0647e-04\n",
            "Epoch 174: val_loss did not improve from 0.00073\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 7.1586e-04 - val_loss: 8.1318e-04\n",
            "Epoch 175/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 5.7709e-04\n",
            "Epoch 175: val_loss improved from 0.00073 to 0.00071, saving model to best_model.h5\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 5.8287e-04 - val_loss: 7.0864e-04\n",
            "Epoch 176/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 5.6315e-04\n",
            "Epoch 176: val_loss did not improve from 0.00071\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 5.6067e-04 - val_loss: 0.0020\n",
            "Epoch 177/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.8346e-04\n",
            "Epoch 177: val_loss did not improve from 0.00071\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.8346e-04 - val_loss: 0.0026\n",
            "Epoch 178/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.4103e-04\n",
            "Epoch 178: val_loss did not improve from 0.00071\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.4081e-04 - val_loss: 7.9124e-04\n",
            "Epoch 179/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.9060e-04\n",
            "Epoch 179: val_loss did not improve from 0.00071\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.9060e-04 - val_loss: 0.0030\n",
            "Epoch 180/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 5.2820e-04\n",
            "Epoch 180: val_loss did not improve from 0.00071\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 5.3328e-04 - val_loss: 0.0048\n",
            "Epoch 181/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.9164e-04\n",
            "Epoch 181: val_loss did not improve from 0.00071\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.9613e-04 - val_loss: 0.0017\n",
            "Epoch 182/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.5911e-04\n",
            "Epoch 182: val_loss improved from 0.00071 to 0.00060, saving model to best_model.h5\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.5891e-04 - val_loss: 5.9986e-04\n",
            "Epoch 183/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.8472e-04\n",
            "Epoch 183: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.8472e-04 - val_loss: 9.2193e-04\n",
            "Epoch 184/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.7799e-04\n",
            "Epoch 184: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.7787e-04 - val_loss: 0.0054\n",
            "Epoch 185/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.6986e-04\n",
            "Epoch 185: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 4.7586e-04 - val_loss: 0.0014\n",
            "Epoch 186/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.4952e-04\n",
            "Epoch 186: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 4.5347e-04 - val_loss: 0.0016\n",
            "Epoch 187/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0011\n",
            "Epoch 187: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 0.0011 - val_loss: 0.0059\n",
            "Epoch 188/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0013\n",
            "Epoch 188: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.0013 - val_loss: 0.0067\n",
            "Epoch 189/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 7.0472e-04\n",
            "Epoch 189: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 6.9901e-04 - val_loss: 7.4138e-04\n",
            "Epoch 190/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 5.5315e-04\n",
            "Epoch 190: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 5.5530e-04 - val_loss: 0.0023\n",
            "Epoch 191/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 5.4540e-04\n",
            "Epoch 191: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 5.3898e-04 - val_loss: 0.0012\n",
            "Epoch 192/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.6266e-04\n",
            "Epoch 192: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.5686e-04 - val_loss: 0.0025\n",
            "Epoch 193/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.9873e-04\n",
            "Epoch 193: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.9873e-04 - val_loss: 0.0015\n",
            "Epoch 194/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 5.6302e-04\n",
            "Epoch 194: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 5.6674e-04 - val_loss: 0.0045\n",
            "Epoch 195/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 6.3192e-04\n",
            "Epoch 195: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 6.2637e-04 - val_loss: 0.0049\n",
            "Epoch 196/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 5.0092e-04\n",
            "Epoch 196: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.9627e-04 - val_loss: 0.0014\n",
            "Epoch 197/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.6700e-04\n",
            "Epoch 197: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.6448e-04 - val_loss: 0.0020\n",
            "Epoch 198/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.4522e-04\n",
            "Epoch 198: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.4615e-04 - val_loss: 0.0017\n",
            "Epoch 199/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 4.2491e-04\n",
            "Epoch 199: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.1583e-04 - val_loss: 0.0017\n",
            "Epoch 200/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.1415e-04\n",
            "Epoch 200: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.1636e-04 - val_loss: 0.0030\n",
            "Epoch 201/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.2763e-04\n",
            "Epoch 201: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.2797e-04 - val_loss: 0.0021\n",
            "Epoch 202/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.9327e-04\n",
            "Epoch 202: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.8952e-04 - val_loss: 0.0021\n",
            "Epoch 203/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 5.4246e-04\n",
            "Epoch 203: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 5.4820e-04 - val_loss: 0.0021\n",
            "Epoch 204/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.0632e-04\n",
            "Epoch 204: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.0404e-04 - val_loss: 0.0015\n",
            "Epoch 205/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.9449e-04\n",
            "Epoch 205: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.9419e-04 - val_loss: 0.0033\n",
            "Epoch 206/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.0261e-04\n",
            "Epoch 206: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 4.0490e-04 - val_loss: 0.0024\n",
            "Epoch 207/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.9793e-04\n",
            "Epoch 207: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.9929e-04 - val_loss: 0.0012\n",
            "Epoch 208/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.5287e-04\n",
            "Epoch 208: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.5045e-04 - val_loss: 0.0030\n",
            "Epoch 209/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.2268e-04\n",
            "Epoch 209: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.2366e-04 - val_loss: 0.0023\n",
            "Epoch 210/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.2556e-04\n",
            "Epoch 210: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.2959e-04 - val_loss: 6.3467e-04\n",
            "Epoch 211/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.9757e-04\n",
            "Epoch 211: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.9983e-04 - val_loss: 6.4010e-04\n",
            "Epoch 212/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.4963e-04\n",
            "Epoch 212: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 4.5030e-04 - val_loss: 6.5753e-04\n",
            "Epoch 213/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.9834e-04\n",
            "Epoch 213: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.9235e-04 - val_loss: 0.0035\n",
            "Epoch 214/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.1133e-04\n",
            "Epoch 214: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.1932e-04 - val_loss: 0.0022\n",
            "Epoch 215/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.1723e-04\n",
            "Epoch 215: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.1639e-04 - val_loss: 0.0045\n",
            "Epoch 216/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.7960e-04\n",
            "Epoch 216: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7781e-04 - val_loss: 0.0020\n",
            "Epoch 217/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.2494e-04\n",
            "Epoch 217: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.1759e-04 - val_loss: 0.0019\n",
            "Epoch 218/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.2748e-04\n",
            "Epoch 218: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.1565e-04 - val_loss: 0.0017\n",
            "Epoch 219/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.0839e-04\n",
            "Epoch 219: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.1393e-04 - val_loss: 0.0040\n",
            "Epoch 220/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.0567e-04\n",
            "Epoch 220: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.0247e-04 - val_loss: 0.0037\n",
            "Epoch 221/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.4812e-04\n",
            "Epoch 221: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.4812e-04 - val_loss: 0.0038\n",
            "Epoch 222/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.1788e-04\n",
            "Epoch 222: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.1633e-04 - val_loss: 0.0019\n",
            "Epoch 223/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 5.8926e-04\n",
            "Epoch 223: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 5.8940e-04 - val_loss: 0.0024\n",
            "Epoch 224/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.4293e-04\n",
            "Epoch 224: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.4130e-04 - val_loss: 0.0017\n",
            "Epoch 225/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.9518e-04\n",
            "Epoch 225: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.9524e-04 - val_loss: 0.0032\n",
            "Epoch 226/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.6656e-04\n",
            "Epoch 226: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.6656e-04 - val_loss: 0.0018\n",
            "Epoch 227/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.9430e-04\n",
            "Epoch 227: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.9486e-04 - val_loss: 7.1171e-04\n",
            "Epoch 228/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.7190e-04\n",
            "Epoch 228: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.7259e-04 - val_loss: 0.0023\n",
            "Epoch 229/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.0812e-04\n",
            "Epoch 229: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.0812e-04 - val_loss: 0.0017\n",
            "Epoch 230/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.9332e-04\n",
            "Epoch 230: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.9332e-04 - val_loss: 0.0027\n",
            "Epoch 231/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.3546e-04\n",
            "Epoch 231: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 4.3507e-04 - val_loss: 0.0023\n",
            "Epoch 232/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 5.1442e-04\n",
            "Epoch 232: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 5.0663e-04 - val_loss: 0.0052\n",
            "Epoch 233/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.8130e-04\n",
            "Epoch 233: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.8130e-04 - val_loss: 0.0034\n",
            "Epoch 234/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.7300e-04\n",
            "Epoch 234: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7401e-04 - val_loss: 0.0032\n",
            "Epoch 235/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 5.0808e-04\n",
            "Epoch 235: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 5.1759e-04 - val_loss: 0.0037\n",
            "Epoch 236/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.5363e-04\n",
            "Epoch 236: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.5473e-04 - val_loss: 0.0014\n",
            "Epoch 237/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 4.2884e-04\n",
            "Epoch 237: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.3475e-04 - val_loss: 9.3146e-04\n",
            "Epoch 238/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.5791e-04\n",
            "Epoch 238: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.5791e-04 - val_loss: 0.0066\n",
            "Epoch 239/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.3567e-04\n",
            "Epoch 239: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.3528e-04 - val_loss: 0.0018\n",
            "Epoch 240/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.4345e-04\n",
            "Epoch 240: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.4345e-04 - val_loss: 0.0020\n",
            "Epoch 241/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.4789e-04\n",
            "Epoch 241: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.4539e-04 - val_loss: 0.0020\n",
            "Epoch 242/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.9315e-04\n",
            "Epoch 242: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9291e-04 - val_loss: 0.0025\n",
            "Epoch 243/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.6543e-04\n",
            "Epoch 243: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.6648e-04 - val_loss: 0.0015\n",
            "Epoch 244/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.8882e-04\n",
            "Epoch 244: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8872e-04 - val_loss: 9.8805e-04\n",
            "Epoch 245/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.3608e-04\n",
            "Epoch 245: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.4295e-04 - val_loss: 0.0013\n",
            "Epoch 246/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 5.3179e-04\n",
            "Epoch 246: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 5.2597e-04 - val_loss: 0.0023\n",
            "Epoch 247/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.3509e-04\n",
            "Epoch 247: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 4.3509e-04 - val_loss: 0.0026\n",
            "Epoch 248/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.4270e-04\n",
            "Epoch 248: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.3921e-04 - val_loss: 0.0031\n",
            "Epoch 249/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.0759e-04\n",
            "Epoch 249: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.1588e-04 - val_loss: 0.0022\n",
            "Epoch 250/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.8524e-04\n",
            "Epoch 250: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7869e-04 - val_loss: 0.0018\n",
            "Epoch 251/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6001e-04\n",
            "Epoch 251: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6005e-04 - val_loss: 0.0012\n",
            "Epoch 252/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.5382e-04\n",
            "Epoch 252: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.4583e-04 - val_loss: 0.0039\n",
            "Epoch 253/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.0669e-04\n",
            "Epoch 253: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.0234e-04 - val_loss: 0.0030\n",
            "Epoch 254/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.9230e-04\n",
            "Epoch 254: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.9230e-04 - val_loss: 9.1965e-04\n",
            "Epoch 255/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.8857e-04\n",
            "Epoch 255: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.8976e-04 - val_loss: 0.0017\n",
            "Epoch 256/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.2771e-04\n",
            "Epoch 256: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.2884e-04 - val_loss: 0.0028\n",
            "Epoch 257/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.2597e-04\n",
            "Epoch 257: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.2649e-04 - val_loss: 0.0038\n",
            "Epoch 258/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.7420e-04\n",
            "Epoch 258: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7543e-04 - val_loss: 0.0042\n",
            "Epoch 259/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.0771e-04\n",
            "Epoch 259: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.0793e-04 - val_loss: 0.0033\n",
            "Epoch 260/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.4220e-04\n",
            "Epoch 260: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.4150e-04 - val_loss: 0.0013\n",
            "Epoch 261/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.4905e-04\n",
            "Epoch 261: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4957e-04 - val_loss: 0.0012\n",
            "Epoch 262/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.5638e-04\n",
            "Epoch 262: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.5589e-04 - val_loss: 0.0023\n",
            "Epoch 263/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.0762e-04\n",
            "Epoch 263: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.0778e-04 - val_loss: 0.0032\n",
            "Epoch 264/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 5.8722e-04\n",
            "Epoch 264: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 5.7853e-04 - val_loss: 0.0026\n",
            "Epoch 265/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6774e-04\n",
            "Epoch 265: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.7189e-04 - val_loss: 7.3838e-04\n",
            "Epoch 266/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.1236e-04\n",
            "Epoch 266: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 4.1266e-04 - val_loss: 0.0043\n",
            "Epoch 267/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.4690e-04\n",
            "Epoch 267: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 4.4690e-04 - val_loss: 0.0014\n",
            "Epoch 268/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.6090e-04\n",
            "Epoch 268: val_loss improved from 0.00060 to 0.00053, saving model to best_model.h5\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 4.6455e-04 - val_loss: 5.3374e-04\n",
            "Epoch 269/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.1492e-04\n",
            "Epoch 269: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.1500e-04 - val_loss: 0.0021\n",
            "Epoch 270/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.8301e-04\n",
            "Epoch 270: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.7970e-04 - val_loss: 0.0027\n",
            "Epoch 271/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.0688e-04\n",
            "Epoch 271: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.2041e-04 - val_loss: 0.0029\n",
            "Epoch 272/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.9190e-04\n",
            "Epoch 272: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9247e-04 - val_loss: 0.0052\n",
            "Epoch 273/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.8583e-04\n",
            "Epoch 273: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.8461e-04 - val_loss: 0.0017\n",
            "Epoch 274/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.6906e-04\n",
            "Epoch 274: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.7083e-04 - val_loss: 0.0013\n",
            "Epoch 275/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.2525e-04\n",
            "Epoch 275: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.2266e-04 - val_loss: 0.0019\n",
            "Epoch 276/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.9834e-04\n",
            "Epoch 276: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9834e-04 - val_loss: 0.0015\n",
            "Epoch 277/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.8973e-04\n",
            "Epoch 277: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9122e-04 - val_loss: 0.0012\n",
            "Epoch 278/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6650e-04\n",
            "Epoch 278: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6241e-04 - val_loss: 0.0021\n",
            "Epoch 279/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.2167e-04\n",
            "Epoch 279: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.2167e-04 - val_loss: 0.0038\n",
            "Epoch 280/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.2418e-04\n",
            "Epoch 280: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.1995e-04 - val_loss: 9.6256e-04\n",
            "Epoch 281/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.2990e-04\n",
            "Epoch 281: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.2524e-04 - val_loss: 0.0019\n",
            "Epoch 282/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.9069e-04\n",
            "Epoch 282: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.8910e-04 - val_loss: 0.0017\n",
            "Epoch 283/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.5628e-04\n",
            "Epoch 283: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.5628e-04 - val_loss: 0.0018\n",
            "Epoch 284/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.1547e-04\n",
            "Epoch 284: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 4.1547e-04 - val_loss: 0.0038\n",
            "Epoch 285/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.8304e-04\n",
            "Epoch 285: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.9310e-04 - val_loss: 0.0028\n",
            "Epoch 286/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.7359e-04\n",
            "Epoch 286: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.7458e-04 - val_loss: 0.0017\n",
            "Epoch 287/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.3499e-04\n",
            "Epoch 287: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.4317e-04 - val_loss: 0.0022\n",
            "Epoch 288/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.1330e-04\n",
            "Epoch 288: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 4.0727e-04 - val_loss: 0.0041\n",
            "Epoch 289/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.6234e-04\n",
            "Epoch 289: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7807e-04 - val_loss: 0.0011\n",
            "Epoch 290/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.9501e-04\n",
            "Epoch 290: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9501e-04 - val_loss: 0.0027\n",
            "Epoch 291/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.7598e-04\n",
            "Epoch 291: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7468e-04 - val_loss: 0.0011\n",
            "Epoch 292/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.7420e-04\n",
            "Epoch 292: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.6509e-04 - val_loss: 0.0013\n",
            "Epoch 293/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.5869e-04\n",
            "Epoch 293: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7151e-04 - val_loss: 9.5837e-04\n",
            "Epoch 294/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.0898e-04\n",
            "Epoch 294: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.0476e-04 - val_loss: 0.0027\n",
            "Epoch 295/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.2134e-04\n",
            "Epoch 295: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.2633e-04 - val_loss: 0.0046\n",
            "Epoch 296/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.1592e-04\n",
            "Epoch 296: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.2170e-04 - val_loss: 0.0017\n",
            "Epoch 297/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.8554e-04\n",
            "Epoch 297: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7989e-04 - val_loss: 0.0023\n",
            "Epoch 298/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.2544e-04\n",
            "Epoch 298: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.1182e-04 - val_loss: 0.0030\n",
            "Epoch 299/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.5978e-04\n",
            "Epoch 299: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5728e-04 - val_loss: 9.4836e-04\n",
            "Epoch 300/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.5684e-04\n",
            "Epoch 300: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6024e-04 - val_loss: 0.0027\n",
            "Epoch 301/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.8760e-04\n",
            "Epoch 301: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.8395e-04 - val_loss: 0.0030\n",
            "Epoch 302/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.8528e-04\n",
            "Epoch 302: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.8688e-04 - val_loss: 8.0290e-04\n",
            "Epoch 303/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.9224e-04\n",
            "Epoch 303: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9175e-04 - val_loss: 0.0029\n",
            "Epoch 304/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.6208e-04\n",
            "Epoch 304: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6208e-04 - val_loss: 0.0016\n",
            "Epoch 305/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.8858e-04\n",
            "Epoch 305: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8858e-04 - val_loss: 0.0023\n",
            "Epoch 306/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.7378e-04\n",
            "Epoch 306: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.8129e-04 - val_loss: 0.0031\n",
            "Epoch 307/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.2123e-04\n",
            "Epoch 307: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.2155e-04 - val_loss: 0.0016\n",
            "Epoch 308/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.5752e-04\n",
            "Epoch 308: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5675e-04 - val_loss: 0.0032\n",
            "Epoch 309/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.0203e-04\n",
            "Epoch 309: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.9843e-04 - val_loss: 0.0027\n",
            "Epoch 310/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.4726e-04\n",
            "Epoch 310: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4416e-04 - val_loss: 0.0012\n",
            "Epoch 311/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.6291e-04\n",
            "Epoch 311: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6409e-04 - val_loss: 0.0022\n",
            "Epoch 312/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.6566e-04\n",
            "Epoch 312: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5561e-04 - val_loss: 0.0015\n",
            "Epoch 313/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.8782e-04\n",
            "Epoch 313: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.8907e-04 - val_loss: 0.0011\n",
            "Epoch 314/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.0585e-04\n",
            "Epoch 314: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.0820e-04 - val_loss: 7.5588e-04\n",
            "Epoch 315/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 5.1061e-04\n",
            "Epoch 315: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 5.0498e-04 - val_loss: 0.0012\n",
            "Epoch 316/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.4994e-04\n",
            "Epoch 316: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4994e-04 - val_loss: 0.0016\n",
            "Epoch 317/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6300e-04\n",
            "Epoch 317: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5859e-04 - val_loss: 0.0015\n",
            "Epoch 318/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.9202e-04\n",
            "Epoch 318: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9671e-04 - val_loss: 0.0035\n",
            "Epoch 319/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.6584e-04\n",
            "Epoch 319: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.6582e-04 - val_loss: 0.0023\n",
            "Epoch 320/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6227e-04\n",
            "Epoch 320: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5442e-04 - val_loss: 0.0022\n",
            "Epoch 321/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.2165e-04\n",
            "Epoch 321: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.2181e-04 - val_loss: 0.0033\n",
            "Epoch 322/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 5.3141e-04\n",
            "Epoch 322: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 5.4100e-04 - val_loss: 0.0013\n",
            "Epoch 323/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.6974e-04\n",
            "Epoch 323: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6840e-04 - val_loss: 0.0031\n",
            "Epoch 324/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.2910e-04\n",
            "Epoch 324: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3034e-04 - val_loss: 0.0040\n",
            "Epoch 325/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.5925e-04\n",
            "Epoch 325: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.5925e-04 - val_loss: 0.0033\n",
            "Epoch 326/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.6164e-04\n",
            "Epoch 326: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.6164e-04 - val_loss: 0.0023\n",
            "Epoch 327/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.6714e-04\n",
            "Epoch 327: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.6723e-04 - val_loss: 0.0035\n",
            "Epoch 328/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.8391e-04\n",
            "Epoch 328: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8318e-04 - val_loss: 0.0028\n",
            "Epoch 329/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.3425e-04\n",
            "Epoch 329: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.3577e-04 - val_loss: 0.0015\n",
            "Epoch 330/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.6462e-04\n",
            "Epoch 330: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6947e-04 - val_loss: 0.0014\n",
            "Epoch 331/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.7162e-04\n",
            "Epoch 331: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7297e-04 - val_loss: 0.0024\n",
            "Epoch 332/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.0354e-04\n",
            "Epoch 332: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.0024e-04 - val_loss: 0.0018\n",
            "Epoch 333/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.9971e-04\n",
            "Epoch 333: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9766e-04 - val_loss: 8.6036e-04\n",
            "Epoch 334/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.6167e-04\n",
            "Epoch 334: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6043e-04 - val_loss: 0.0030\n",
            "Epoch 335/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.2956e-04\n",
            "Epoch 335: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3940e-04 - val_loss: 0.0025\n",
            "Epoch 336/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.7657e-04\n",
            "Epoch 336: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6437e-04 - val_loss: 0.0019\n",
            "Epoch 337/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.4811e-04\n",
            "Epoch 337: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4811e-04 - val_loss: 0.0018\n",
            "Epoch 338/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.2300e-04\n",
            "Epoch 338: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.2300e-04 - val_loss: 0.0024\n",
            "Epoch 339/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.6928e-04\n",
            "Epoch 339: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6839e-04 - val_loss: 0.0010\n",
            "Epoch 340/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.8761e-04\n",
            "Epoch 340: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.8400e-04 - val_loss: 0.0030\n",
            "Epoch 341/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.4981e-04\n",
            "Epoch 341: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.4435e-04 - val_loss: 0.0025\n",
            "Epoch 342/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.0842e-04\n",
            "Epoch 342: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.0871e-04 - val_loss: 0.0026\n",
            "Epoch 343/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.1426e-04\n",
            "Epoch 343: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.1099e-04 - val_loss: 0.0029\n",
            "Epoch 344/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6142e-04\n",
            "Epoch 344: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7311e-04 - val_loss: 0.0031\n",
            "Epoch 345/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.1271e-04\n",
            "Epoch 345: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 4.1271e-04 - val_loss: 0.0043\n",
            "Epoch 346/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.6534e-04\n",
            "Epoch 346: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.6332e-04 - val_loss: 0.0026\n",
            "Epoch 347/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.3229e-04\n",
            "Epoch 347: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.3322e-04 - val_loss: 0.0050\n",
            "Epoch 348/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.4818e-04\n",
            "Epoch 348: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.5353e-04 - val_loss: 0.0028\n",
            "Epoch 349/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.2535e-04\n",
            "Epoch 349: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.2535e-04 - val_loss: 0.0011\n",
            "Epoch 350/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.6199e-04\n",
            "Epoch 350: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.6430e-04 - val_loss: 0.0018\n",
            "Epoch 351/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.0425e-04\n",
            "Epoch 351: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.1379e-04 - val_loss: 0.0015\n",
            "Epoch 352/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.3128e-04\n",
            "Epoch 352: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.2452e-04 - val_loss: 0.0016\n",
            "Epoch 353/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.5642e-04\n",
            "Epoch 353: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5642e-04 - val_loss: 0.0030\n",
            "Epoch 354/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.3474e-04\n",
            "Epoch 354: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3256e-04 - val_loss: 9.4133e-04\n",
            "Epoch 355/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.5297e-04\n",
            "Epoch 355: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5061e-04 - val_loss: 0.0011\n",
            "Epoch 356/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.3746e-04\n",
            "Epoch 356: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4122e-04 - val_loss: 0.0018\n",
            "Epoch 357/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.5890e-04\n",
            "Epoch 357: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5867e-04 - val_loss: 0.0016\n",
            "Epoch 358/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.1738e-04\n",
            "Epoch 358: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.1436e-04 - val_loss: 0.0021\n",
            "Epoch 359/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.6407e-04\n",
            "Epoch 359: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.6541e-04 - val_loss: 0.0036\n",
            "Epoch 360/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.2957e-04\n",
            "Epoch 360: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.2956e-04 - val_loss: 0.0025\n",
            "Epoch 361/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.4534e-04\n",
            "Epoch 361: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3935e-04 - val_loss: 0.0051\n",
            "Epoch 362/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.3581e-04\n",
            "Epoch 362: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3283e-04 - val_loss: 0.0023\n",
            "Epoch 363/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.8604e-04\n",
            "Epoch 363: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.9399e-04 - val_loss: 0.0028\n",
            "Epoch 364/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.8401e-04\n",
            "Epoch 364: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.8358e-04 - val_loss: 0.0023\n",
            "Epoch 365/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.3211e-04\n",
            "Epoch 365: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3209e-04 - val_loss: 0.0012\n",
            "Epoch 366/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.1856e-04\n",
            "Epoch 366: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.1856e-04 - val_loss: 0.0021\n",
            "Epoch 367/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.4250e-04\n",
            "Epoch 367: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.4223e-04 - val_loss: 0.0015\n",
            "Epoch 368/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.7781e-04\n",
            "Epoch 368: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.7781e-04 - val_loss: 0.0083\n",
            "Epoch 369/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.7817e-04\n",
            "Epoch 369: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.7640e-04 - val_loss: 0.0030\n",
            "Epoch 370/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.4337e-04\n",
            "Epoch 370: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.4297e-04 - val_loss: 0.0013\n",
            "Epoch 371/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.8136e-04\n",
            "Epoch 371: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.7792e-04 - val_loss: 0.0013\n",
            "Epoch 372/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.6582e-04\n",
            "Epoch 372: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.6582e-04 - val_loss: 0.0032\n",
            "Epoch 373/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.2476e-04\n",
            "Epoch 373: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.2013e-04 - val_loss: 0.0031\n",
            "Epoch 374/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 2.9687e-04\n",
            "Epoch 374: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 2.9811e-04 - val_loss: 0.0025\n",
            "Epoch 375/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.3903e-04\n",
            "Epoch 375: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3955e-04 - val_loss: 0.0055\n",
            "Epoch 376/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.7425e-04\n",
            "Epoch 376: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.6900e-04 - val_loss: 9.6514e-04\n",
            "Epoch 377/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.2639e-04\n",
            "Epoch 377: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.2233e-04 - val_loss: 0.0017\n",
            "Epoch 378/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.5231e-04\n",
            "Epoch 378: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.5231e-04 - val_loss: 0.0060\n",
            "Epoch 379/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.2957e-04\n",
            "Epoch 379: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2957e-04 - val_loss: 0.0042\n",
            "Epoch 380/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.5072e-04\n",
            "Epoch 380: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5072e-04 - val_loss: 0.0035\n",
            "Epoch 381/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.3660e-04\n",
            "Epoch 381: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4338e-04 - val_loss: 9.7863e-04\n",
            "Epoch 382/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.3421e-04\n",
            "Epoch 382: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4328e-04 - val_loss: 0.0030\n",
            "Epoch 383/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.3685e-04\n",
            "Epoch 383: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3100e-04 - val_loss: 0.0036\n",
            "Epoch 384/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.4634e-04\n",
            "Epoch 384: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3967e-04 - val_loss: 0.0024\n",
            "Epoch 385/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.5588e-04\n",
            "Epoch 385: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5294e-04 - val_loss: 0.0038\n",
            "Epoch 386/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.1596e-04\n",
            "Epoch 386: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.1503e-04 - val_loss: 0.0025\n",
            "Epoch 387/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.4683e-04\n",
            "Epoch 387: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.4276e-04 - val_loss: 0.0014\n",
            "Epoch 388/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.4795e-04\n",
            "Epoch 388: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.4995e-04 - val_loss: 0.0034\n",
            "Epoch 389/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.2515e-04\n",
            "Epoch 389: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.2340e-04 - val_loss: 0.0017\n",
            "Epoch 390/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.3039e-04\n",
            "Epoch 390: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.2590e-04 - val_loss: 0.0027\n",
            "Epoch 391/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.6354e-04\n",
            "Epoch 391: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.5504e-04 - val_loss: 0.0040\n",
            "Epoch 392/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.3686e-04\n",
            "Epoch 392: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3204e-04 - val_loss: 0.0017\n",
            "Epoch 393/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.4650e-04\n",
            "Epoch 393: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4650e-04 - val_loss: 0.0020\n",
            "Epoch 394/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.5253e-04\n",
            "Epoch 394: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.5233e-04 - val_loss: 0.0032\n",
            "Epoch 395/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.0762e-04\n",
            "Epoch 395: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.2080e-04 - val_loss: 0.0023\n",
            "Epoch 396/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.4203e-04\n",
            "Epoch 396: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4538e-04 - val_loss: 0.0036\n",
            "Epoch 397/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.8088e-04\n",
            "Epoch 397: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.8537e-04 - val_loss: 0.0032\n",
            "Epoch 398/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.6445e-04\n",
            "Epoch 398: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6368e-04 - val_loss: 0.0040\n",
            "Epoch 399/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.0293e-04\n",
            "Epoch 399: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 2.9981e-04 - val_loss: 0.0022\n",
            "Epoch 400/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.3470e-04\n",
            "Epoch 400: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3322e-04 - val_loss: 0.0024\n",
            "Epoch 401/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.2852e-04\n",
            "Epoch 401: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2547e-04 - val_loss: 0.0035\n",
            "Epoch 402/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 2.9714e-04\n",
            "Epoch 402: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 2.9714e-04 - val_loss: 0.0015\n",
            "Epoch 403/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.0960e-04\n",
            "Epoch 403: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0960e-04 - val_loss: 0.0017\n",
            "Epoch 404/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.2475e-04\n",
            "Epoch 404: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2475e-04 - val_loss: 0.0035\n",
            "Epoch 405/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.3777e-04\n",
            "Epoch 405: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3219e-04 - val_loss: 0.0024\n",
            "Epoch 406/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.5416e-04\n",
            "Epoch 406: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5278e-04 - val_loss: 0.0031\n",
            "Epoch 407/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.1692e-04\n",
            "Epoch 407: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.1843e-04 - val_loss: 0.0041\n",
            "Epoch 408/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 2.9115e-04\n",
            "Epoch 408: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.9115e-04 - val_loss: 0.0033\n",
            "Epoch 409/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.8029e-04\n",
            "Epoch 409: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8029e-04 - val_loss: 0.0050\n",
            "Epoch 410/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.6044e-04\n",
            "Epoch 410: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.6120e-04 - val_loss: 0.0043\n",
            "Epoch 411/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.4074e-04\n",
            "Epoch 411: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4038e-04 - val_loss: 0.0044\n",
            "Epoch 412/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.1778e-04\n",
            "Epoch 412: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.1663e-04 - val_loss: 0.0028\n",
            "Epoch 413/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.7866e-04\n",
            "Epoch 413: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7959e-04 - val_loss: 0.0016\n",
            "Epoch 414/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.5584e-04\n",
            "Epoch 414: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5586e-04 - val_loss: 0.0026\n",
            "Epoch 415/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.7894e-04\n",
            "Epoch 415: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7469e-04 - val_loss: 0.0044\n",
            "Epoch 416/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.3325e-04\n",
            "Epoch 416: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.3493e-04 - val_loss: 0.0037\n",
            "Epoch 417/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.1083e-04\n",
            "Epoch 417: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.1548e-04 - val_loss: 0.0027\n",
            "Epoch 418/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.5156e-04\n",
            "Epoch 418: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4887e-04 - val_loss: 0.0014\n",
            "Epoch 419/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.5758e-04\n",
            "Epoch 419: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5758e-04 - val_loss: 0.0012\n",
            "Epoch 420/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.8463e-04\n",
            "Epoch 420: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.8463e-04 - val_loss: 9.8069e-04\n",
            "Epoch 421/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.9186e-04\n",
            "Epoch 421: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.9417e-04 - val_loss: 0.0023\n",
            "Epoch 422/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.2879e-04\n",
            "Epoch 422: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2879e-04 - val_loss: 0.0028\n",
            "Epoch 423/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.7498e-04\n",
            "Epoch 423: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7292e-04 - val_loss: 0.0027\n",
            "Epoch 424/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.3346e-04\n",
            "Epoch 424: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3346e-04 - val_loss: 0.0023\n",
            "Epoch 425/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.4210e-04\n",
            "Epoch 425: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.4056e-04 - val_loss: 0.0027\n",
            "Epoch 426/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 2.7295e-04\n",
            "Epoch 426: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 2.8472e-04 - val_loss: 0.0031\n",
            "Epoch 427/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.0609e-04\n",
            "Epoch 427: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 4.0570e-04 - val_loss: 0.0015\n",
            "Epoch 428/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.3411e-04\n",
            "Epoch 428: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.3411e-04 - val_loss: 0.0011\n",
            "Epoch 429/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.2867e-04\n",
            "Epoch 429: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.2867e-04 - val_loss: 0.0019\n",
            "Epoch 430/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.1433e-04\n",
            "Epoch 430: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.2891e-04 - val_loss: 0.0030\n",
            "Epoch 431/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.1481e-04\n",
            "Epoch 431: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1405e-04 - val_loss: 0.0020\n",
            "Epoch 432/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.4561e-04\n",
            "Epoch 432: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4129e-04 - val_loss: 0.0035\n",
            "Epoch 433/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.0096e-04\n",
            "Epoch 433: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.9617e-04 - val_loss: 0.0073\n",
            "Epoch 434/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.2014e-04\n",
            "Epoch 434: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1909e-04 - val_loss: 0.0024\n",
            "Epoch 435/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.4329e-04\n",
            "Epoch 435: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4612e-04 - val_loss: 0.0042\n",
            "Epoch 436/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.5070e-04\n",
            "Epoch 436: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4802e-04 - val_loss: 9.9127e-04\n",
            "Epoch 437/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.8343e-04\n",
            "Epoch 437: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.8156e-04 - val_loss: 0.0049\n",
            "Epoch 438/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.5366e-04\n",
            "Epoch 438: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.5366e-04 - val_loss: 0.0043\n",
            "Epoch 439/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.4377e-04\n",
            "Epoch 439: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4101e-04 - val_loss: 0.0038\n",
            "Epoch 440/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.0084e-04\n",
            "Epoch 440: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0084e-04 - val_loss: 0.0023\n",
            "Epoch 441/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.4140e-04\n",
            "Epoch 441: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3925e-04 - val_loss: 0.0039\n",
            "Epoch 442/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.1358e-04\n",
            "Epoch 442: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1358e-04 - val_loss: 0.0045\n",
            "Epoch 443/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.2047e-04\n",
            "Epoch 443: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1925e-04 - val_loss: 0.0061\n",
            "Epoch 444/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.2135e-04\n",
            "Epoch 444: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2224e-04 - val_loss: 0.0023\n",
            "Epoch 445/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.2964e-04\n",
            "Epoch 445: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.2964e-04 - val_loss: 0.0025\n",
            "Epoch 446/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.2267e-04\n",
            "Epoch 446: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.1829e-04 - val_loss: 0.0025\n",
            "Epoch 447/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.4398e-04\n",
            "Epoch 447: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.4398e-04 - val_loss: 0.0027\n",
            "Epoch 448/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.3560e-04\n",
            "Epoch 448: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.4045e-04 - val_loss: 0.0031\n",
            "Epoch 449/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.3173e-04\n",
            "Epoch 449: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.3216e-04 - val_loss: 0.0031\n",
            "Epoch 450/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.2656e-04\n",
            "Epoch 450: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2656e-04 - val_loss: 0.0023\n",
            "Epoch 451/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.8529e-04\n",
            "Epoch 451: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.7835e-04 - val_loss: 0.0041\n",
            "Epoch 452/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.4120e-04\n",
            "Epoch 452: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4115e-04 - val_loss: 0.0020\n",
            "Epoch 453/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.0924e-04\n",
            "Epoch 453: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0924e-04 - val_loss: 0.0024\n",
            "Epoch 454/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.1496e-04\n",
            "Epoch 454: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.1816e-04 - val_loss: 0.0076\n",
            "Epoch 455/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.1814e-04\n",
            "Epoch 455: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2300e-04 - val_loss: 0.0024\n",
            "Epoch 456/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 2.8794e-04\n",
            "Epoch 456: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.8718e-04 - val_loss: 0.0024\n",
            "Epoch 457/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 2.7857e-04\n",
            "Epoch 457: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.7857e-04 - val_loss: 0.0020\n",
            "Epoch 458/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 2.9386e-04\n",
            "Epoch 458: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.9468e-04 - val_loss: 0.0056\n",
            "Epoch 459/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.1490e-04\n",
            "Epoch 459: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1407e-04 - val_loss: 0.0032\n",
            "Epoch 460/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.5158e-04\n",
            "Epoch 460: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4548e-04 - val_loss: 0.0026\n",
            "Epoch 461/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.4877e-04\n",
            "Epoch 461: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4997e-04 - val_loss: 0.0041\n",
            "Epoch 462/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.3486e-04\n",
            "Epoch 462: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3211e-04 - val_loss: 0.0034\n",
            "Epoch 463/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.1610e-04\n",
            "Epoch 463: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1217e-04 - val_loss: 0.0032\n",
            "Epoch 464/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.1963e-04\n",
            "Epoch 464: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.1948e-04 - val_loss: 0.0053\n",
            "Epoch 465/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 2.9873e-04\n",
            "Epoch 465: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.0076e-04 - val_loss: 0.0016\n",
            "Epoch 466/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.0321e-04\n",
            "Epoch 466: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.0321e-04 - val_loss: 0.0032\n",
            "Epoch 467/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.2909e-04\n",
            "Epoch 467: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.2442e-04 - val_loss: 0.0025\n",
            "Epoch 468/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 2.9235e-04\n",
            "Epoch 468: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 2.9235e-04 - val_loss: 0.0024\n",
            "Epoch 469/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.4300e-04\n",
            "Epoch 469: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.4266e-04 - val_loss: 0.0048\n",
            "Epoch 470/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.3715e-04\n",
            "Epoch 470: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3715e-04 - val_loss: 0.0040\n",
            "Epoch 471/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.3074e-04\n",
            "Epoch 471: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.3074e-04 - val_loss: 0.0024\n",
            "Epoch 472/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 2.9829e-04\n",
            "Epoch 472: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.0075e-04 - val_loss: 0.0035\n",
            "Epoch 473/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 2.8880e-04\n",
            "Epoch 473: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 2.8376e-04 - val_loss: 0.0030\n",
            "Epoch 474/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.2374e-04\n",
            "Epoch 474: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1876e-04 - val_loss: 0.0023\n",
            "Epoch 475/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.0834e-04\n",
            "Epoch 475: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0699e-04 - val_loss: 0.0035\n",
            "Epoch 476/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 2.8348e-04\n",
            "Epoch 476: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.8278e-04 - val_loss: 0.0036\n",
            "Epoch 477/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 2.9976e-04\n",
            "Epoch 477: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.9863e-04 - val_loss: 0.0037\n",
            "Epoch 478/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 2.9567e-04\n",
            "Epoch 478: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.9585e-04 - val_loss: 0.0042\n",
            "Epoch 479/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.7395e-04\n",
            "Epoch 479: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.7015e-04 - val_loss: 0.0011\n",
            "Epoch 480/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.1810e-04\n",
            "Epoch 480: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1614e-04 - val_loss: 0.0013\n",
            "Epoch 481/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.1235e-04\n",
            "Epoch 481: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.1146e-04 - val_loss: 0.0027\n",
            "Epoch 482/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.1104e-04\n",
            "Epoch 482: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1104e-04 - val_loss: 0.0050\n",
            "Epoch 483/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.1699e-04\n",
            "Epoch 483: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.1092e-04 - val_loss: 0.0051\n",
            "Epoch 484/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 2.8791e-04\n",
            "Epoch 484: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 2.8863e-04 - val_loss: 0.0016\n",
            "Epoch 485/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 2.8341e-04\n",
            "Epoch 485: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.8818e-04 - val_loss: 0.0028\n",
            "Epoch 486/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.1923e-04\n",
            "Epoch 486: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.2119e-04 - val_loss: 0.0022\n",
            "Epoch 487/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.1707e-04\n",
            "Epoch 487: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.1532e-04 - val_loss: 0.0036\n",
            "Epoch 488/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 2.8907e-04\n",
            "Epoch 488: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 2.8878e-04 - val_loss: 0.0037\n",
            "Epoch 489/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.3611e-04\n",
            "Epoch 489: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3356e-04 - val_loss: 0.0038\n",
            "Epoch 490/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.4163e-04\n",
            "Epoch 490: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4073e-04 - val_loss: 0.0075\n",
            "Epoch 491/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.2940e-04\n",
            "Epoch 491: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3092e-04 - val_loss: 0.0019\n",
            "Epoch 492/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.7285e-04\n",
            "Epoch 492: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.6845e-04 - val_loss: 0.0058\n",
            "Epoch 493/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.9752e-04\n",
            "Epoch 493: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.8555e-04 - val_loss: 0.0037\n",
            "Epoch 494/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.1906e-04\n",
            "Epoch 494: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1565e-04 - val_loss: 0.0045\n",
            "Epoch 495/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.2555e-04\n",
            "Epoch 495: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2673e-04 - val_loss: 0.0045\n",
            "Epoch 496/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.3628e-04\n",
            "Epoch 496: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3628e-04 - val_loss: 0.0069\n",
            "Epoch 497/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 2.9507e-04\n",
            "Epoch 497: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.9671e-04 - val_loss: 0.0050\n",
            "Epoch 498/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.0431e-04\n",
            "Epoch 498: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.0320e-04 - val_loss: 0.0030\n",
            "Epoch 499/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.3167e-04\n",
            "Epoch 499: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3282e-04 - val_loss: 0.0052\n",
            "Epoch 500/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.0796e-04\n",
            "Epoch 500: val_loss did not improve from 0.00053\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0793e-04 - val_loss: 0.0018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(filepath='best_model_oc.h5', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
        "\n",
        "# Train the model with ModelCheckpoint callback\n",
        "history_oc = model_oc.fit(X_train_oc, y_train_oc, epochs=500, batch_size=16, validation_data=(X_test_oc, y_test_oc), callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXYY8yVL1FoH",
        "outputId": "e1d92fd1-b6c6-449e-b5e9-cd4f6e00ba8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.0363\n",
            "Epoch 1: val_loss improved from inf to 0.01242, saving model to best_model_oc.h5\n",
            "61/61 [==============================] - 4s 16ms/step - loss: 0.0342 - val_loss: 0.0124\n",
            "Epoch 2/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0074\n",
            "Epoch 2: val_loss improved from 0.01242 to 0.00497, saving model to best_model_oc.h5\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.0074 - val_loss: 0.0050\n",
            "Epoch 3/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.0057\n",
            "Epoch 3: val_loss did not improve from 0.00497\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0056 - val_loss: 0.0071\n",
            "Epoch 4/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0045\n",
            "Epoch 4: val_loss did not improve from 0.00497\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0044 - val_loss: 0.0114\n",
            "Epoch 5/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0031\n",
            "Epoch 5: val_loss did not improve from 0.00497\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.0031 - val_loss: 0.0075\n",
            "Epoch 6/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0030\n",
            "Epoch 6: val_loss did not improve from 0.00497\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.0030 - val_loss: 0.0088\n",
            "Epoch 7/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0026\n",
            "Epoch 7: val_loss did not improve from 0.00497\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.0026 - val_loss: 0.0063\n",
            "Epoch 8/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.0025\n",
            "Epoch 8: val_loss did not improve from 0.00497\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 0.0025 - val_loss: 0.0071\n",
            "Epoch 9/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0025\n",
            "Epoch 9: val_loss did not improve from 0.00497\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0025 - val_loss: 0.0109\n",
            "Epoch 10/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0022\n",
            "Epoch 10: val_loss did not improve from 0.00497\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0050\n",
            "Epoch 11/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.0021\n",
            "Epoch 11: val_loss improved from 0.00497 to 0.00365, saving model to best_model_oc.h5\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.0022 - val_loss: 0.0037\n",
            "Epoch 12/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0019\n",
            "Epoch 12: val_loss did not improve from 0.00365\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0053\n",
            "Epoch 13/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0016\n",
            "Epoch 13: val_loss did not improve from 0.00365\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0084\n",
            "Epoch 14/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0016\n",
            "Epoch 14: val_loss improved from 0.00365 to 0.00189, saving model to best_model_oc.h5\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.0016 - val_loss: 0.0019\n",
            "Epoch 15/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0017\n",
            "Epoch 15: val_loss did not improve from 0.00189\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0042\n",
            "Epoch 16/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0017\n",
            "Epoch 16: val_loss did not improve from 0.00189\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0127\n",
            "Epoch 17/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0017\n",
            "Epoch 17: val_loss did not improve from 0.00189\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 18/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0015\n",
            "Epoch 18: val_loss did not improve from 0.00189\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0029\n",
            "Epoch 19/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0021\n",
            "Epoch 19: val_loss did not improve from 0.00189\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 0.0027\n",
            "Epoch 20/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0014\n",
            "Epoch 20: val_loss did not improve from 0.00189\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0079\n",
            "Epoch 21/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0014\n",
            "Epoch 21: val_loss did not improve from 0.00189\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0046\n",
            "Epoch 22/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0014\n",
            "Epoch 22: val_loss did not improve from 0.00189\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0084\n",
            "Epoch 23/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0014\n",
            "Epoch 23: val_loss did not improve from 0.00189\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0044\n",
            "Epoch 24/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.0014\n",
            "Epoch 24: val_loss improved from 0.00189 to 0.00097, saving model to best_model_oc.h5\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 9.7198e-04\n",
            "Epoch 25/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0013\n",
            "Epoch 25: val_loss did not improve from 0.00097\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0025\n",
            "Epoch 26/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0012\n",
            "Epoch 26: val_loss did not improve from 0.00097\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 0.0012 - val_loss: 0.0100\n",
            "Epoch 27/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0012\n",
            "Epoch 27: val_loss did not improve from 0.00097\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 0.0012 - val_loss: 0.0015\n",
            "Epoch 28/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0012\n",
            "Epoch 28: val_loss did not improve from 0.00097\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 0.0012 - val_loss: 0.0038\n",
            "Epoch 29/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0014\n",
            "Epoch 29: val_loss did not improve from 0.00097\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 0.0014 - val_loss: 0.0011\n",
            "Epoch 30/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 9.8061e-04\n",
            "Epoch 30: val_loss did not improve from 0.00097\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 9.7934e-04 - val_loss: 0.0012\n",
            "Epoch 31/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 9.7570e-04\n",
            "Epoch 31: val_loss improved from 0.00097 to 0.00087, saving model to best_model_oc.h5\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 9.6956e-04 - val_loss: 8.6969e-04\n",
            "Epoch 32/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 9.8152e-04\n",
            "Epoch 32: val_loss did not improve from 0.00087\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 9.8152e-04 - val_loss: 0.0018\n",
            "Epoch 33/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0011\n",
            "Epoch 33: val_loss did not improve from 0.00087\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0011 - val_loss: 0.0032\n",
            "Epoch 34/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0010\n",
            "Epoch 34: val_loss did not improve from 0.00087\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0040\n",
            "Epoch 35/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0010\n",
            "Epoch 35: val_loss did not improve from 0.00087\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 0.0010 - val_loss: 0.0014\n",
            "Epoch 36/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 9.9582e-04\n",
            "Epoch 36: val_loss did not improve from 0.00087\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 9.7560e-04 - val_loss: 0.0025\n",
            "Epoch 37/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 9.1600e-04\n",
            "Epoch 37: val_loss did not improve from 0.00087\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 9.1463e-04 - val_loss: 0.0029\n",
            "Epoch 38/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 8.3688e-04\n",
            "Epoch 38: val_loss did not improve from 0.00087\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 8.3241e-04 - val_loss: 0.0036\n",
            "Epoch 39/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 8.5827e-04\n",
            "Epoch 39: val_loss did not improve from 0.00087\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 8.5827e-04 - val_loss: 0.0024\n",
            "Epoch 40/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 8.9137e-04\n",
            "Epoch 40: val_loss did not improve from 0.00087\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 8.9137e-04 - val_loss: 0.0011\n",
            "Epoch 41/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 8.7430e-04\n",
            "Epoch 41: val_loss improved from 0.00087 to 0.00084, saving model to best_model_oc.h5\n",
            "61/61 [==============================] - 2s 28ms/step - loss: 8.7430e-04 - val_loss: 8.4148e-04\n",
            "Epoch 42/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 8.1848e-04\n",
            "Epoch 42: val_loss did not improve from 0.00084\n",
            "61/61 [==============================] - 2s 27ms/step - loss: 8.1907e-04 - val_loss: 0.0055\n",
            "Epoch 43/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 8.9249e-04\n",
            "Epoch 43: val_loss did not improve from 0.00084\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 8.9061e-04 - val_loss: 0.0011\n",
            "Epoch 44/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 9.2100e-04\n",
            "Epoch 44: val_loss did not improve from 0.00084\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 9.2123e-04 - val_loss: 0.0029\n",
            "Epoch 45/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 8.2166e-04\n",
            "Epoch 45: val_loss improved from 0.00084 to 0.00071, saving model to best_model_oc.h5\n",
            "61/61 [==============================] - 1s 22ms/step - loss: 8.2166e-04 - val_loss: 7.0554e-04\n",
            "Epoch 46/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 7.6224e-04\n",
            "Epoch 46: val_loss did not improve from 0.00071\n",
            "61/61 [==============================] - 1s 24ms/step - loss: 7.6556e-04 - val_loss: 0.0022\n",
            "Epoch 47/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 8.2969e-04\n",
            "Epoch 47: val_loss improved from 0.00071 to 0.00060, saving model to best_model_oc.h5\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 8.1909e-04 - val_loss: 6.0250e-04\n",
            "Epoch 48/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 7.6188e-04\n",
            "Epoch 48: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 7.6188e-04 - val_loss: 0.0031\n",
            "Epoch 49/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 7.6131e-04\n",
            "Epoch 49: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 7.8822e-04 - val_loss: 6.1052e-04\n",
            "Epoch 50/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 8.8195e-04\n",
            "Epoch 50: val_loss did not improve from 0.00060\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 8.8195e-04 - val_loss: 0.0014\n",
            "Epoch 51/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 7.3689e-04\n",
            "Epoch 51: val_loss improved from 0.00060 to 0.00058, saving model to best_model_oc.h5\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 7.3689e-04 - val_loss: 5.7914e-04\n",
            "Epoch 52/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 7.3216e-04\n",
            "Epoch 52: val_loss did not improve from 0.00058\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 7.4274e-04 - val_loss: 0.0015\n",
            "Epoch 53/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 6.7071e-04\n",
            "Epoch 53: val_loss did not improve from 0.00058\n",
            "61/61 [==============================] - 2s 28ms/step - loss: 6.6931e-04 - val_loss: 0.0028\n",
            "Epoch 54/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 8.0620e-04\n",
            "Epoch 54: val_loss did not improve from 0.00058\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 8.3713e-04 - val_loss: 8.1323e-04\n",
            "Epoch 55/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 7.6329e-04\n",
            "Epoch 55: val_loss did not improve from 0.00058\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 7.5720e-04 - val_loss: 9.4193e-04\n",
            "Epoch 56/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 7.9126e-04\n",
            "Epoch 56: val_loss did not improve from 0.00058\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 7.8883e-04 - val_loss: 0.0012\n",
            "Epoch 57/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 6.9043e-04\n",
            "Epoch 57: val_loss did not improve from 0.00058\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 6.9043e-04 - val_loss: 0.0019\n",
            "Epoch 58/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 6.3446e-04\n",
            "Epoch 58: val_loss did not improve from 0.00058\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 6.3765e-04 - val_loss: 0.0040\n",
            "Epoch 59/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 8.6628e-04\n",
            "Epoch 59: val_loss did not improve from 0.00058\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 8.7002e-04 - val_loss: 0.0013\n",
            "Epoch 60/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 7.7937e-04\n",
            "Epoch 60: val_loss did not improve from 0.00058\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 7.8125e-04 - val_loss: 0.0037\n",
            "Epoch 61/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 7.0037e-04\n",
            "Epoch 61: val_loss improved from 0.00058 to 0.00049, saving model to best_model_oc.h5\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 6.8264e-04 - val_loss: 4.8618e-04\n",
            "Epoch 62/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 6.2137e-04\n",
            "Epoch 62: val_loss did not improve from 0.00049\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 6.2057e-04 - val_loss: 8.9806e-04\n",
            "Epoch 63/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 6.5406e-04\n",
            "Epoch 63: val_loss did not improve from 0.00049\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 6.3787e-04 - val_loss: 7.6410e-04\n",
            "Epoch 64/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 5.5896e-04\n",
            "Epoch 64: val_loss improved from 0.00049 to 0.00043, saving model to best_model_oc.h5\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 5.5522e-04 - val_loss: 4.3084e-04\n",
            "Epoch 65/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 6.6117e-04\n",
            "Epoch 65: val_loss did not improve from 0.00043\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 6.5602e-04 - val_loss: 8.3544e-04\n",
            "Epoch 66/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 6.4835e-04\n",
            "Epoch 66: val_loss did not improve from 0.00043\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 6.5372e-04 - val_loss: 0.0024\n",
            "Epoch 67/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 5.9539e-04\n",
            "Epoch 67: val_loss did not improve from 0.00043\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 5.9325e-04 - val_loss: 0.0028\n",
            "Epoch 68/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 6.0418e-04\n",
            "Epoch 68: val_loss did not improve from 0.00043\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 6.0418e-04 - val_loss: 4.7848e-04\n",
            "Epoch 69/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 5.6854e-04\n",
            "Epoch 69: val_loss did not improve from 0.00043\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 5.6854e-04 - val_loss: 9.4904e-04\n",
            "Epoch 70/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 6.3251e-04\n",
            "Epoch 70: val_loss did not improve from 0.00043\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 6.3436e-04 - val_loss: 4.3176e-04\n",
            "Epoch 71/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 7.3692e-04\n",
            "Epoch 71: val_loss did not improve from 0.00043\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 7.3577e-04 - val_loss: 0.0017\n",
            "Epoch 72/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 5.2304e-04\n",
            "Epoch 72: val_loss did not improve from 0.00043\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 5.2304e-04 - val_loss: 8.8984e-04\n",
            "Epoch 73/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.6170e-04\n",
            "Epoch 73: val_loss did not improve from 0.00043\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 4.6069e-04 - val_loss: 7.7722e-04\n",
            "Epoch 74/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 5.5914e-04\n",
            "Epoch 74: val_loss did not improve from 0.00043\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 5.5914e-04 - val_loss: 6.1167e-04\n",
            "Epoch 75/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 5.1657e-04\n",
            "Epoch 75: val_loss did not improve from 0.00043\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 5.1657e-04 - val_loss: 0.0022\n",
            "Epoch 76/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 5.3617e-04\n",
            "Epoch 76: val_loss did not improve from 0.00043\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 5.3753e-04 - val_loss: 6.9466e-04\n",
            "Epoch 77/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 6.1130e-04\n",
            "Epoch 77: val_loss did not improve from 0.00043\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 6.1130e-04 - val_loss: 0.0037\n",
            "Epoch 78/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 5.0613e-04\n",
            "Epoch 78: val_loss did not improve from 0.00043\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 5.0133e-04 - val_loss: 0.0017\n",
            "Epoch 79/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 6.5724e-04\n",
            "Epoch 79: val_loss did not improve from 0.00043\n",
            "61/61 [==============================] - 1s 24ms/step - loss: 6.5724e-04 - val_loss: 0.0028\n",
            "Epoch 80/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 5.0259e-04\n",
            "Epoch 80: val_loss did not improve from 0.00043\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.9977e-04 - val_loss: 9.6418e-04\n",
            "Epoch 81/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.9530e-04\n",
            "Epoch 81: val_loss did not improve from 0.00043\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.9338e-04 - val_loss: 0.0043\n",
            "Epoch 82/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 5.5601e-04\n",
            "Epoch 82: val_loss did not improve from 0.00043\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 5.5539e-04 - val_loss: 7.9852e-04\n",
            "Epoch 83/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.9831e-04\n",
            "Epoch 83: val_loss did not improve from 0.00043\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 5.0469e-04 - val_loss: 0.0019\n",
            "Epoch 84/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 5.0065e-04\n",
            "Epoch 84: val_loss did not improve from 0.00043\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.9739e-04 - val_loss: 0.0011\n",
            "Epoch 85/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 5.1428e-04\n",
            "Epoch 85: val_loss did not improve from 0.00043\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 5.2699e-04 - val_loss: 0.0025\n",
            "Epoch 86/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 5.7684e-04\n",
            "Epoch 86: val_loss did not improve from 0.00043\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 5.7684e-04 - val_loss: 0.0015\n",
            "Epoch 87/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.7597e-04\n",
            "Epoch 87: val_loss improved from 0.00043 to 0.00036, saving model to best_model_oc.h5\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.6771e-04 - val_loss: 3.5523e-04\n",
            "Epoch 88/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.5459e-04\n",
            "Epoch 88: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.6339e-04 - val_loss: 0.0014\n",
            "Epoch 89/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 5.2445e-04\n",
            "Epoch 89: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 5.2708e-04 - val_loss: 0.0037\n",
            "Epoch 90/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 4.8860e-04\n",
            "Epoch 90: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.9686e-04 - val_loss: 0.0014\n",
            "Epoch 91/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.8025e-04\n",
            "Epoch 91: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.8025e-04 - val_loss: 5.7936e-04\n",
            "Epoch 92/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.9250e-04\n",
            "Epoch 92: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 4.9250e-04 - val_loss: 0.0052\n",
            "Epoch 93/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.5906e-04\n",
            "Epoch 93: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 4.5661e-04 - val_loss: 9.7928e-04\n",
            "Epoch 94/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.4245e-04\n",
            "Epoch 94: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 4.4245e-04 - val_loss: 0.0011\n",
            "Epoch 95/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.8059e-04\n",
            "Epoch 95: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 4.8059e-04 - val_loss: 0.0011\n",
            "Epoch 96/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.8209e-04\n",
            "Epoch 96: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 4.9917e-04 - val_loss: 0.0010\n",
            "Epoch 97/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.3582e-04\n",
            "Epoch 97: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 4.3461e-04 - val_loss: 5.4448e-04\n",
            "Epoch 98/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.4899e-04\n",
            "Epoch 98: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 22ms/step - loss: 4.5461e-04 - val_loss: 0.0014\n",
            "Epoch 99/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.0495e-04\n",
            "Epoch 99: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 23ms/step - loss: 4.0675e-04 - val_loss: 0.0014\n",
            "Epoch 100/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.5906e-04\n",
            "Epoch 100: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.6234e-04 - val_loss: 0.0015\n",
            "Epoch 101/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.6620e-04\n",
            "Epoch 101: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.6596e-04 - val_loss: 0.0017\n",
            "Epoch 102/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.5179e-04\n",
            "Epoch 102: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 4.5343e-04 - val_loss: 0.0024\n",
            "Epoch 103/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 5.3281e-04\n",
            "Epoch 103: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 5.3109e-04 - val_loss: 7.6117e-04\n",
            "Epoch 104/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.8815e-04\n",
            "Epoch 104: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.8753e-04 - val_loss: 9.7089e-04\n",
            "Epoch 105/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.3471e-04\n",
            "Epoch 105: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.3471e-04 - val_loss: 0.0035\n",
            "Epoch 106/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.7126e-04\n",
            "Epoch 106: val_loss improved from 0.00036 to 0.00032, saving model to best_model_oc.h5\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.6901e-04 - val_loss: 3.1985e-04\n",
            "Epoch 107/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.0873e-04\n",
            "Epoch 107: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.1337e-04 - val_loss: 0.0021\n",
            "Epoch 108/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.3819e-04\n",
            "Epoch 108: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.3819e-04 - val_loss: 0.0010\n",
            "Epoch 109/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.0995e-04\n",
            "Epoch 109: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.0931e-04 - val_loss: 4.2751e-04\n",
            "Epoch 110/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 4.2675e-04\n",
            "Epoch 110: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.3214e-04 - val_loss: 3.8145e-04\n",
            "Epoch 111/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.1369e-04\n",
            "Epoch 111: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.0538e-04 - val_loss: 0.0011\n",
            "Epoch 112/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.2123e-04\n",
            "Epoch 112: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.1836e-04 - val_loss: 0.0016\n",
            "Epoch 113/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.6047e-04\n",
            "Epoch 113: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.5516e-04 - val_loss: 0.0018\n",
            "Epoch 114/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.5427e-04\n",
            "Epoch 114: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.5268e-04 - val_loss: 3.2864e-04\n",
            "Epoch 115/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.3353e-04\n",
            "Epoch 115: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 4.2314e-04 - val_loss: 6.5283e-04\n",
            "Epoch 116/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.2149e-04\n",
            "Epoch 116: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 4.2316e-04 - val_loss: 0.0019\n",
            "Epoch 117/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.9021e-04\n",
            "Epoch 117: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 24ms/step - loss: 3.8842e-04 - val_loss: 7.9426e-04\n",
            "Epoch 118/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.9943e-04\n",
            "Epoch 118: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 4.9764e-04 - val_loss: 0.0012\n",
            "Epoch 119/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.1159e-04\n",
            "Epoch 119: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.1747e-04 - val_loss: 0.0018\n",
            "Epoch 120/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.3323e-04\n",
            "Epoch 120: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 4.2639e-04 - val_loss: 0.0025\n",
            "Epoch 121/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.8084e-04\n",
            "Epoch 121: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.8964e-04 - val_loss: 5.9936e-04\n",
            "Epoch 122/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.2321e-04\n",
            "Epoch 122: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 22ms/step - loss: 4.2573e-04 - val_loss: 0.0013\n",
            "Epoch 123/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.3165e-04\n",
            "Epoch 123: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 4.2757e-04 - val_loss: 0.0011\n",
            "Epoch 124/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.5130e-04\n",
            "Epoch 124: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 4.6165e-04 - val_loss: 0.0025\n",
            "Epoch 125/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.2331e-04\n",
            "Epoch 125: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.2185e-04 - val_loss: 9.1050e-04\n",
            "Epoch 126/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.3341e-04\n",
            "Epoch 126: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 4.3871e-04 - val_loss: 3.2632e-04\n",
            "Epoch 127/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.5778e-04\n",
            "Epoch 127: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 23ms/step - loss: 4.5724e-04 - val_loss: 9.7331e-04\n",
            "Epoch 128/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.1533e-04\n",
            "Epoch 128: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 2s 25ms/step - loss: 4.2391e-04 - val_loss: 4.0543e-04\n",
            "Epoch 129/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.5204e-04\n",
            "Epoch 129: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 23ms/step - loss: 3.5204e-04 - val_loss: 6.0068e-04\n",
            "Epoch 130/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.2158e-04\n",
            "Epoch 130: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 4.2198e-04 - val_loss: 0.0030\n",
            "Epoch 131/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.6054e-04\n",
            "Epoch 131: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 4.5981e-04 - val_loss: 0.0022\n",
            "Epoch 132/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 5.1823e-04\n",
            "Epoch 132: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 5.1527e-04 - val_loss: 0.0021\n",
            "Epoch 133/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.5003e-04\n",
            "Epoch 133: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 4.4692e-04 - val_loss: 0.0017\n",
            "Epoch 134/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.3467e-04\n",
            "Epoch 134: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 4.3189e-04 - val_loss: 0.0034\n",
            "Epoch 135/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.7022e-04\n",
            "Epoch 135: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.6698e-04 - val_loss: 0.0013\n",
            "Epoch 136/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 5.1588e-04\n",
            "Epoch 136: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 5.2824e-04 - val_loss: 0.0013\n",
            "Epoch 137/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.4325e-04\n",
            "Epoch 137: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 4.3622e-04 - val_loss: 0.0033\n",
            "Epoch 138/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.3871e-04\n",
            "Epoch 138: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 23ms/step - loss: 3.3700e-04 - val_loss: 0.0031\n",
            "Epoch 139/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.6482e-04\n",
            "Epoch 139: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 3.6928e-04 - val_loss: 0.0017\n",
            "Epoch 140/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.8012e-04\n",
            "Epoch 140: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 4.7136e-04 - val_loss: 0.0035\n",
            "Epoch 141/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.9263e-04\n",
            "Epoch 141: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.9443e-04 - val_loss: 0.0042\n",
            "Epoch 142/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.3924e-04\n",
            "Epoch 142: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 4.4330e-04 - val_loss: 0.0048\n",
            "Epoch 143/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.9943e-04\n",
            "Epoch 143: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 4.0595e-04 - val_loss: 0.0017\n",
            "Epoch 144/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.6075e-04\n",
            "Epoch 144: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 3.6075e-04 - val_loss: 0.0024\n",
            "Epoch 145/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.2632e-04\n",
            "Epoch 145: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 24ms/step - loss: 4.2632e-04 - val_loss: 0.0018\n",
            "Epoch 146/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.2064e-04\n",
            "Epoch 146: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.1671e-04 - val_loss: 9.7006e-04\n",
            "Epoch 147/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.1459e-04\n",
            "Epoch 147: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 4.1478e-04 - val_loss: 0.0013\n",
            "Epoch 148/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.9489e-04\n",
            "Epoch 148: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.9220e-04 - val_loss: 7.8199e-04\n",
            "Epoch 149/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.7601e-04\n",
            "Epoch 149: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.7333e-04 - val_loss: 0.0044\n",
            "Epoch 150/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.3728e-04\n",
            "Epoch 150: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 4.3884e-04 - val_loss: 0.0032\n",
            "Epoch 151/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.1351e-04\n",
            "Epoch 151: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.1493e-04 - val_loss: 0.0040\n",
            "Epoch 152/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.4173e-04\n",
            "Epoch 152: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.4590e-04 - val_loss: 0.0014\n",
            "Epoch 153/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.6131e-04\n",
            "Epoch 153: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 4.5708e-04 - val_loss: 7.4730e-04\n",
            "Epoch 154/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.2012e-04\n",
            "Epoch 154: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 4.1311e-04 - val_loss: 0.0072\n",
            "Epoch 155/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.0176e-04\n",
            "Epoch 155: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.9962e-04 - val_loss: 0.0026\n",
            "Epoch 156/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.6485e-04\n",
            "Epoch 156: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.6130e-04 - val_loss: 0.0014\n",
            "Epoch 157/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.2939e-04\n",
            "Epoch 157: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.2432e-04 - val_loss: 0.0010\n",
            "Epoch 158/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.6577e-04\n",
            "Epoch 158: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.6608e-04 - val_loss: 8.9118e-04\n",
            "Epoch 159/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.9274e-04\n",
            "Epoch 159: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.0169e-04 - val_loss: 0.0026\n",
            "Epoch 160/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.6024e-04\n",
            "Epoch 160: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6104e-04 - val_loss: 7.7209e-04\n",
            "Epoch 161/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.0291e-04\n",
            "Epoch 161: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.0356e-04 - val_loss: 0.0026\n",
            "Epoch 162/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.6316e-04\n",
            "Epoch 162: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6368e-04 - val_loss: 0.0021\n",
            "Epoch 163/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.9897e-04\n",
            "Epoch 163: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9573e-04 - val_loss: 0.0033\n",
            "Epoch 164/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.4521e-04\n",
            "Epoch 164: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4521e-04 - val_loss: 0.0044\n",
            "Epoch 165/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.9328e-04\n",
            "Epoch 165: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.8813e-04 - val_loss: 0.0011\n",
            "Epoch 166/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.8054e-04\n",
            "Epoch 166: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7214e-04 - val_loss: 0.0013\n",
            "Epoch 167/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.8468e-04\n",
            "Epoch 167: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.8468e-04 - val_loss: 7.0713e-04\n",
            "Epoch 168/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.1490e-04\n",
            "Epoch 168: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.1872e-04 - val_loss: 0.0026\n",
            "Epoch 169/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.9202e-04\n",
            "Epoch 169: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.9202e-04 - val_loss: 0.0014\n",
            "Epoch 170/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.7206e-04\n",
            "Epoch 170: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.7031e-04 - val_loss: 0.0015\n",
            "Epoch 171/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.4946e-04\n",
            "Epoch 171: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 3.5441e-04 - val_loss: 0.0032\n",
            "Epoch 172/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.7354e-04\n",
            "Epoch 172: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 22ms/step - loss: 3.7354e-04 - val_loss: 0.0036\n",
            "Epoch 173/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.9137e-04\n",
            "Epoch 173: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 2s 25ms/step - loss: 3.8928e-04 - val_loss: 0.0057\n",
            "Epoch 174/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.5258e-04\n",
            "Epoch 174: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 3.5111e-04 - val_loss: 0.0012\n",
            "Epoch 175/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.5348e-04\n",
            "Epoch 175: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.4992e-04 - val_loss: 0.0028\n",
            "Epoch 176/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.8169e-04\n",
            "Epoch 176: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.8198e-04 - val_loss: 0.0032\n",
            "Epoch 177/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.8157e-04\n",
            "Epoch 177: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.8065e-04 - val_loss: 0.0024\n",
            "Epoch 178/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.4566e-04\n",
            "Epoch 178: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 4.4566e-04 - val_loss: 0.0017\n",
            "Epoch 179/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.7174e-04\n",
            "Epoch 179: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 4.6592e-04 - val_loss: 3.6743e-04\n",
            "Epoch 180/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.4640e-04\n",
            "Epoch 180: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 4.4930e-04 - val_loss: 0.0027\n",
            "Epoch 181/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.9208e-04\n",
            "Epoch 181: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.9163e-04 - val_loss: 7.6935e-04\n",
            "Epoch 182/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.9909e-04\n",
            "Epoch 182: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.8827e-04 - val_loss: 0.0026\n",
            "Epoch 183/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.7674e-04\n",
            "Epoch 183: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.7522e-04 - val_loss: 0.0031\n",
            "Epoch 184/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.8652e-04\n",
            "Epoch 184: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9496e-04 - val_loss: 0.0013\n",
            "Epoch 185/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.9919e-04\n",
            "Epoch 185: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.9425e-04 - val_loss: 0.0035\n",
            "Epoch 186/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.5566e-04\n",
            "Epoch 186: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.6087e-04 - val_loss: 0.0021\n",
            "Epoch 187/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.9108e-04\n",
            "Epoch 187: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 4.0746e-04 - val_loss: 0.0034\n",
            "Epoch 188/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.3680e-04\n",
            "Epoch 188: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.3805e-04 - val_loss: 0.0014\n",
            "Epoch 189/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.5021e-04\n",
            "Epoch 189: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3944e-04 - val_loss: 0.0018\n",
            "Epoch 190/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.4053e-04\n",
            "Epoch 190: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4381e-04 - val_loss: 0.0010\n",
            "Epoch 191/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.0343e-04\n",
            "Epoch 191: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.0501e-04 - val_loss: 0.0019\n",
            "Epoch 192/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.4387e-04\n",
            "Epoch 192: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.5468e-04 - val_loss: 0.0044\n",
            "Epoch 193/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.1476e-04\n",
            "Epoch 193: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.1239e-04 - val_loss: 0.0011\n",
            "Epoch 194/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.7216e-04\n",
            "Epoch 194: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7022e-04 - val_loss: 0.0027\n",
            "Epoch 195/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.6139e-04\n",
            "Epoch 195: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.6306e-04 - val_loss: 0.0039\n",
            "Epoch 196/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.7892e-04\n",
            "Epoch 196: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.7739e-04 - val_loss: 0.0019\n",
            "Epoch 197/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.6719e-04\n",
            "Epoch 197: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6719e-04 - val_loss: 0.0031\n",
            "Epoch 198/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.0159e-04\n",
            "Epoch 198: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.0185e-04 - val_loss: 0.0079\n",
            "Epoch 199/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.9574e-04\n",
            "Epoch 199: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9574e-04 - val_loss: 0.0021\n",
            "Epoch 200/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.8631e-04\n",
            "Epoch 200: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.8381e-04 - val_loss: 0.0053\n",
            "Epoch 201/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.6889e-04\n",
            "Epoch 201: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.6266e-04 - val_loss: 3.8536e-04\n",
            "Epoch 202/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.7023e-04\n",
            "Epoch 202: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7023e-04 - val_loss: 0.0012\n",
            "Epoch 203/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.2350e-04\n",
            "Epoch 203: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.1921e-04 - val_loss: 0.0012\n",
            "Epoch 204/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.7021e-04\n",
            "Epoch 204: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.6861e-04 - val_loss: 0.0025\n",
            "Epoch 205/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.4725e-04\n",
            "Epoch 205: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.4301e-04 - val_loss: 0.0029\n",
            "Epoch 206/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.7567e-04\n",
            "Epoch 206: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.7472e-04 - val_loss: 9.4816e-04\n",
            "Epoch 207/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.3006e-04\n",
            "Epoch 207: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2937e-04 - val_loss: 0.0038\n",
            "Epoch 208/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.1117e-04\n",
            "Epoch 208: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.0337e-04 - val_loss: 0.0029\n",
            "Epoch 209/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.3717e-04\n",
            "Epoch 209: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3717e-04 - val_loss: 0.0020\n",
            "Epoch 210/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.2173e-04\n",
            "Epoch 210: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.2423e-04 - val_loss: 0.0038\n",
            "Epoch 211/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.7942e-04\n",
            "Epoch 211: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.9709e-04 - val_loss: 0.0038\n",
            "Epoch 212/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.6383e-04\n",
            "Epoch 212: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6559e-04 - val_loss: 0.0049\n",
            "Epoch 213/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.2559e-04\n",
            "Epoch 213: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.2210e-04 - val_loss: 0.0021\n",
            "Epoch 214/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.9191e-04\n",
            "Epoch 214: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.0292e-04 - val_loss: 9.5449e-04\n",
            "Epoch 215/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.7753e-04\n",
            "Epoch 215: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.7673e-04 - val_loss: 0.0053\n",
            "Epoch 216/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.6492e-04\n",
            "Epoch 216: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6492e-04 - val_loss: 0.0015\n",
            "Epoch 217/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.0621e-04\n",
            "Epoch 217: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.0122e-04 - val_loss: 0.0036\n",
            "Epoch 218/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.3870e-04\n",
            "Epoch 218: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.3356e-04 - val_loss: 0.0067\n",
            "Epoch 219/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.9779e-04\n",
            "Epoch 219: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9779e-04 - val_loss: 0.0029\n",
            "Epoch 220/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.5259e-04\n",
            "Epoch 220: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.5259e-04 - val_loss: 0.0053\n",
            "Epoch 221/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.4676e-04\n",
            "Epoch 221: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4967e-04 - val_loss: 0.0049\n",
            "Epoch 222/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6511e-04\n",
            "Epoch 222: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6309e-04 - val_loss: 0.0050\n",
            "Epoch 223/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.8720e-04\n",
            "Epoch 223: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.8720e-04 - val_loss: 0.0014\n",
            "Epoch 224/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.5050e-04\n",
            "Epoch 224: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.5050e-04 - val_loss: 0.0031\n",
            "Epoch 225/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.4533e-04\n",
            "Epoch 225: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5224e-04 - val_loss: 0.0019\n",
            "Epoch 226/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.5856e-04\n",
            "Epoch 226: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.5392e-04 - val_loss: 0.0036\n",
            "Epoch 227/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.7447e-04\n",
            "Epoch 227: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.7190e-04 - val_loss: 0.0048\n",
            "Epoch 228/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.0891e-04\n",
            "Epoch 228: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.0885e-04 - val_loss: 0.0022\n",
            "Epoch 229/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.3159e-04\n",
            "Epoch 229: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3368e-04 - val_loss: 0.0026\n",
            "Epoch 230/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6041e-04\n",
            "Epoch 230: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5837e-04 - val_loss: 0.0041\n",
            "Epoch 231/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.4860e-04\n",
            "Epoch 231: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4004e-04 - val_loss: 0.0015\n",
            "Epoch 232/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.5476e-04\n",
            "Epoch 232: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4969e-04 - val_loss: 0.0065\n",
            "Epoch 233/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.4290e-04\n",
            "Epoch 233: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4262e-04 - val_loss: 0.0042\n",
            "Epoch 234/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.4972e-04\n",
            "Epoch 234: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.5169e-04 - val_loss: 0.0028\n",
            "Epoch 235/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.2103e-04\n",
            "Epoch 235: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.2727e-04 - val_loss: 0.0023\n",
            "Epoch 236/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.8344e-04\n",
            "Epoch 236: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7845e-04 - val_loss: 0.0049\n",
            "Epoch 237/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.1966e-04\n",
            "Epoch 237: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.1760e-04 - val_loss: 0.0012\n",
            "Epoch 238/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.2054e-04\n",
            "Epoch 238: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2054e-04 - val_loss: 0.0037\n",
            "Epoch 239/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6567e-04\n",
            "Epoch 239: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.6508e-04 - val_loss: 0.0030\n",
            "Epoch 240/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.5849e-04\n",
            "Epoch 240: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.5762e-04 - val_loss: 0.0030\n",
            "Epoch 241/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.6578e-04\n",
            "Epoch 241: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.6413e-04 - val_loss: 0.0033\n",
            "Epoch 242/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.9381e-04\n",
            "Epoch 242: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.9226e-04 - val_loss: 0.0056\n",
            "Epoch 243/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.5346e-04\n",
            "Epoch 243: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5682e-04 - val_loss: 0.0042\n",
            "Epoch 244/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.4425e-04\n",
            "Epoch 244: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.4762e-04 - val_loss: 0.0026\n",
            "Epoch 245/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.5134e-04\n",
            "Epoch 245: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.5134e-04 - val_loss: 0.0036\n",
            "Epoch 246/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.8269e-04\n",
            "Epoch 246: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.8269e-04 - val_loss: 0.0028\n",
            "Epoch 247/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.2373e-04\n",
            "Epoch 247: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2919e-04 - val_loss: 0.0034\n",
            "Epoch 248/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.2941e-04\n",
            "Epoch 248: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 4.3141e-04 - val_loss: 0.0023\n",
            "Epoch 249/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.8355e-04\n",
            "Epoch 249: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.8759e-04 - val_loss: 0.0049\n",
            "Epoch 250/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.9385e-04\n",
            "Epoch 250: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.8693e-04 - val_loss: 0.0055\n",
            "Epoch 251/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.7484e-04\n",
            "Epoch 251: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7484e-04 - val_loss: 0.0015\n",
            "Epoch 252/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.6746e-04\n",
            "Epoch 252: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6131e-04 - val_loss: 0.0025\n",
            "Epoch 253/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.4671e-04\n",
            "Epoch 253: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4386e-04 - val_loss: 0.0034\n",
            "Epoch 254/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.3192e-04\n",
            "Epoch 254: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.3301e-04 - val_loss: 0.0044\n",
            "Epoch 255/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.7136e-04\n",
            "Epoch 255: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7259e-04 - val_loss: 0.0067\n",
            "Epoch 256/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.5604e-04\n",
            "Epoch 256: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.5519e-04 - val_loss: 0.0062\n",
            "Epoch 257/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.7636e-04\n",
            "Epoch 257: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7747e-04 - val_loss: 0.0058\n",
            "Epoch 258/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.4513e-04\n",
            "Epoch 258: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4577e-04 - val_loss: 0.0051\n",
            "Epoch 259/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.7288e-04\n",
            "Epoch 259: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7288e-04 - val_loss: 0.0057\n",
            "Epoch 260/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6111e-04\n",
            "Epoch 260: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.5707e-04 - val_loss: 0.0047\n",
            "Epoch 261/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.9623e-04\n",
            "Epoch 261: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.9073e-04 - val_loss: 0.0062\n",
            "Epoch 262/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.5596e-04\n",
            "Epoch 262: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.5258e-04 - val_loss: 0.0025\n",
            "Epoch 263/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.6278e-04\n",
            "Epoch 263: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.6094e-04 - val_loss: 0.0047\n",
            "Epoch 264/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.4232e-04\n",
            "Epoch 264: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.4420e-04 - val_loss: 0.0023\n",
            "Epoch 265/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.7424e-04\n",
            "Epoch 265: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.7358e-04 - val_loss: 0.0036\n",
            "Epoch 266/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.6593e-04\n",
            "Epoch 266: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.6395e-04 - val_loss: 0.0028\n",
            "Epoch 267/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.5462e-04\n",
            "Epoch 267: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.5244e-04 - val_loss: 0.0012\n",
            "Epoch 268/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6314e-04\n",
            "Epoch 268: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5771e-04 - val_loss: 0.0021\n",
            "Epoch 269/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.3795e-04\n",
            "Epoch 269: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.3124e-04 - val_loss: 0.0041\n",
            "Epoch 270/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.3907e-04\n",
            "Epoch 270: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4355e-04 - val_loss: 8.1970e-04\n",
            "Epoch 271/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.3587e-04\n",
            "Epoch 271: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3639e-04 - val_loss: 0.0046\n",
            "Epoch 272/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.8757e-04\n",
            "Epoch 272: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9178e-04 - val_loss: 0.0016\n",
            "Epoch 273/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.8716e-04\n",
            "Epoch 273: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.8407e-04 - val_loss: 0.0048\n",
            "Epoch 274/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.4899e-04\n",
            "Epoch 274: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5355e-04 - val_loss: 0.0050\n",
            "Epoch 275/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.9220e-04\n",
            "Epoch 275: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.8652e-04 - val_loss: 0.0025\n",
            "Epoch 276/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.7625e-04\n",
            "Epoch 276: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.7531e-04 - val_loss: 5.5638e-04\n",
            "Epoch 277/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.9525e-04\n",
            "Epoch 277: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9525e-04 - val_loss: 0.0025\n",
            "Epoch 278/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.5868e-04\n",
            "Epoch 278: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5875e-04 - val_loss: 0.0039\n",
            "Epoch 279/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.8432e-04\n",
            "Epoch 279: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7395e-04 - val_loss: 0.0041\n",
            "Epoch 280/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.9125e-04\n",
            "Epoch 280: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9969e-04 - val_loss: 0.0026\n",
            "Epoch 281/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.8136e-04\n",
            "Epoch 281: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 23ms/step - loss: 3.8136e-04 - val_loss: 0.0054\n",
            "Epoch 282/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.5245e-04\n",
            "Epoch 282: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5069e-04 - val_loss: 0.0056\n",
            "Epoch 283/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.2503e-04\n",
            "Epoch 283: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.2503e-04 - val_loss: 0.0055\n",
            "Epoch 284/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.8551e-04\n",
            "Epoch 284: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.7942e-04 - val_loss: 0.0033\n",
            "Epoch 285/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.9749e-04\n",
            "Epoch 285: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.9561e-04 - val_loss: 0.0039\n",
            "Epoch 286/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.6768e-04\n",
            "Epoch 286: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.6768e-04 - val_loss: 0.0055\n",
            "Epoch 287/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.4460e-04\n",
            "Epoch 287: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4460e-04 - val_loss: 0.0030\n",
            "Epoch 288/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.2100e-04\n",
            "Epoch 288: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.2172e-04 - val_loss: 0.0038\n",
            "Epoch 289/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.9839e-04\n",
            "Epoch 289: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.9206e-04 - val_loss: 0.0033\n",
            "Epoch 290/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.2787e-04\n",
            "Epoch 290: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2976e-04 - val_loss: 0.0040\n",
            "Epoch 291/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.4877e-04\n",
            "Epoch 291: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4314e-04 - val_loss: 0.0029\n",
            "Epoch 292/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.6993e-04\n",
            "Epoch 292: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7390e-04 - val_loss: 0.0028\n",
            "Epoch 293/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.3870e-04\n",
            "Epoch 293: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3899e-04 - val_loss: 0.0047\n",
            "Epoch 294/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.4977e-04\n",
            "Epoch 294: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.5997e-04 - val_loss: 0.0033\n",
            "Epoch 295/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.2766e-04\n",
            "Epoch 295: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3254e-04 - val_loss: 0.0030\n",
            "Epoch 296/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.3725e-04\n",
            "Epoch 296: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4976e-04 - val_loss: 0.0042\n",
            "Epoch 297/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.6816e-04\n",
            "Epoch 297: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6725e-04 - val_loss: 0.0041\n",
            "Epoch 298/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.2561e-04\n",
            "Epoch 298: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.2375e-04 - val_loss: 0.0053\n",
            "Epoch 299/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.3648e-04\n",
            "Epoch 299: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3115e-04 - val_loss: 0.0060\n",
            "Epoch 300/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.0906e-04\n",
            "Epoch 300: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.0288e-04 - val_loss: 0.0096\n",
            "Epoch 301/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6273e-04\n",
            "Epoch 301: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.6193e-04 - val_loss: 0.0036\n",
            "Epoch 302/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.5345e-04\n",
            "Epoch 302: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.4748e-04 - val_loss: 0.0056\n",
            "Epoch 303/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.5832e-04\n",
            "Epoch 303: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5832e-04 - val_loss: 0.0074\n",
            "Epoch 304/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.2833e-04\n",
            "Epoch 304: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.2577e-04 - val_loss: 0.0041\n",
            "Epoch 305/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.3005e-04\n",
            "Epoch 305: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.3352e-04 - val_loss: 0.0041\n",
            "Epoch 306/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.4125e-04\n",
            "Epoch 306: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3963e-04 - val_loss: 0.0024\n",
            "Epoch 307/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.6722e-04\n",
            "Epoch 307: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6544e-04 - val_loss: 0.0048\n",
            "Epoch 308/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.6081e-04\n",
            "Epoch 308: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6071e-04 - val_loss: 0.0048\n",
            "Epoch 309/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.7914e-04\n",
            "Epoch 309: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.7909e-04 - val_loss: 0.0046\n",
            "Epoch 310/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.4493e-04\n",
            "Epoch 310: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.4368e-04 - val_loss: 0.0012\n",
            "Epoch 311/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.1870e-04\n",
            "Epoch 311: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1702e-04 - val_loss: 0.0058\n",
            "Epoch 312/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 2.9083e-04\n",
            "Epoch 312: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.9416e-04 - val_loss: 0.0044\n",
            "Epoch 313/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.8977e-04\n",
            "Epoch 313: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.9962e-04 - val_loss: 0.0051\n",
            "Epoch 314/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.1517e-04\n",
            "Epoch 314: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.1517e-04 - val_loss: 0.0058\n",
            "Epoch 315/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.3628e-04\n",
            "Epoch 315: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.4445e-04 - val_loss: 0.0038\n",
            "Epoch 316/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.9651e-04\n",
            "Epoch 316: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.9651e-04 - val_loss: 0.0045\n",
            "Epoch 317/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.8461e-04\n",
            "Epoch 317: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.8461e-04 - val_loss: 0.0066\n",
            "Epoch 318/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.6218e-04\n",
            "Epoch 318: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5718e-04 - val_loss: 0.0031\n",
            "Epoch 319/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.8056e-04\n",
            "Epoch 319: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7823e-04 - val_loss: 0.0015\n",
            "Epoch 320/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.6865e-04\n",
            "Epoch 320: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6865e-04 - val_loss: 0.0073\n",
            "Epoch 321/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.5260e-04\n",
            "Epoch 321: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.5260e-04 - val_loss: 0.0034\n",
            "Epoch 322/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.5242e-04\n",
            "Epoch 322: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.4777e-04 - val_loss: 0.0020\n",
            "Epoch 323/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.9688e-04\n",
            "Epoch 323: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.9554e-04 - val_loss: 0.0059\n",
            "Epoch 324/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.2412e-04\n",
            "Epoch 324: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.2359e-04 - val_loss: 0.0042\n",
            "Epoch 325/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.0504e-04\n",
            "Epoch 325: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0504e-04 - val_loss: 0.0025\n",
            "Epoch 326/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.0751e-04\n",
            "Epoch 326: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1149e-04 - val_loss: 0.0063\n",
            "Epoch 327/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.2050e-04\n",
            "Epoch 327: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1584e-04 - val_loss: 0.0050\n",
            "Epoch 328/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.1353e-04\n",
            "Epoch 328: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1760e-04 - val_loss: 0.0039\n",
            "Epoch 329/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.4314e-04\n",
            "Epoch 329: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4153e-04 - val_loss: 0.0015\n",
            "Epoch 330/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.6113e-04\n",
            "Epoch 330: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.5963e-04 - val_loss: 0.0024\n",
            "Epoch 331/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.7499e-04\n",
            "Epoch 331: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.7218e-04 - val_loss: 0.0052\n",
            "Epoch 332/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 2.9600e-04\n",
            "Epoch 332: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.9472e-04 - val_loss: 0.0019\n",
            "Epoch 333/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.3856e-04\n",
            "Epoch 333: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3613e-04 - val_loss: 0.0054\n",
            "Epoch 334/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.4116e-04\n",
            "Epoch 334: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3894e-04 - val_loss: 0.0042\n",
            "Epoch 335/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.3992e-04\n",
            "Epoch 335: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3903e-04 - val_loss: 0.0077\n",
            "Epoch 336/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.1039e-04\n",
            "Epoch 336: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.1488e-04 - val_loss: 0.0041\n",
            "Epoch 337/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.2238e-04\n",
            "Epoch 337: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.2000e-04 - val_loss: 0.0034\n",
            "Epoch 338/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.1507e-04\n",
            "Epoch 338: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.2225e-04 - val_loss: 0.0076\n",
            "Epoch 339/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.5550e-04\n",
            "Epoch 339: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5550e-04 - val_loss: 0.0073\n",
            "Epoch 340/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.3871e-04\n",
            "Epoch 340: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.3871e-04 - val_loss: 0.0045\n",
            "Epoch 341/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.1734e-04\n",
            "Epoch 341: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.1585e-04 - val_loss: 0.0029\n",
            "Epoch 342/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.5550e-04\n",
            "Epoch 342: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.5410e-04 - val_loss: 0.0048\n",
            "Epoch 343/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.0575e-04\n",
            "Epoch 343: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.0489e-04 - val_loss: 0.0043\n",
            "Epoch 344/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.4924e-04\n",
            "Epoch 344: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.4752e-04 - val_loss: 0.0044\n",
            "Epoch 345/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 2.9636e-04\n",
            "Epoch 345: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.9781e-04 - val_loss: 0.0062\n",
            "Epoch 346/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 2.8966e-04\n",
            "Epoch 346: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.9576e-04 - val_loss: 0.0071\n",
            "Epoch 347/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.4746e-04\n",
            "Epoch 347: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.4746e-04 - val_loss: 0.0031\n",
            "Epoch 348/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.3478e-04\n",
            "Epoch 348: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3948e-04 - val_loss: 0.0056\n",
            "Epoch 349/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.1650e-04\n",
            "Epoch 349: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1549e-04 - val_loss: 0.0034\n",
            "Epoch 350/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.0450e-04\n",
            "Epoch 350: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0517e-04 - val_loss: 0.0074\n",
            "Epoch 351/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.3537e-04\n",
            "Epoch 351: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3537e-04 - val_loss: 0.0044\n",
            "Epoch 352/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.8875e-04\n",
            "Epoch 352: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.8641e-04 - val_loss: 0.0017\n",
            "Epoch 353/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.1732e-04\n",
            "Epoch 353: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1799e-04 - val_loss: 0.0034\n",
            "Epoch 354/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.3213e-04\n",
            "Epoch 354: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2604e-04 - val_loss: 0.0043\n",
            "Epoch 355/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.4060e-04\n",
            "Epoch 355: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4060e-04 - val_loss: 0.0061\n",
            "Epoch 356/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.4913e-04\n",
            "Epoch 356: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5407e-04 - val_loss: 0.0022\n",
            "Epoch 357/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 2.9673e-04\n",
            "Epoch 357: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 2.9283e-04 - val_loss: 0.0052\n",
            "Epoch 358/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.4544e-04\n",
            "Epoch 358: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.4223e-04 - val_loss: 0.0048\n",
            "Epoch 359/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.2534e-04\n",
            "Epoch 359: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.2457e-04 - val_loss: 0.0053\n",
            "Epoch 360/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.1470e-04\n",
            "Epoch 360: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.1357e-04 - val_loss: 0.0061\n",
            "Epoch 361/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 2.9423e-04\n",
            "Epoch 361: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 2.9353e-04 - val_loss: 0.0042\n",
            "Epoch 362/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.4116e-04\n",
            "Epoch 362: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.4261e-04 - val_loss: 0.0045\n",
            "Epoch 363/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.0208e-04\n",
            "Epoch 363: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0332e-04 - val_loss: 0.0065\n",
            "Epoch 364/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.4981e-04\n",
            "Epoch 364: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4824e-04 - val_loss: 0.0086\n",
            "Epoch 365/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.0016e-04\n",
            "Epoch 365: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.9786e-04 - val_loss: 0.0093\n",
            "Epoch 366/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.0971e-04\n",
            "Epoch 366: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.1493e-04 - val_loss: 0.0076\n",
            "Epoch 367/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.0013e-04\n",
            "Epoch 367: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0512e-04 - val_loss: 0.0135\n",
            "Epoch 368/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.3961e-04\n",
            "Epoch 368: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3651e-04 - val_loss: 0.0041\n",
            "Epoch 369/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.5089e-04\n",
            "Epoch 369: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4666e-04 - val_loss: 0.0087\n",
            "Epoch 370/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.6559e-04\n",
            "Epoch 370: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.6559e-04 - val_loss: 0.0065\n",
            "Epoch 371/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.0336e-04\n",
            "Epoch 371: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.0190e-04 - val_loss: 0.0036\n",
            "Epoch 372/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.5189e-04\n",
            "Epoch 372: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5120e-04 - val_loss: 0.0069\n",
            "Epoch 373/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 2.8364e-04\n",
            "Epoch 373: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 2.8425e-04 - val_loss: 0.0030\n",
            "Epoch 374/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.5476e-04\n",
            "Epoch 374: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5197e-04 - val_loss: 0.0069\n",
            "Epoch 375/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.5312e-04\n",
            "Epoch 375: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.5312e-04 - val_loss: 0.0059\n",
            "Epoch 376/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.2117e-04\n",
            "Epoch 376: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.1010e-04 - val_loss: 0.0051\n",
            "Epoch 377/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.5617e-04\n",
            "Epoch 377: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.5649e-04 - val_loss: 0.0067\n",
            "Epoch 378/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.2205e-04\n",
            "Epoch 378: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 4.2132e-04 - val_loss: 0.0018\n",
            "Epoch 379/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.0842e-04\n",
            "Epoch 379: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.0842e-04 - val_loss: 0.0047\n",
            "Epoch 380/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.5951e-04\n",
            "Epoch 380: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.5951e-04 - val_loss: 0.0040\n",
            "Epoch 381/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.0343e-04\n",
            "Epoch 381: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.1981e-04 - val_loss: 0.0051\n",
            "Epoch 382/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.8032e-04\n",
            "Epoch 382: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.7900e-04 - val_loss: 0.0101\n",
            "Epoch 383/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.1556e-04\n",
            "Epoch 383: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1473e-04 - val_loss: 0.0032\n",
            "Epoch 384/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 2.8325e-04\n",
            "Epoch 384: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 2.8088e-04 - val_loss: 0.0044\n",
            "Epoch 385/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.1755e-04\n",
            "Epoch 385: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1903e-04 - val_loss: 0.0042\n",
            "Epoch 386/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 2.9433e-04\n",
            "Epoch 386: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 2.9418e-04 - val_loss: 0.0021\n",
            "Epoch 387/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 2.9943e-04\n",
            "Epoch 387: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.9797e-04 - val_loss: 0.0021\n",
            "Epoch 388/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 2.8250e-04\n",
            "Epoch 388: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.8250e-04 - val_loss: 0.0050\n",
            "Epoch 389/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.2538e-04\n",
            "Epoch 389: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.2582e-04 - val_loss: 0.0105\n",
            "Epoch 390/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.4196e-04\n",
            "Epoch 390: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4196e-04 - val_loss: 0.0040\n",
            "Epoch 391/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.0740e-04\n",
            "Epoch 391: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0740e-04 - val_loss: 0.0041\n",
            "Epoch 392/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.2741e-04\n",
            "Epoch 392: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1975e-04 - val_loss: 0.0021\n",
            "Epoch 393/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.1895e-04\n",
            "Epoch 393: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1559e-04 - val_loss: 0.0054\n",
            "Epoch 394/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.3384e-04\n",
            "Epoch 394: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3384e-04 - val_loss: 0.0041\n",
            "Epoch 395/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.2977e-04\n",
            "Epoch 395: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2893e-04 - val_loss: 0.0059\n",
            "Epoch 396/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 2.9930e-04\n",
            "Epoch 396: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.9794e-04 - val_loss: 0.0063\n",
            "Epoch 397/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 2.8318e-04\n",
            "Epoch 397: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.9085e-04 - val_loss: 0.0037\n",
            "Epoch 398/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.7291e-04\n",
            "Epoch 398: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.7291e-04 - val_loss: 0.0056\n",
            "Epoch 399/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.3148e-04\n",
            "Epoch 399: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.3343e-04 - val_loss: 0.0071\n",
            "Epoch 400/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.2386e-04\n",
            "Epoch 400: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.2984e-04 - val_loss: 0.0081\n",
            "Epoch 401/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 2.8171e-04\n",
            "Epoch 401: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.8894e-04 - val_loss: 0.0084\n",
            "Epoch 402/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.1648e-04\n",
            "Epoch 402: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1648e-04 - val_loss: 0.0039\n",
            "Epoch 403/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.1934e-04\n",
            "Epoch 403: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.1702e-04 - val_loss: 0.0080\n",
            "Epoch 404/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.1288e-04\n",
            "Epoch 404: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.1288e-04 - val_loss: 0.0044\n",
            "Epoch 405/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.0237e-04\n",
            "Epoch 405: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0214e-04 - val_loss: 0.0050\n",
            "Epoch 406/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.7488e-04\n",
            "Epoch 406: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.7488e-04 - val_loss: 0.0014\n",
            "Epoch 407/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.5606e-04\n",
            "Epoch 407: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4902e-04 - val_loss: 0.0078\n",
            "Epoch 408/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 2.9840e-04\n",
            "Epoch 408: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.9736e-04 - val_loss: 0.0034\n",
            "Epoch 409/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.2542e-04\n",
            "Epoch 409: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2727e-04 - val_loss: 0.0046\n",
            "Epoch 410/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 2.9852e-04\n",
            "Epoch 410: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 2.9852e-04 - val_loss: 0.0022\n",
            "Epoch 411/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.1191e-04\n",
            "Epoch 411: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1163e-04 - val_loss: 0.0050\n",
            "Epoch 412/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.2494e-04\n",
            "Epoch 412: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2301e-04 - val_loss: 0.0015\n",
            "Epoch 413/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.1832e-04\n",
            "Epoch 413: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.1694e-04 - val_loss: 0.0085\n",
            "Epoch 414/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.1442e-04\n",
            "Epoch 414: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1291e-04 - val_loss: 0.0037\n",
            "Epoch 415/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.0779e-04\n",
            "Epoch 415: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.1199e-04 - val_loss: 0.0094\n",
            "Epoch 416/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.4034e-04\n",
            "Epoch 416: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.3832e-04 - val_loss: 0.0040\n",
            "Epoch 417/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.5409e-04\n",
            "Epoch 417: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.5379e-04 - val_loss: 0.0067\n",
            "Epoch 418/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.3232e-04\n",
            "Epoch 418: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.3235e-04 - val_loss: 0.0027\n",
            "Epoch 419/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.0051e-04\n",
            "Epoch 419: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.0229e-04 - val_loss: 0.0037\n",
            "Epoch 420/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.3999e-04\n",
            "Epoch 420: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3850e-04 - val_loss: 0.0078\n",
            "Epoch 421/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.3932e-04\n",
            "Epoch 421: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3880e-04 - val_loss: 0.0044\n",
            "Epoch 422/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.3757e-04\n",
            "Epoch 422: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3888e-04 - val_loss: 0.0033\n",
            "Epoch 423/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.2215e-04\n",
            "Epoch 423: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2163e-04 - val_loss: 0.0038\n",
            "Epoch 424/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 2.9511e-04\n",
            "Epoch 424: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.9219e-04 - val_loss: 0.0030\n",
            "Epoch 425/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.0813e-04\n",
            "Epoch 425: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.0873e-04 - val_loss: 0.0046\n",
            "Epoch 426/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 2.7825e-04\n",
            "Epoch 426: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 2.7849e-04 - val_loss: 0.0041\n",
            "Epoch 427/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.0999e-04\n",
            "Epoch 427: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.0441e-04 - val_loss: 0.0050\n",
            "Epoch 428/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 2.7135e-04\n",
            "Epoch 428: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.6880e-04 - val_loss: 0.0021\n",
            "Epoch 429/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.0040e-04\n",
            "Epoch 429: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.0139e-04 - val_loss: 0.0039\n",
            "Epoch 430/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 2.7563e-04\n",
            "Epoch 430: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 2.8081e-04 - val_loss: 0.0054\n",
            "Epoch 431/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 2.9746e-04\n",
            "Epoch 431: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 24ms/step - loss: 3.0511e-04 - val_loss: 0.0078\n",
            "Epoch 432/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.6379e-04\n",
            "Epoch 432: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.6479e-04 - val_loss: 0.0039\n",
            "Epoch 433/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.2046e-04\n",
            "Epoch 433: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.1814e-04 - val_loss: 0.0052\n",
            "Epoch 434/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.0800e-04\n",
            "Epoch 434: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.0435e-04 - val_loss: 0.0034\n",
            "Epoch 435/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.2373e-04\n",
            "Epoch 435: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 3.2373e-04 - val_loss: 0.0048\n",
            "Epoch 436/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.3350e-04\n",
            "Epoch 436: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.2835e-04 - val_loss: 0.0098\n",
            "Epoch 437/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 2.8489e-04\n",
            "Epoch 437: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 2.8436e-04 - val_loss: 0.0041\n",
            "Epoch 438/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 2.9493e-04\n",
            "Epoch 438: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 2.9126e-04 - val_loss: 0.0052\n",
            "Epoch 439/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 2.9304e-04\n",
            "Epoch 439: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.9304e-04 - val_loss: 0.0066\n",
            "Epoch 440/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.0002e-04\n",
            "Epoch 440: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0308e-04 - val_loss: 0.0035\n",
            "Epoch 441/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 2.8531e-04\n",
            "Epoch 441: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.8531e-04 - val_loss: 0.0039\n",
            "Epoch 442/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.0007e-04\n",
            "Epoch 442: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0438e-04 - val_loss: 0.0049\n",
            "Epoch 443/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.4207e-04\n",
            "Epoch 443: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4123e-04 - val_loss: 0.0070\n",
            "Epoch 444/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.1196e-04\n",
            "Epoch 444: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1720e-04 - val_loss: 0.0031\n",
            "Epoch 445/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 2.9004e-04\n",
            "Epoch 445: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 2.9004e-04 - val_loss: 0.0044\n",
            "Epoch 446/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.2686e-04\n",
            "Epoch 446: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2895e-04 - val_loss: 0.0078\n",
            "Epoch 447/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.1232e-04\n",
            "Epoch 447: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.1191e-04 - val_loss: 0.0038\n",
            "Epoch 448/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 2.8670e-04\n",
            "Epoch 448: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.8185e-04 - val_loss: 0.0067\n",
            "Epoch 449/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.1280e-04\n",
            "Epoch 449: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1280e-04 - val_loss: 0.0081\n",
            "Epoch 450/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 2.9609e-04\n",
            "Epoch 450: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.9370e-04 - val_loss: 0.0046\n",
            "Epoch 451/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6133e-04\n",
            "Epoch 451: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.6259e-04 - val_loss: 0.0115\n",
            "Epoch 452/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.6813e-04\n",
            "Epoch 452: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.6722e-04 - val_loss: 0.0053\n",
            "Epoch 453/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.0415e-04\n",
            "Epoch 453: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.0557e-04 - val_loss: 0.0037\n",
            "Epoch 454/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.2896e-04\n",
            "Epoch 454: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.2820e-04 - val_loss: 0.0072\n",
            "Epoch 455/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.3714e-04\n",
            "Epoch 455: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.3125e-04 - val_loss: 0.0098\n",
            "Epoch 456/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.2061e-04\n",
            "Epoch 456: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2061e-04 - val_loss: 0.0080\n",
            "Epoch 457/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6972e-04\n",
            "Epoch 457: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.7019e-04 - val_loss: 0.0051\n",
            "Epoch 458/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.1484e-04\n",
            "Epoch 458: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1353e-04 - val_loss: 0.0111\n",
            "Epoch 459/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 2.6694e-04\n",
            "Epoch 459: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.6959e-04 - val_loss: 0.0025\n",
            "Epoch 460/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 2.7415e-04\n",
            "Epoch 460: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.7773e-04 - val_loss: 0.0078\n",
            "Epoch 461/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.0045e-04\n",
            "Epoch 461: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0140e-04 - val_loss: 0.0088\n",
            "Epoch 462/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.2089e-04\n",
            "Epoch 462: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2025e-04 - val_loss: 0.0036\n",
            "Epoch 463/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.0285e-04\n",
            "Epoch 463: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0406e-04 - val_loss: 0.0084\n",
            "Epoch 464/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.0519e-04\n",
            "Epoch 464: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0519e-04 - val_loss: 0.0062\n",
            "Epoch 465/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 2.8174e-04\n",
            "Epoch 465: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 2.8218e-04 - val_loss: 0.0077\n",
            "Epoch 466/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.2395e-04\n",
            "Epoch 466: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3302e-04 - val_loss: 0.0022\n",
            "Epoch 467/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.0807e-04\n",
            "Epoch 467: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0697e-04 - val_loss: 0.0039\n",
            "Epoch 468/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.0336e-04\n",
            "Epoch 468: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0398e-04 - val_loss: 0.0065\n",
            "Epoch 469/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.2062e-04\n",
            "Epoch 469: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1921e-04 - val_loss: 0.0042\n",
            "Epoch 470/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.2287e-04\n",
            "Epoch 470: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.2541e-04 - val_loss: 0.0048\n",
            "Epoch 471/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.1019e-04\n",
            "Epoch 471: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.0956e-04 - val_loss: 0.0048\n",
            "Epoch 472/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 2.7541e-04\n",
            "Epoch 472: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.7479e-04 - val_loss: 0.0035\n",
            "Epoch 473/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 2.6220e-04\n",
            "Epoch 473: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 2.6220e-04 - val_loss: 0.0023\n",
            "Epoch 474/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.4004e-04\n",
            "Epoch 474: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.4582e-04 - val_loss: 0.0080\n",
            "Epoch 475/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.0283e-04\n",
            "Epoch 475: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.0280e-04 - val_loss: 0.0057\n",
            "Epoch 476/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.2183e-04\n",
            "Epoch 476: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1837e-04 - val_loss: 0.0023\n",
            "Epoch 477/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.1163e-04\n",
            "Epoch 477: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2891e-04 - val_loss: 0.0075\n",
            "Epoch 478/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.3521e-04\n",
            "Epoch 478: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3249e-04 - val_loss: 0.0072\n",
            "Epoch 479/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 2.6930e-04\n",
            "Epoch 479: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.6697e-04 - val_loss: 0.0077\n",
            "Epoch 480/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 2.9969e-04\n",
            "Epoch 480: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0240e-04 - val_loss: 0.0057\n",
            "Epoch 481/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.0589e-04\n",
            "Epoch 481: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.0589e-04 - val_loss: 0.0058\n",
            "Epoch 482/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 2.9257e-04\n",
            "Epoch 482: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.8783e-04 - val_loss: 0.0043\n",
            "Epoch 483/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 2.6831e-04\n",
            "Epoch 483: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 2.8000e-04 - val_loss: 0.0034\n",
            "Epoch 484/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.5718e-04\n",
            "Epoch 484: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.5335e-04 - val_loss: 0.0077\n",
            "Epoch 485/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.1221e-04\n",
            "Epoch 485: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0733e-04 - val_loss: 0.0094\n",
            "Epoch 486/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 2.8488e-04\n",
            "Epoch 486: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.8990e-04 - val_loss: 0.0076\n",
            "Epoch 487/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 2.9317e-04\n",
            "Epoch 487: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 2.9189e-04 - val_loss: 0.0099\n",
            "Epoch 488/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.2169e-04\n",
            "Epoch 488: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 3.2057e-04 - val_loss: 0.0043\n",
            "Epoch 489/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 2.6879e-04\n",
            "Epoch 489: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.6834e-04 - val_loss: 0.0054\n",
            "Epoch 490/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 2.9185e-04\n",
            "Epoch 490: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 24ms/step - loss: 2.9185e-04 - val_loss: 0.0071\n",
            "Epoch 491/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 2.9911e-04\n",
            "Epoch 491: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 2.9911e-04 - val_loss: 0.0051\n",
            "Epoch 492/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 2.9927e-04\n",
            "Epoch 492: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.0119e-04 - val_loss: 0.0046\n",
            "Epoch 493/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 2.9853e-04\n",
            "Epoch 493: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.9794e-04 - val_loss: 0.0030\n",
            "Epoch 494/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.3959e-04\n",
            "Epoch 494: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3439e-04 - val_loss: 0.0047\n",
            "Epoch 495/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 2.7257e-04\n",
            "Epoch 495: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.6881e-04 - val_loss: 0.0065\n",
            "Epoch 496/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.0270e-04\n",
            "Epoch 496: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0171e-04 - val_loss: 0.0036\n",
            "Epoch 497/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 2.9005e-04\n",
            "Epoch 497: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.9088e-04 - val_loss: 0.0042\n",
            "Epoch 498/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.0760e-04\n",
            "Epoch 498: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0925e-04 - val_loss: 0.0097\n",
            "Epoch 499/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 2.8251e-04\n",
            "Epoch 499: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 2.8006e-04 - val_loss: 0.0024\n",
            "Epoch 500/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.3462e-04\n",
            "Epoch 500: val_loss did not improve from 0.00032\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.3372e-04 - val_loss: 0.0048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(filepath='best_model_ocl.h5', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
        "\n",
        "# Train the model with ModelCheckpoint callback\n",
        "history_ocl = model_ocl.fit(X_train_ocl, y_train_ocl, epochs=500, batch_size=16, validation_data=(X_test_ocl, y_test_ocl), callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kreNpSY-5ubz",
        "outputId": "101cd079-7e6e-4ef3-c897-70f8209558dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0314\n",
            "Epoch 1: val_loss improved from inf to 0.01163, saving model to best_model_ocl.h5\n",
            "61/61 [==============================] - 3s 17ms/step - loss: 0.0314 - val_loss: 0.0116\n",
            "Epoch 2/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0077\n",
            "Epoch 2: val_loss did not improve from 0.01163\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.0076 - val_loss: 0.0167\n",
            "Epoch 3/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.0054\n",
            "Epoch 3: val_loss improved from 0.01163 to 0.00914, saving model to best_model_ocl.h5\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.0053 - val_loss: 0.0091\n",
            "Epoch 4/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0045\n",
            "Epoch 4: val_loss improved from 0.00914 to 0.00815, saving model to best_model_ocl.h5\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.0044 - val_loss: 0.0082\n",
            "Epoch 5/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.0052\n",
            "Epoch 5: val_loss did not improve from 0.00815\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0051 - val_loss: 0.0118\n",
            "Epoch 6/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0033\n",
            "Epoch 6: val_loss did not improve from 0.00815\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.0033 - val_loss: 0.0122\n",
            "Epoch 7/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0031\n",
            "Epoch 7: val_loss did not improve from 0.00815\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0030 - val_loss: 0.0090\n",
            "Epoch 8/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0027\n",
            "Epoch 8: val_loss did not improve from 0.00815\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.0027 - val_loss: 0.0123\n",
            "Epoch 9/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0026\n",
            "Epoch 9: val_loss did not improve from 0.00815\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 0.0026 - val_loss: 0.0244\n",
            "Epoch 10/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0027\n",
            "Epoch 10: val_loss improved from 0.00815 to 0.00771, saving model to best_model_ocl.h5\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.0027 - val_loss: 0.0077\n",
            "Epoch 11/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0020\n",
            "Epoch 11: val_loss improved from 0.00771 to 0.00492, saving model to best_model_ocl.h5\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0021 - val_loss: 0.0049\n",
            "Epoch 12/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.0022\n",
            "Epoch 12: val_loss did not improve from 0.00492\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.0022 - val_loss: 0.0135\n",
            "Epoch 13/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0019\n",
            "Epoch 13: val_loss did not improve from 0.00492\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.0019 - val_loss: 0.0125\n",
            "Epoch 14/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.0018\n",
            "Epoch 14: val_loss did not improve from 0.00492\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0055\n",
            "Epoch 15/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0018\n",
            "Epoch 15: val_loss did not improve from 0.00492\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0108\n",
            "Epoch 16/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.0015\n",
            "Epoch 16: val_loss did not improve from 0.00492\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0051\n",
            "Epoch 17/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0017\n",
            "Epoch 17: val_loss did not improve from 0.00492\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.0017 - val_loss: 0.0070\n",
            "Epoch 18/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0014\n",
            "Epoch 18: val_loss improved from 0.00492 to 0.00328, saving model to best_model_ocl.h5\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0014 - val_loss: 0.0033\n",
            "Epoch 19/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0014\n",
            "Epoch 19: val_loss did not improve from 0.00328\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0014 - val_loss: 0.0049\n",
            "Epoch 20/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0015\n",
            "Epoch 20: val_loss did not improve from 0.00328\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 0.0015 - val_loss: 0.0051\n",
            "Epoch 21/500\n",
            "54/61 [=========================>....] - ETA: 0s - loss: 0.0014\n",
            "Epoch 21: val_loss did not improve from 0.00328\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0033\n",
            "Epoch 22/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0014\n",
            "Epoch 22: val_loss improved from 0.00328 to 0.00238, saving model to best_model_ocl.h5\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0014 - val_loss: 0.0024\n",
            "Epoch 23/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0015\n",
            "Epoch 23: val_loss did not improve from 0.00238\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.0015 - val_loss: 0.0083\n",
            "Epoch 24/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0016\n",
            "Epoch 24: val_loss did not improve from 0.00238\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.0016 - val_loss: 0.0103\n",
            "Epoch 25/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.0014\n",
            "Epoch 25: val_loss did not improve from 0.00238\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0047\n",
            "Epoch 26/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0014\n",
            "Epoch 26: val_loss improved from 0.00238 to 0.00226, saving model to best_model_ocl.h5\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 0.0014 - val_loss: 0.0023\n",
            "Epoch 27/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0013\n",
            "Epoch 27: val_loss did not improve from 0.00226\n",
            "61/61 [==============================] - 2s 26ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 28/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0011\n",
            "Epoch 28: val_loss did not improve from 0.00226\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.0011 - val_loss: 0.0033\n",
            "Epoch 29/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0012\n",
            "Epoch 29: val_loss did not improve from 0.00226\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.0012 - val_loss: 0.0034\n",
            "Epoch 30/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0011\n",
            "Epoch 30: val_loss improved from 0.00226 to 0.00116, saving model to best_model_ocl.h5\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.0011 - val_loss: 0.0012\n",
            "Epoch 31/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0016\n",
            "Epoch 31: val_loss improved from 0.00116 to 0.00069, saving model to best_model_ocl.h5\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 0.0016 - val_loss: 6.8720e-04\n",
            "Epoch 32/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0013\n",
            "Epoch 32: val_loss did not improve from 0.00069\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 0.0013 - val_loss: 8.6885e-04\n",
            "Epoch 33/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0013\n",
            "Epoch 33: val_loss did not improve from 0.00069\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 0.0013 - val_loss: 0.0014\n",
            "Epoch 34/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0013\n",
            "Epoch 34: val_loss did not improve from 0.00069\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.0013 - val_loss: 0.0081\n",
            "Epoch 35/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0010\n",
            "Epoch 35: val_loss did not improve from 0.00069\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.0010 - val_loss: 0.0015\n",
            "Epoch 36/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0011\n",
            "Epoch 36: val_loss did not improve from 0.00069\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0010\n",
            "Epoch 37/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0011\n",
            "Epoch 37: val_loss did not improve from 0.00069\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0061\n",
            "Epoch 38/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0010\n",
            "Epoch 38: val_loss did not improve from 0.00069\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 39/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0010\n",
            "Epoch 39: val_loss did not improve from 0.00069\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.0010 - val_loss: 0.0018\n",
            "Epoch 40/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 9.7375e-04\n",
            "Epoch 40: val_loss improved from 0.00069 to 0.00066, saving model to best_model_ocl.h5\n",
            "61/61 [==============================] - 1s 23ms/step - loss: 9.7238e-04 - val_loss: 6.6475e-04\n",
            "Epoch 41/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0010\n",
            "Epoch 41: val_loss did not improve from 0.00066\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.0010 - val_loss: 0.0048\n",
            "Epoch 42/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 8.9487e-04\n",
            "Epoch 42: val_loss did not improve from 0.00066\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 8.9487e-04 - val_loss: 0.0017\n",
            "Epoch 43/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 8.5646e-04\n",
            "Epoch 43: val_loss did not improve from 0.00066\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 8.4239e-04 - val_loss: 0.0028\n",
            "Epoch 44/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 8.9119e-04\n",
            "Epoch 44: val_loss did not improve from 0.00066\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 9.0756e-04 - val_loss: 0.0023\n",
            "Epoch 45/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 8.9238e-04\n",
            "Epoch 45: val_loss did not improve from 0.00066\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 9.0253e-04 - val_loss: 0.0033\n",
            "Epoch 46/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 7.4256e-04\n",
            "Epoch 46: val_loss did not improve from 0.00066\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 7.3863e-04 - val_loss: 0.0011\n",
            "Epoch 47/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 9.1102e-04\n",
            "Epoch 47: val_loss did not improve from 0.00066\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 9.0564e-04 - val_loss: 0.0032\n",
            "Epoch 48/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 7.5496e-04\n",
            "Epoch 48: val_loss did not improve from 0.00066\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 7.5123e-04 - val_loss: 0.0013\n",
            "Epoch 49/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 7.7389e-04\n",
            "Epoch 49: val_loss did not improve from 0.00066\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 7.7895e-04 - val_loss: 0.0028\n",
            "Epoch 50/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 7.1473e-04\n",
            "Epoch 50: val_loss did not improve from 0.00066\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 7.0761e-04 - val_loss: 0.0049\n",
            "Epoch 51/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 6.6997e-04\n",
            "Epoch 51: val_loss did not improve from 0.00066\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 6.6997e-04 - val_loss: 0.0020\n",
            "Epoch 52/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 7.0102e-04\n",
            "Epoch 52: val_loss did not improve from 0.00066\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 6.9830e-04 - val_loss: 0.0056\n",
            "Epoch 53/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 7.9812e-04\n",
            "Epoch 53: val_loss did not improve from 0.00066\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 7.9844e-04 - val_loss: 0.0016\n",
            "Epoch 54/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 6.7551e-04\n",
            "Epoch 54: val_loss did not improve from 0.00066\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 6.7665e-04 - val_loss: 0.0019\n",
            "Epoch 55/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 6.1653e-04\n",
            "Epoch 55: val_loss improved from 0.00066 to 0.00045, saving model to best_model_ocl.h5\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 6.2903e-04 - val_loss: 4.4963e-04\n",
            "Epoch 56/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 7.2930e-04\n",
            "Epoch 56: val_loss did not improve from 0.00045\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 7.2863e-04 - val_loss: 0.0029\n",
            "Epoch 57/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 7.1716e-04\n",
            "Epoch 57: val_loss improved from 0.00045 to 0.00041, saving model to best_model_ocl.h5\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 7.1055e-04 - val_loss: 4.1093e-04\n",
            "Epoch 58/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 6.9395e-04\n",
            "Epoch 58: val_loss improved from 0.00041 to 0.00040, saving model to best_model_ocl.h5\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 6.9037e-04 - val_loss: 3.9781e-04\n",
            "Epoch 59/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 6.4306e-04\n",
            "Epoch 59: val_loss did not improve from 0.00040\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 6.5155e-04 - val_loss: 0.0023\n",
            "Epoch 60/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 6.3433e-04\n",
            "Epoch 60: val_loss did not improve from 0.00040\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 6.3474e-04 - val_loss: 0.0026\n",
            "Epoch 61/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 5.9214e-04\n",
            "Epoch 61: val_loss did not improve from 0.00040\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 5.9214e-04 - val_loss: 0.0019\n",
            "Epoch 62/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 7.0684e-04\n",
            "Epoch 62: val_loss did not improve from 0.00040\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 6.9778e-04 - val_loss: 0.0022\n",
            "Epoch 63/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 6.0660e-04\n",
            "Epoch 63: val_loss did not improve from 0.00040\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 6.0561e-04 - val_loss: 0.0016\n",
            "Epoch 64/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 6.7788e-04\n",
            "Epoch 64: val_loss did not improve from 0.00040\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 6.7125e-04 - val_loss: 8.9692e-04\n",
            "Epoch 65/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 5.9677e-04\n",
            "Epoch 65: val_loss did not improve from 0.00040\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 5.9400e-04 - val_loss: 0.0058\n",
            "Epoch 66/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 6.5582e-04\n",
            "Epoch 66: val_loss did not improve from 0.00040\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 6.5315e-04 - val_loss: 8.6940e-04\n",
            "Epoch 67/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 7.6890e-04\n",
            "Epoch 67: val_loss did not improve from 0.00040\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 7.7238e-04 - val_loss: 0.0023\n",
            "Epoch 68/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 6.4507e-04\n",
            "Epoch 68: val_loss did not improve from 0.00040\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 6.4213e-04 - val_loss: 0.0016\n",
            "Epoch 69/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 6.0852e-04\n",
            "Epoch 69: val_loss did not improve from 0.00040\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 6.1519e-04 - val_loss: 0.0018\n",
            "Epoch 70/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 6.4610e-04\n",
            "Epoch 70: val_loss improved from 0.00040 to 0.00036, saving model to best_model_ocl.h5\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 6.3943e-04 - val_loss: 3.6168e-04\n",
            "Epoch 71/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 7.5303e-04\n",
            "Epoch 71: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 7.3385e-04 - val_loss: 0.0047\n",
            "Epoch 72/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 5.8037e-04\n",
            "Epoch 72: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 5.8838e-04 - val_loss: 3.7148e-04\n",
            "Epoch 73/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 5.7747e-04\n",
            "Epoch 73: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 5.6924e-04 - val_loss: 0.0014\n",
            "Epoch 74/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 5.7273e-04\n",
            "Epoch 74: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 5.7700e-04 - val_loss: 7.0250e-04\n",
            "Epoch 75/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 5.8197e-04\n",
            "Epoch 75: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 5.6829e-04 - val_loss: 9.9085e-04\n",
            "Epoch 76/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 6.0324e-04\n",
            "Epoch 76: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 6.0128e-04 - val_loss: 5.5964e-04\n",
            "Epoch 77/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 5.4921e-04\n",
            "Epoch 77: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 5.4700e-04 - val_loss: 3.6831e-04\n",
            "Epoch 78/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 5.5646e-04\n",
            "Epoch 78: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 5.5646e-04 - val_loss: 9.5781e-04\n",
            "Epoch 79/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 5.2422e-04\n",
            "Epoch 79: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 5.2381e-04 - val_loss: 5.5189e-04\n",
            "Epoch 80/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 5.3405e-04\n",
            "Epoch 80: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 5.3807e-04 - val_loss: 3.9934e-04\n",
            "Epoch 81/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 5.8208e-04\n",
            "Epoch 81: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 5.7887e-04 - val_loss: 0.0011\n",
            "Epoch 82/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 5.0321e-04\n",
            "Epoch 82: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 5.0321e-04 - val_loss: 0.0022\n",
            "Epoch 83/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 5.7230e-04\n",
            "Epoch 83: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 5.7520e-04 - val_loss: 0.0011\n",
            "Epoch 84/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 5.3245e-04\n",
            "Epoch 84: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 5.3061e-04 - val_loss: 0.0016\n",
            "Epoch 85/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.7117e-04\n",
            "Epoch 85: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 4.6968e-04 - val_loss: 0.0019\n",
            "Epoch 86/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 5.4220e-04\n",
            "Epoch 86: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 5.4449e-04 - val_loss: 0.0027\n",
            "Epoch 87/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 6.4807e-04\n",
            "Epoch 87: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 6.4807e-04 - val_loss: 7.5014e-04\n",
            "Epoch 88/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 5.3866e-04\n",
            "Epoch 88: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 5.2519e-04 - val_loss: 0.0027\n",
            "Epoch 89/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.5750e-04\n",
            "Epoch 89: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.5880e-04 - val_loss: 0.0031\n",
            "Epoch 90/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.7909e-04\n",
            "Epoch 90: val_loss did not improve from 0.00036\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 4.8391e-04 - val_loss: 0.0010\n",
            "Epoch 91/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 6.1486e-04\n",
            "Epoch 91: val_loss improved from 0.00036 to 0.00030, saving model to best_model_ocl.h5\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 6.1667e-04 - val_loss: 2.9517e-04\n",
            "Epoch 92/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 5.0453e-04\n",
            "Epoch 92: val_loss did not improve from 0.00030\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 5.0804e-04 - val_loss: 5.2932e-04\n",
            "Epoch 93/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.7087e-04\n",
            "Epoch 93: val_loss did not improve from 0.00030\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 4.6980e-04 - val_loss: 6.5361e-04\n",
            "Epoch 94/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 5.7528e-04\n",
            "Epoch 94: val_loss did not improve from 0.00030\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 5.6581e-04 - val_loss: 9.9566e-04\n",
            "Epoch 95/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 4.3833e-04\n",
            "Epoch 95: val_loss improved from 0.00030 to 0.00028, saving model to best_model_ocl.h5\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2603e-04 - val_loss: 2.8391e-04\n",
            "Epoch 96/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 5.4821e-04\n",
            "Epoch 96: val_loss did not improve from 0.00028\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 5.4821e-04 - val_loss: 0.0021\n",
            "Epoch 97/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 4.5153e-04\n",
            "Epoch 97: val_loss did not improve from 0.00028\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.4240e-04 - val_loss: 3.6155e-04\n",
            "Epoch 98/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 5.0290e-04\n",
            "Epoch 98: val_loss did not improve from 0.00028\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 5.0963e-04 - val_loss: 0.0011\n",
            "Epoch 99/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.6595e-04\n",
            "Epoch 99: val_loss did not improve from 0.00028\n",
            "61/61 [==============================] - 2s 30ms/step - loss: 4.6595e-04 - val_loss: 0.0023\n",
            "Epoch 100/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 6.3250e-04\n",
            "Epoch 100: val_loss did not improve from 0.00028\n",
            "61/61 [==============================] - 2s 29ms/step - loss: 6.3086e-04 - val_loss: 0.0019\n",
            "Epoch 101/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.7080e-04\n",
            "Epoch 101: val_loss did not improve from 0.00028\n",
            "61/61 [==============================] - 2s 28ms/step - loss: 4.7080e-04 - val_loss: 2.8489e-04\n",
            "Epoch 102/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 5.0250e-04\n",
            "Epoch 102: val_loss did not improve from 0.00028\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 5.0237e-04 - val_loss: 0.0015\n",
            "Epoch 103/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.3203e-04\n",
            "Epoch 103: val_loss improved from 0.00028 to 0.00027, saving model to best_model_ocl.h5\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 4.3111e-04 - val_loss: 2.6732e-04\n",
            "Epoch 104/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.8373e-04\n",
            "Epoch 104: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 4.8373e-04 - val_loss: 5.1045e-04\n",
            "Epoch 105/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 5.0075e-04\n",
            "Epoch 105: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 5.0075e-04 - val_loss: 2.9096e-04\n",
            "Epoch 106/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.6258e-04\n",
            "Epoch 106: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 4.6258e-04 - val_loss: 2.9707e-04\n",
            "Epoch 107/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 5.0458e-04\n",
            "Epoch 107: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 4.9803e-04 - val_loss: 5.6502e-04\n",
            "Epoch 108/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.7244e-04\n",
            "Epoch 108: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.7509e-04 - val_loss: 2.8779e-04\n",
            "Epoch 109/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 5.6635e-04\n",
            "Epoch 109: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 5.8099e-04 - val_loss: 3.3473e-04\n",
            "Epoch 110/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.5019e-04\n",
            "Epoch 110: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 4.4840e-04 - val_loss: 0.0019\n",
            "Epoch 111/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.9451e-04\n",
            "Epoch 111: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.8931e-04 - val_loss: 0.0018\n",
            "Epoch 112/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.9312e-04\n",
            "Epoch 112: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8945e-04 - val_loss: 3.1352e-04\n",
            "Epoch 113/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 4.4038e-04\n",
            "Epoch 113: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.4956e-04 - val_loss: 0.0027\n",
            "Epoch 114/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.8167e-04\n",
            "Epoch 114: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.8274e-04 - val_loss: 0.0033\n",
            "Epoch 115/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 4.4789e-04\n",
            "Epoch 115: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.4473e-04 - val_loss: 0.0016\n",
            "Epoch 116/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.8237e-04\n",
            "Epoch 116: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.7584e-04 - val_loss: 7.3912e-04\n",
            "Epoch 117/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.2830e-04\n",
            "Epoch 117: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.2830e-04 - val_loss: 2.7087e-04\n",
            "Epoch 118/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 4.3952e-04\n",
            "Epoch 118: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.4193e-04 - val_loss: 2.8426e-04\n",
            "Epoch 119/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.1731e-04\n",
            "Epoch 119: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.1731e-04 - val_loss: 8.6054e-04\n",
            "Epoch 120/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.0846e-04\n",
            "Epoch 120: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 4.0846e-04 - val_loss: 3.4158e-04\n",
            "Epoch 121/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.0048e-04\n",
            "Epoch 121: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.9987e-04 - val_loss: 3.1614e-04\n",
            "Epoch 122/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.1769e-04\n",
            "Epoch 122: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 4.1769e-04 - val_loss: 0.0012\n",
            "Epoch 123/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.7859e-04\n",
            "Epoch 123: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.7731e-04 - val_loss: 5.3705e-04\n",
            "Epoch 124/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.2860e-04\n",
            "Epoch 124: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 4.2860e-04 - val_loss: 5.2936e-04\n",
            "Epoch 125/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.7656e-04\n",
            "Epoch 125: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 4.8165e-04 - val_loss: 0.0018\n",
            "Epoch 126/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 5.6427e-04\n",
            "Epoch 126: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 5.7371e-04 - val_loss: 5.5813e-04\n",
            "Epoch 127/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.6505e-04\n",
            "Epoch 127: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 24ms/step - loss: 4.6505e-04 - val_loss: 0.0011\n",
            "Epoch 128/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.4951e-04\n",
            "Epoch 128: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 23ms/step - loss: 4.4951e-04 - val_loss: 6.6749e-04\n",
            "Epoch 129/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.8145e-04\n",
            "Epoch 129: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 4.7917e-04 - val_loss: 0.0018\n",
            "Epoch 130/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.2017e-04\n",
            "Epoch 130: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 2s 26ms/step - loss: 4.1975e-04 - val_loss: 3.9210e-04\n",
            "Epoch 131/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.1309e-04\n",
            "Epoch 131: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 4.0963e-04 - val_loss: 0.0011\n",
            "Epoch 132/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.2504e-04\n",
            "Epoch 132: val_loss improved from 0.00027 to 0.00027, saving model to best_model_ocl.h5\n",
            "61/61 [==============================] - 1s 23ms/step - loss: 4.1766e-04 - val_loss: 2.6652e-04\n",
            "Epoch 133/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.6032e-04\n",
            "Epoch 133: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 3.6090e-04 - val_loss: 4.4572e-04\n",
            "Epoch 134/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 5.0898e-04\n",
            "Epoch 134: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 5.1023e-04 - val_loss: 9.3167e-04\n",
            "Epoch 135/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.7404e-04\n",
            "Epoch 135: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 3.7355e-04 - val_loss: 0.0020\n",
            "Epoch 136/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.1514e-04\n",
            "Epoch 136: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 22ms/step - loss: 4.1454e-04 - val_loss: 5.8716e-04\n",
            "Epoch 137/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.8534e-04\n",
            "Epoch 137: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 22ms/step - loss: 3.8517e-04 - val_loss: 0.0015\n",
            "Epoch 138/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.3743e-04\n",
            "Epoch 138: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 2s 25ms/step - loss: 4.3743e-04 - val_loss: 7.8047e-04\n",
            "Epoch 139/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 5.9008e-04\n",
            "Epoch 139: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 5.9008e-04 - val_loss: 6.5990e-04\n",
            "Epoch 140/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.3544e-04\n",
            "Epoch 140: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 4.3340e-04 - val_loss: 5.9479e-04\n",
            "Epoch 141/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.0238e-04\n",
            "Epoch 141: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.9702e-04 - val_loss: 9.5045e-04\n",
            "Epoch 142/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 5.1905e-04\n",
            "Epoch 142: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 5.2310e-04 - val_loss: 3.2180e-04\n",
            "Epoch 143/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.8252e-04\n",
            "Epoch 143: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8829e-04 - val_loss: 4.2402e-04\n",
            "Epoch 144/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 6.2777e-04\n",
            "Epoch 144: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 6.1946e-04 - val_loss: 5.5921e-04\n",
            "Epoch 145/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.9551e-04\n",
            "Epoch 145: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.9183e-04 - val_loss: 0.0011\n",
            "Epoch 146/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.5796e-04\n",
            "Epoch 146: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 4.5826e-04 - val_loss: 9.3155e-04\n",
            "Epoch 147/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.3202e-04\n",
            "Epoch 147: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 4.3188e-04 - val_loss: 0.0020\n",
            "Epoch 148/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.2951e-04\n",
            "Epoch 148: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 4.2951e-04 - val_loss: 0.0025\n",
            "Epoch 149/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 5.8717e-04\n",
            "Epoch 149: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 5.7914e-04 - val_loss: 3.4997e-04\n",
            "Epoch 150/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.3912e-04\n",
            "Epoch 150: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.4014e-04 - val_loss: 5.8151e-04\n",
            "Epoch 151/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.4407e-04\n",
            "Epoch 151: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 4.4057e-04 - val_loss: 0.0028\n",
            "Epoch 152/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.9347e-04\n",
            "Epoch 152: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 3.9109e-04 - val_loss: 8.9994e-04\n",
            "Epoch 153/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.8990e-04\n",
            "Epoch 153: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.9116e-04 - val_loss: 5.4615e-04\n",
            "Epoch 154/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.4343e-04\n",
            "Epoch 154: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.4350e-04 - val_loss: 2.8493e-04\n",
            "Epoch 155/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.9582e-04\n",
            "Epoch 155: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.9537e-04 - val_loss: 0.0018\n",
            "Epoch 156/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.7211e-04\n",
            "Epoch 156: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.8619e-04 - val_loss: 0.0017\n",
            "Epoch 157/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.8895e-04\n",
            "Epoch 157: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.8304e-04 - val_loss: 0.0013\n",
            "Epoch 158/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.8468e-04\n",
            "Epoch 158: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.8483e-04 - val_loss: 4.6442e-04\n",
            "Epoch 159/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.0871e-04\n",
            "Epoch 159: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.0304e-04 - val_loss: 3.1955e-04\n",
            "Epoch 160/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.8149e-04\n",
            "Epoch 160: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.8201e-04 - val_loss: 2.9100e-04\n",
            "Epoch 161/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.3216e-04\n",
            "Epoch 161: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.3147e-04 - val_loss: 0.0012\n",
            "Epoch 162/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.0013e-04\n",
            "Epoch 162: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.9950e-04 - val_loss: 0.0028\n",
            "Epoch 163/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.6723e-04\n",
            "Epoch 163: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.6907e-04 - val_loss: 8.0576e-04\n",
            "Epoch 164/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.3235e-04\n",
            "Epoch 164: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.3268e-04 - val_loss: 0.0016\n",
            "Epoch 165/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.5620e-04\n",
            "Epoch 165: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.5441e-04 - val_loss: 2.7782e-04\n",
            "Epoch 166/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.6485e-04\n",
            "Epoch 166: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.6581e-04 - val_loss: 0.0018\n",
            "Epoch 167/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.9802e-04\n",
            "Epoch 167: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9274e-04 - val_loss: 0.0010\n",
            "Epoch 168/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.7071e-04\n",
            "Epoch 168: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7159e-04 - val_loss: 0.0013\n",
            "Epoch 169/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.4519e-04\n",
            "Epoch 169: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.4536e-04 - val_loss: 4.7312e-04\n",
            "Epoch 170/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.7141e-04\n",
            "Epoch 170: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.7141e-04 - val_loss: 8.1028e-04\n",
            "Epoch 171/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.7569e-04\n",
            "Epoch 171: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.7193e-04 - val_loss: 0.0019\n",
            "Epoch 172/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.2875e-04\n",
            "Epoch 172: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2911e-04 - val_loss: 0.0013\n",
            "Epoch 173/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.5995e-04\n",
            "Epoch 173: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6599e-04 - val_loss: 0.0023\n",
            "Epoch 174/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.5774e-04\n",
            "Epoch 174: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.5774e-04 - val_loss: 0.0015\n",
            "Epoch 175/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 5.5069e-04\n",
            "Epoch 175: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 5.3775e-04 - val_loss: 0.0017\n",
            "Epoch 176/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.8984e-04\n",
            "Epoch 176: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.8884e-04 - val_loss: 3.4932e-04\n",
            "Epoch 177/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.5426e-04\n",
            "Epoch 177: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6254e-04 - val_loss: 0.0017\n",
            "Epoch 178/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.4531e-04\n",
            "Epoch 178: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4413e-04 - val_loss: 3.6906e-04\n",
            "Epoch 179/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.1512e-04\n",
            "Epoch 179: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.0581e-04 - val_loss: 0.0027\n",
            "Epoch 180/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.9589e-04\n",
            "Epoch 180: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9439e-04 - val_loss: 0.0064\n",
            "Epoch 181/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.1810e-04\n",
            "Epoch 181: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.2280e-04 - val_loss: 0.0037\n",
            "Epoch 182/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.5724e-04\n",
            "Epoch 182: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.5671e-04 - val_loss: 8.9750e-04\n",
            "Epoch 183/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.1057e-04\n",
            "Epoch 183: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.0951e-04 - val_loss: 0.0026\n",
            "Epoch 184/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.9644e-04\n",
            "Epoch 184: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9635e-04 - val_loss: 3.5967e-04\n",
            "Epoch 185/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.0093e-04\n",
            "Epoch 185: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9087e-04 - val_loss: 4.6745e-04\n",
            "Epoch 186/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.0309e-04\n",
            "Epoch 186: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.0309e-04 - val_loss: 0.0018\n",
            "Epoch 187/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.4658e-04\n",
            "Epoch 187: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.3882e-04 - val_loss: 0.0010\n",
            "Epoch 188/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.9089e-04\n",
            "Epoch 188: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9287e-04 - val_loss: 0.0042\n",
            "Epoch 189/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.0002e-04\n",
            "Epoch 189: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 4.0150e-04 - val_loss: 0.0012\n",
            "Epoch 190/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.5431e-04\n",
            "Epoch 190: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.5455e-04 - val_loss: 0.0016\n",
            "Epoch 191/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.5423e-04\n",
            "Epoch 191: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.5825e-04 - val_loss: 0.0020\n",
            "Epoch 192/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.1337e-04\n",
            "Epoch 192: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.1349e-04 - val_loss: 3.3717e-04\n",
            "Epoch 193/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.8006e-04\n",
            "Epoch 193: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.8432e-04 - val_loss: 0.0040\n",
            "Epoch 194/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.3278e-04\n",
            "Epoch 194: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.2891e-04 - val_loss: 0.0027\n",
            "Epoch 195/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.9853e-04\n",
            "Epoch 195: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.0390e-04 - val_loss: 8.8146e-04\n",
            "Epoch 196/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.0090e-04\n",
            "Epoch 196: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.0105e-04 - val_loss: 0.0012\n",
            "Epoch 197/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.0189e-04\n",
            "Epoch 197: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9150e-04 - val_loss: 0.0024\n",
            "Epoch 198/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.4554e-04\n",
            "Epoch 198: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4584e-04 - val_loss: 0.0049\n",
            "Epoch 199/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.6072e-04\n",
            "Epoch 199: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6411e-04 - val_loss: 0.0043\n",
            "Epoch 200/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.6037e-04\n",
            "Epoch 200: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.6097e-04 - val_loss: 0.0018\n",
            "Epoch 201/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.6535e-04\n",
            "Epoch 201: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7647e-04 - val_loss: 0.0027\n",
            "Epoch 202/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.9325e-04\n",
            "Epoch 202: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.0183e-04 - val_loss: 0.0012\n",
            "Epoch 203/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.0719e-04\n",
            "Epoch 203: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.0747e-04 - val_loss: 0.0017\n",
            "Epoch 204/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.1167e-04\n",
            "Epoch 204: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.3172e-04 - val_loss: 0.0090\n",
            "Epoch 205/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.7102e-04\n",
            "Epoch 205: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.7328e-04 - val_loss: 0.0047\n",
            "Epoch 206/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.9981e-04\n",
            "Epoch 206: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.0708e-04 - val_loss: 0.0014\n",
            "Epoch 207/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.5637e-04\n",
            "Epoch 207: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.5857e-04 - val_loss: 0.0036\n",
            "Epoch 208/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.7088e-04\n",
            "Epoch 208: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.7551e-04 - val_loss: 0.0023\n",
            "Epoch 209/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.7822e-04\n",
            "Epoch 209: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.7718e-04 - val_loss: 0.0035\n",
            "Epoch 210/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.7909e-04\n",
            "Epoch 210: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8596e-04 - val_loss: 0.0034\n",
            "Epoch 211/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.7086e-04\n",
            "Epoch 211: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.7012e-04 - val_loss: 0.0035\n",
            "Epoch 212/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.2852e-04\n",
            "Epoch 212: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.2189e-04 - val_loss: 0.0023\n",
            "Epoch 213/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.8786e-04\n",
            "Epoch 213: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7801e-04 - val_loss: 5.1288e-04\n",
            "Epoch 214/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.4110e-04\n",
            "Epoch 214: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.4956e-04 - val_loss: 0.0015\n",
            "Epoch 215/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.9826e-04\n",
            "Epoch 215: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9826e-04 - val_loss: 0.0013\n",
            "Epoch 216/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.5623e-04\n",
            "Epoch 216: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.5011e-04 - val_loss: 0.0013\n",
            "Epoch 217/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.3709e-04\n",
            "Epoch 217: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.3709e-04 - val_loss: 3.1446e-04\n",
            "Epoch 218/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.4305e-04\n",
            "Epoch 218: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.4027e-04 - val_loss: 0.0047\n",
            "Epoch 219/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.7073e-04\n",
            "Epoch 219: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.6654e-04 - val_loss: 0.0017\n",
            "Epoch 220/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.3048e-04\n",
            "Epoch 220: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3444e-04 - val_loss: 0.0025\n",
            "Epoch 221/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.3695e-04\n",
            "Epoch 221: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3655e-04 - val_loss: 0.0034\n",
            "Epoch 222/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.9376e-04\n",
            "Epoch 222: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9250e-04 - val_loss: 0.0024\n",
            "Epoch 223/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.7212e-04\n",
            "Epoch 223: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7112e-04 - val_loss: 0.0014\n",
            "Epoch 224/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.8981e-04\n",
            "Epoch 224: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.8776e-04 - val_loss: 0.0036\n",
            "Epoch 225/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.8573e-04\n",
            "Epoch 225: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.0309e-04 - val_loss: 0.0025\n",
            "Epoch 226/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.7178e-04\n",
            "Epoch 226: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.8248e-04 - val_loss: 5.8735e-04\n",
            "Epoch 227/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.6673e-04\n",
            "Epoch 227: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.6049e-04 - val_loss: 0.0043\n",
            "Epoch 228/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.3603e-04\n",
            "Epoch 228: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.3204e-04 - val_loss: 5.0427e-04\n",
            "Epoch 229/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.5634e-04\n",
            "Epoch 229: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.5482e-04 - val_loss: 0.0042\n",
            "Epoch 230/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.5691e-04\n",
            "Epoch 230: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.5603e-04 - val_loss: 0.0019\n",
            "Epoch 231/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.6179e-04\n",
            "Epoch 231: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.6283e-04 - val_loss: 0.0020\n",
            "Epoch 232/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.0158e-04\n",
            "Epoch 232: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.0096e-04 - val_loss: 0.0019\n",
            "Epoch 233/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.7780e-04\n",
            "Epoch 233: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.7363e-04 - val_loss: 0.0019\n",
            "Epoch 234/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.6162e-04\n",
            "Epoch 234: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.7042e-04 - val_loss: 0.0029\n",
            "Epoch 235/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.2974e-04\n",
            "Epoch 235: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.2486e-04 - val_loss: 0.0061\n",
            "Epoch 236/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.0067e-04\n",
            "Epoch 236: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9845e-04 - val_loss: 0.0025\n",
            "Epoch 237/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.5304e-04\n",
            "Epoch 237: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4749e-04 - val_loss: 0.0018\n",
            "Epoch 238/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.8023e-04\n",
            "Epoch 238: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.8499e-04 - val_loss: 9.2988e-04\n",
            "Epoch 239/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.0829e-04\n",
            "Epoch 239: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.0829e-04 - val_loss: 0.0019\n",
            "Epoch 240/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.3886e-04\n",
            "Epoch 240: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3886e-04 - val_loss: 0.0041\n",
            "Epoch 241/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.0942e-04\n",
            "Epoch 241: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.1731e-04 - val_loss: 0.0026\n",
            "Epoch 242/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.7083e-04\n",
            "Epoch 242: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7573e-04 - val_loss: 0.0029\n",
            "Epoch 243/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.4455e-04\n",
            "Epoch 243: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4797e-04 - val_loss: 0.0036\n",
            "Epoch 244/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.4471e-04\n",
            "Epoch 244: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4672e-04 - val_loss: 0.0061\n",
            "Epoch 245/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.4714e-04\n",
            "Epoch 245: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5189e-04 - val_loss: 0.0011\n",
            "Epoch 246/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.2043e-04\n",
            "Epoch 246: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.2133e-04 - val_loss: 9.7322e-04\n",
            "Epoch 247/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.2554e-04\n",
            "Epoch 247: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.2680e-04 - val_loss: 7.5811e-04\n",
            "Epoch 248/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.3943e-04\n",
            "Epoch 248: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.3911e-04 - val_loss: 0.0029\n",
            "Epoch 249/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.4238e-04\n",
            "Epoch 249: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.4179e-04 - val_loss: 0.0011\n",
            "Epoch 250/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.4307e-04\n",
            "Epoch 250: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.4240e-04 - val_loss: 0.0083\n",
            "Epoch 251/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.4416e-04\n",
            "Epoch 251: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.4416e-04 - val_loss: 0.0016\n",
            "Epoch 252/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.8657e-04\n",
            "Epoch 252: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.8250e-04 - val_loss: 0.0041\n",
            "Epoch 253/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.1948e-04\n",
            "Epoch 253: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.2270e-04 - val_loss: 0.0022\n",
            "Epoch 254/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.1005e-04\n",
            "Epoch 254: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.1005e-04 - val_loss: 0.0039\n",
            "Epoch 255/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.2449e-04\n",
            "Epoch 255: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.2228e-04 - val_loss: 0.0039\n",
            "Epoch 256/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.2008e-04\n",
            "Epoch 256: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2091e-04 - val_loss: 0.0061\n",
            "Epoch 257/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.4831e-04\n",
            "Epoch 257: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4938e-04 - val_loss: 0.0040\n",
            "Epoch 258/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.4066e-04\n",
            "Epoch 258: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4137e-04 - val_loss: 0.0043\n",
            "Epoch 259/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.0704e-04\n",
            "Epoch 259: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.0398e-04 - val_loss: 0.0074\n",
            "Epoch 260/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.4771e-04\n",
            "Epoch 260: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4666e-04 - val_loss: 0.0021\n",
            "Epoch 261/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.4672e-04\n",
            "Epoch 261: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4757e-04 - val_loss: 0.0070\n",
            "Epoch 262/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.3344e-04\n",
            "Epoch 262: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4094e-04 - val_loss: 0.0038\n",
            "Epoch 263/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.3088e-04\n",
            "Epoch 263: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3347e-04 - val_loss: 0.0038\n",
            "Epoch 264/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.7776e-04\n",
            "Epoch 264: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.7209e-04 - val_loss: 0.0021\n",
            "Epoch 265/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.3918e-04\n",
            "Epoch 265: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4011e-04 - val_loss: 0.0047\n",
            "Epoch 266/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.7248e-04\n",
            "Epoch 266: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7726e-04 - val_loss: 0.0020\n",
            "Epoch 267/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.6521e-04\n",
            "Epoch 267: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 2s 26ms/step - loss: 3.6521e-04 - val_loss: 0.0036\n",
            "Epoch 268/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6587e-04\n",
            "Epoch 268: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6513e-04 - val_loss: 0.0011\n",
            "Epoch 269/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.9116e-04\n",
            "Epoch 269: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.9598e-04 - val_loss: 0.0053\n",
            "Epoch 270/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.8191e-04\n",
            "Epoch 270: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.7937e-04 - val_loss: 0.0075\n",
            "Epoch 271/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.1463e-04\n",
            "Epoch 271: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.1377e-04 - val_loss: 0.0027\n",
            "Epoch 272/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.4849e-04\n",
            "Epoch 272: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5368e-04 - val_loss: 0.0012\n",
            "Epoch 273/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.1319e-04\n",
            "Epoch 273: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.1432e-04 - val_loss: 0.0062\n",
            "Epoch 274/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.6212e-04\n",
            "Epoch 274: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6246e-04 - val_loss: 0.0035\n",
            "Epoch 275/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.5569e-04\n",
            "Epoch 275: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.5389e-04 - val_loss: 0.0080\n",
            "Epoch 276/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.2890e-04\n",
            "Epoch 276: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.2871e-04 - val_loss: 0.0032\n",
            "Epoch 277/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.5130e-04\n",
            "Epoch 277: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6420e-04 - val_loss: 0.0029\n",
            "Epoch 278/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.3415e-04\n",
            "Epoch 278: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4162e-04 - val_loss: 0.0029\n",
            "Epoch 279/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.6544e-04\n",
            "Epoch 279: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6254e-04 - val_loss: 0.0083\n",
            "Epoch 280/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.1396e-04\n",
            "Epoch 280: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.0840e-04 - val_loss: 0.0059\n",
            "Epoch 281/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.2030e-04\n",
            "Epoch 281: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.1664e-04 - val_loss: 0.0024\n",
            "Epoch 282/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.6028e-04\n",
            "Epoch 282: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5276e-04 - val_loss: 0.0025\n",
            "Epoch 283/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.5748e-04\n",
            "Epoch 283: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5748e-04 - val_loss: 0.0052\n",
            "Epoch 284/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.8415e-04\n",
            "Epoch 284: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.8301e-04 - val_loss: 0.0077\n",
            "Epoch 285/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.1919e-04\n",
            "Epoch 285: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.1785e-04 - val_loss: 0.0037\n",
            "Epoch 286/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.4923e-04\n",
            "Epoch 286: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5486e-04 - val_loss: 0.0029\n",
            "Epoch 287/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.9367e-04\n",
            "Epoch 287: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.9139e-04 - val_loss: 0.0032\n",
            "Epoch 288/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.5208e-04\n",
            "Epoch 288: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.4536e-04 - val_loss: 0.0036\n",
            "Epoch 289/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 2.9276e-04\n",
            "Epoch 289: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 2.9276e-04 - val_loss: 0.0040\n",
            "Epoch 290/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.2563e-04\n",
            "Epoch 290: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.2563e-04 - val_loss: 0.0028\n",
            "Epoch 291/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.2847e-04\n",
            "Epoch 291: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2969e-04 - val_loss: 0.0043\n",
            "Epoch 292/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.5907e-04\n",
            "Epoch 292: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5609e-04 - val_loss: 0.0027\n",
            "Epoch 293/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.1943e-04\n",
            "Epoch 293: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1534e-04 - val_loss: 0.0048\n",
            "Epoch 294/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.1129e-04\n",
            "Epoch 294: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.1048e-04 - val_loss: 0.0025\n",
            "Epoch 295/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.7458e-04\n",
            "Epoch 295: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7582e-04 - val_loss: 0.0049\n",
            "Epoch 296/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 2.9672e-04\n",
            "Epoch 296: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.9535e-04 - val_loss: 0.0073\n",
            "Epoch 297/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.5143e-04\n",
            "Epoch 297: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4645e-04 - val_loss: 0.0043\n",
            "Epoch 298/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.5779e-04\n",
            "Epoch 298: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.5636e-04 - val_loss: 0.0023\n",
            "Epoch 299/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.4570e-04\n",
            "Epoch 299: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3890e-04 - val_loss: 0.0024\n",
            "Epoch 300/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.3980e-04\n",
            "Epoch 300: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4299e-04 - val_loss: 0.0026\n",
            "Epoch 301/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.2746e-04\n",
            "Epoch 301: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.2944e-04 - val_loss: 0.0034\n",
            "Epoch 302/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.2742e-04\n",
            "Epoch 302: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.2618e-04 - val_loss: 0.0032\n",
            "Epoch 303/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.4410e-04\n",
            "Epoch 303: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5736e-04 - val_loss: 0.0041\n",
            "Epoch 304/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.0816e-04\n",
            "Epoch 304: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1597e-04 - val_loss: 9.1337e-04\n",
            "Epoch 305/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 2.8841e-04\n",
            "Epoch 305: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 2.8568e-04 - val_loss: 0.0038\n",
            "Epoch 306/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.2589e-04\n",
            "Epoch 306: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.2833e-04 - val_loss: 0.0042\n",
            "Epoch 307/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.0317e-04\n",
            "Epoch 307: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.0370e-04 - val_loss: 0.0059\n",
            "Epoch 308/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6595e-04\n",
            "Epoch 308: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.7273e-04 - val_loss: 0.0050\n",
            "Epoch 309/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.8382e-04\n",
            "Epoch 309: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.8382e-04 - val_loss: 9.7712e-04\n",
            "Epoch 310/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.1027e-04\n",
            "Epoch 310: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.0561e-04 - val_loss: 0.0013\n",
            "Epoch 311/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.4026e-04\n",
            "Epoch 311: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4026e-04 - val_loss: 0.0039\n",
            "Epoch 312/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.3807e-04\n",
            "Epoch 312: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3780e-04 - val_loss: 0.0037\n",
            "Epoch 313/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.2276e-04\n",
            "Epoch 313: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.1750e-04 - val_loss: 6.0371e-04\n",
            "Epoch 314/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.4418e-04\n",
            "Epoch 314: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5629e-04 - val_loss: 0.0029\n",
            "Epoch 315/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.4117e-04\n",
            "Epoch 315: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4117e-04 - val_loss: 0.0058\n",
            "Epoch 316/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.2367e-04\n",
            "Epoch 316: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.2323e-04 - val_loss: 0.0044\n",
            "Epoch 317/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.2931e-04\n",
            "Epoch 317: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2948e-04 - val_loss: 0.0060\n",
            "Epoch 318/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.0578e-04\n",
            "Epoch 318: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0206e-04 - val_loss: 0.0056\n",
            "Epoch 319/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.4798e-04\n",
            "Epoch 319: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4294e-04 - val_loss: 0.0035\n",
            "Epoch 320/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.5917e-04\n",
            "Epoch 320: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.5917e-04 - val_loss: 0.0029\n",
            "Epoch 321/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.1723e-04\n",
            "Epoch 321: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.2529e-04 - val_loss: 0.0088\n",
            "Epoch 322/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6438e-04\n",
            "Epoch 322: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.6727e-04 - val_loss: 0.0044\n",
            "Epoch 323/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.7219e-04\n",
            "Epoch 323: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6585e-04 - val_loss: 0.0048\n",
            "Epoch 324/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 2.9854e-04\n",
            "Epoch 324: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.0229e-04 - val_loss: 0.0028\n",
            "Epoch 325/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.3487e-04\n",
            "Epoch 325: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.3750e-04 - val_loss: 6.8574e-04\n",
            "Epoch 326/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.7028e-04\n",
            "Epoch 326: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.7002e-04 - val_loss: 0.0049\n",
            "Epoch 327/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.1173e-04\n",
            "Epoch 327: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.1418e-04 - val_loss: 0.0028\n",
            "Epoch 328/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 2.8871e-04\n",
            "Epoch 328: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.9128e-04 - val_loss: 0.0016\n",
            "Epoch 329/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.4561e-04\n",
            "Epoch 329: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4561e-04 - val_loss: 0.0060\n",
            "Epoch 330/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.5166e-04\n",
            "Epoch 330: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4868e-04 - val_loss: 0.0037\n",
            "Epoch 331/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.1030e-04\n",
            "Epoch 331: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.0777e-04 - val_loss: 0.0041\n",
            "Epoch 332/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.1636e-04\n",
            "Epoch 332: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.0812e-04 - val_loss: 0.0045\n",
            "Epoch 333/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.0637e-04\n",
            "Epoch 333: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.0851e-04 - val_loss: 0.0039\n",
            "Epoch 334/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6512e-04\n",
            "Epoch 334: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.6930e-04 - val_loss: 0.0052\n",
            "Epoch 335/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.6150e-04\n",
            "Epoch 335: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.6211e-04 - val_loss: 0.0029\n",
            "Epoch 336/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.0644e-04\n",
            "Epoch 336: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0614e-04 - val_loss: 0.0020\n",
            "Epoch 337/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 2.9774e-04\n",
            "Epoch 337: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.0300e-04 - val_loss: 0.0058\n",
            "Epoch 338/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.4457e-04\n",
            "Epoch 338: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4457e-04 - val_loss: 0.0044\n",
            "Epoch 339/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6383e-04\n",
            "Epoch 339: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.6471e-04 - val_loss: 0.0045\n",
            "Epoch 340/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.2447e-04\n",
            "Epoch 340: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2233e-04 - val_loss: 0.0033\n",
            "Epoch 341/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 4.1345e-04\n",
            "Epoch 341: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.1203e-04 - val_loss: 0.0051\n",
            "Epoch 342/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.0493e-04\n",
            "Epoch 342: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0520e-04 - val_loss: 7.7233e-04\n",
            "Epoch 343/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.7540e-04\n",
            "Epoch 343: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7540e-04 - val_loss: 0.0057\n",
            "Epoch 344/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.3847e-04\n",
            "Epoch 344: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.3814e-04 - val_loss: 0.0031\n",
            "Epoch 345/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.9076e-04\n",
            "Epoch 345: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8965e-04 - val_loss: 0.0073\n",
            "Epoch 346/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.1111e-04\n",
            "Epoch 346: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.1032e-04 - val_loss: 0.0035\n",
            "Epoch 347/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 2.9946e-04\n",
            "Epoch 347: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 2.9859e-04 - val_loss: 0.0082\n",
            "Epoch 348/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.5712e-04\n",
            "Epoch 348: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.6242e-04 - val_loss: 0.0059\n",
            "Epoch 349/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.4903e-04\n",
            "Epoch 349: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.4903e-04 - val_loss: 0.0071\n",
            "Epoch 350/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.3392e-04\n",
            "Epoch 350: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3308e-04 - val_loss: 0.0063\n",
            "Epoch 351/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.0166e-04\n",
            "Epoch 351: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.9902e-04 - val_loss: 0.0017\n",
            "Epoch 352/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.7010e-04\n",
            "Epoch 352: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6350e-04 - val_loss: 7.7063e-04\n",
            "Epoch 353/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.5185e-04\n",
            "Epoch 353: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4964e-04 - val_loss: 0.0063\n",
            "Epoch 354/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.2318e-04\n",
            "Epoch 354: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.1919e-04 - val_loss: 0.0051\n",
            "Epoch 355/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.5165e-04\n",
            "Epoch 355: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5091e-04 - val_loss: 0.0052\n",
            "Epoch 356/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.5264e-04\n",
            "Epoch 356: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.5264e-04 - val_loss: 0.0060\n",
            "Epoch 357/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.4324e-04\n",
            "Epoch 357: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4275e-04 - val_loss: 0.0040\n",
            "Epoch 358/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.2633e-04\n",
            "Epoch 358: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.2608e-04 - val_loss: 0.0082\n",
            "Epoch 359/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.0097e-04\n",
            "Epoch 359: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0140e-04 - val_loss: 0.0057\n",
            "Epoch 360/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.1867e-04\n",
            "Epoch 360: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.1851e-04 - val_loss: 0.0051\n",
            "Epoch 361/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.8770e-04\n",
            "Epoch 361: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.0000e-04 - val_loss: 0.0038\n",
            "Epoch 362/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 2.9896e-04\n",
            "Epoch 362: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.0237e-04 - val_loss: 0.0044\n",
            "Epoch 363/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.5378e-04\n",
            "Epoch 363: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4833e-04 - val_loss: 0.0085\n",
            "Epoch 364/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.1578e-04\n",
            "Epoch 364: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.2301e-04 - val_loss: 0.0042\n",
            "Epoch 365/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.0398e-04\n",
            "Epoch 365: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.0639e-04 - val_loss: 0.0024\n",
            "Epoch 366/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.5563e-04\n",
            "Epoch 366: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.4994e-04 - val_loss: 0.0061\n",
            "Epoch 367/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 2.8241e-04\n",
            "Epoch 367: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 2.8650e-04 - val_loss: 0.0081\n",
            "Epoch 368/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.1922e-04\n",
            "Epoch 368: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.1764e-04 - val_loss: 0.0050\n",
            "Epoch 369/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.3701e-04\n",
            "Epoch 369: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3438e-04 - val_loss: 0.0074\n",
            "Epoch 370/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 2.9027e-04\n",
            "Epoch 370: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 2.9027e-04 - val_loss: 0.0066\n",
            "Epoch 371/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.2294e-04\n",
            "Epoch 371: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1995e-04 - val_loss: 0.0079\n",
            "Epoch 372/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.1321e-04\n",
            "Epoch 372: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.1664e-04 - val_loss: 0.0041\n",
            "Epoch 373/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.1527e-04\n",
            "Epoch 373: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.1212e-04 - val_loss: 0.0042\n",
            "Epoch 374/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.5615e-04\n",
            "Epoch 374: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5274e-04 - val_loss: 0.0093\n",
            "Epoch 375/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.4396e-04\n",
            "Epoch 375: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5465e-04 - val_loss: 0.0024\n",
            "Epoch 376/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.3862e-04\n",
            "Epoch 376: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4598e-04 - val_loss: 0.0039\n",
            "Epoch 377/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.5276e-04\n",
            "Epoch 377: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4575e-04 - val_loss: 0.0033\n",
            "Epoch 378/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.0432e-04\n",
            "Epoch 378: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0582e-04 - val_loss: 0.0049\n",
            "Epoch 379/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 2.6817e-04\n",
            "Epoch 379: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.6791e-04 - val_loss: 0.0072\n",
            "Epoch 380/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.1688e-04\n",
            "Epoch 380: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.2400e-04 - val_loss: 0.0019\n",
            "Epoch 381/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.2175e-04\n",
            "Epoch 381: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2092e-04 - val_loss: 0.0046\n",
            "Epoch 382/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.3006e-04\n",
            "Epoch 382: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3006e-04 - val_loss: 0.0022\n",
            "Epoch 383/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.0686e-04\n",
            "Epoch 383: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0686e-04 - val_loss: 0.0050\n",
            "Epoch 384/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.0280e-04\n",
            "Epoch 384: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.0026e-04 - val_loss: 0.0049\n",
            "Epoch 385/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.1507e-04\n",
            "Epoch 385: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.1306e-04 - val_loss: 0.0020\n",
            "Epoch 386/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.1082e-04\n",
            "Epoch 386: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.1082e-04 - val_loss: 0.0085\n",
            "Epoch 387/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.3560e-04\n",
            "Epoch 387: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.3465e-04 - val_loss: 0.0031\n",
            "Epoch 388/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 2.7598e-04\n",
            "Epoch 388: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 2.8308e-04 - val_loss: 0.0027\n",
            "Epoch 389/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 2.9468e-04\n",
            "Epoch 389: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 2.8968e-04 - val_loss: 0.0033\n",
            "Epoch 390/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 2.9790e-04\n",
            "Epoch 390: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 2.9512e-04 - val_loss: 0.0033\n",
            "Epoch 391/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.4914e-04\n",
            "Epoch 391: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3890e-04 - val_loss: 0.0041\n",
            "Epoch 392/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.1481e-04\n",
            "Epoch 392: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1326e-04 - val_loss: 0.0053\n",
            "Epoch 393/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.2500e-04\n",
            "Epoch 393: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2599e-04 - val_loss: 0.0049\n",
            "Epoch 394/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.1485e-04\n",
            "Epoch 394: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1925e-04 - val_loss: 0.0050\n",
            "Epoch 395/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.9280e-04\n",
            "Epoch 395: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.8949e-04 - val_loss: 0.0044\n",
            "Epoch 396/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.2057e-04\n",
            "Epoch 396: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2057e-04 - val_loss: 0.0028\n",
            "Epoch 397/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.4406e-04\n",
            "Epoch 397: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4157e-04 - val_loss: 0.0032\n",
            "Epoch 398/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.5799e-04\n",
            "Epoch 398: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.5319e-04 - val_loss: 0.0032\n",
            "Epoch 399/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.5407e-04\n",
            "Epoch 399: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5370e-04 - val_loss: 0.0051\n",
            "Epoch 400/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.1644e-04\n",
            "Epoch 400: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1263e-04 - val_loss: 0.0070\n",
            "Epoch 401/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.2457e-04\n",
            "Epoch 401: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.2530e-04 - val_loss: 0.0025\n",
            "Epoch 402/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 2.9913e-04\n",
            "Epoch 402: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 2.9640e-04 - val_loss: 0.0033\n",
            "Epoch 403/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 2.7695e-04\n",
            "Epoch 403: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.7698e-04 - val_loss: 0.0065\n",
            "Epoch 404/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.0044e-04\n",
            "Epoch 404: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 2.9901e-04 - val_loss: 0.0057\n",
            "Epoch 405/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 2.9844e-04\n",
            "Epoch 405: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.0131e-04 - val_loss: 0.0038\n",
            "Epoch 406/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 2.7276e-04\n",
            "Epoch 406: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 2.7768e-04 - val_loss: 0.0046\n",
            "Epoch 407/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.3939e-04\n",
            "Epoch 407: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.3846e-04 - val_loss: 0.0028\n",
            "Epoch 408/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.2172e-04\n",
            "Epoch 408: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.2172e-04 - val_loss: 0.0081\n",
            "Epoch 409/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.7262e-04\n",
            "Epoch 409: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.7162e-04 - val_loss: 0.0030\n",
            "Epoch 410/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 2.7033e-04\n",
            "Epoch 410: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 2.7033e-04 - val_loss: 0.0048\n",
            "Epoch 411/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.3316e-04\n",
            "Epoch 411: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3026e-04 - val_loss: 0.0029\n",
            "Epoch 412/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.2823e-04\n",
            "Epoch 412: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2823e-04 - val_loss: 0.0045\n",
            "Epoch 413/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.2638e-04\n",
            "Epoch 413: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.1888e-04 - val_loss: 0.0038\n",
            "Epoch 414/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 2.8789e-04\n",
            "Epoch 414: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.8905e-04 - val_loss: 0.0039\n",
            "Epoch 415/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.5228e-04\n",
            "Epoch 415: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5228e-04 - val_loss: 0.0063\n",
            "Epoch 416/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.2449e-04\n",
            "Epoch 416: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1948e-04 - val_loss: 0.0028\n",
            "Epoch 417/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.8514e-04\n",
            "Epoch 417: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.8514e-04 - val_loss: 0.0103\n",
            "Epoch 418/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.7921e-04\n",
            "Epoch 418: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.6887e-04 - val_loss: 0.0061\n",
            "Epoch 419/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.7369e-04\n",
            "Epoch 419: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6984e-04 - val_loss: 0.0063\n",
            "Epoch 420/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.2570e-04\n",
            "Epoch 420: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 24ms/step - loss: 3.2621e-04 - val_loss: 0.0061\n",
            "Epoch 421/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 2.9228e-04\n",
            "Epoch 421: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.9192e-04 - val_loss: 0.0048\n",
            "Epoch 422/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 2.9731e-04\n",
            "Epoch 422: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 2.9644e-04 - val_loss: 0.0022\n",
            "Epoch 423/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 2.9350e-04\n",
            "Epoch 423: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 2.9742e-04 - val_loss: 0.0039\n",
            "Epoch 424/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.0830e-04\n",
            "Epoch 424: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.1510e-04 - val_loss: 0.0062\n",
            "Epoch 425/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.0250e-04\n",
            "Epoch 425: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.1505e-04 - val_loss: 0.0047\n",
            "Epoch 426/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.1840e-04\n",
            "Epoch 426: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.1845e-04 - val_loss: 0.0045\n",
            "Epoch 427/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.2240e-04\n",
            "Epoch 427: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.2174e-04 - val_loss: 0.0044\n",
            "Epoch 428/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.2620e-04\n",
            "Epoch 428: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2915e-04 - val_loss: 0.0052\n",
            "Epoch 429/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.2257e-04\n",
            "Epoch 429: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2367e-04 - val_loss: 0.0070\n",
            "Epoch 430/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.6287e-04\n",
            "Epoch 430: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.7411e-04 - val_loss: 0.0070\n",
            "Epoch 431/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.5617e-04\n",
            "Epoch 431: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.5080e-04 - val_loss: 0.0081\n",
            "Epoch 432/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.1111e-04\n",
            "Epoch 432: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.0920e-04 - val_loss: 0.0063\n",
            "Epoch 433/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.0578e-04\n",
            "Epoch 433: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0506e-04 - val_loss: 0.0044\n",
            "Epoch 434/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.0389e-04\n",
            "Epoch 434: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.0201e-04 - val_loss: 0.0023\n",
            "Epoch 435/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.2944e-04\n",
            "Epoch 435: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.2942e-04 - val_loss: 0.0064\n",
            "Epoch 436/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 2.8817e-04\n",
            "Epoch 436: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.9601e-04 - val_loss: 0.0019\n",
            "Epoch 437/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.3604e-04\n",
            "Epoch 437: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3254e-04 - val_loss: 0.0021\n",
            "Epoch 438/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.8507e-04\n",
            "Epoch 438: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.9589e-04 - val_loss: 0.0048\n",
            "Epoch 439/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.5984e-04\n",
            "Epoch 439: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.5984e-04 - val_loss: 0.0044\n",
            "Epoch 440/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.1164e-04\n",
            "Epoch 440: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1049e-04 - val_loss: 0.0078\n",
            "Epoch 441/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.3622e-04\n",
            "Epoch 441: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3714e-04 - val_loss: 0.0044\n",
            "Epoch 442/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.0088e-04\n",
            "Epoch 442: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.0000e-04 - val_loss: 0.0042\n",
            "Epoch 443/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.1341e-04\n",
            "Epoch 443: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.1269e-04 - val_loss: 0.0017\n",
            "Epoch 444/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 2.6896e-04\n",
            "Epoch 444: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 2.6833e-04 - val_loss: 0.0075\n",
            "Epoch 445/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 2.7085e-04\n",
            "Epoch 445: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 2.7547e-04 - val_loss: 0.0055\n",
            "Epoch 446/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 2.9831e-04\n",
            "Epoch 446: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 2.9831e-04 - val_loss: 0.0069\n",
            "Epoch 447/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.7114e-04\n",
            "Epoch 447: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.7302e-04 - val_loss: 0.0050\n",
            "Epoch 448/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.0704e-04\n",
            "Epoch 448: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0561e-04 - val_loss: 0.0073\n",
            "Epoch 449/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 2.7685e-04\n",
            "Epoch 449: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 2.7669e-04 - val_loss: 0.0029\n",
            "Epoch 450/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 2.9086e-04\n",
            "Epoch 450: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.9086e-04 - val_loss: 0.0042\n",
            "Epoch 451/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.2768e-04\n",
            "Epoch 451: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2768e-04 - val_loss: 0.0034\n",
            "Epoch 452/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.0182e-04\n",
            "Epoch 452: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.0640e-04 - val_loss: 0.0042\n",
            "Epoch 453/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 2.9549e-04\n",
            "Epoch 453: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 2.9641e-04 - val_loss: 0.0034\n",
            "Epoch 454/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.1823e-04\n",
            "Epoch 454: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2108e-04 - val_loss: 0.0047\n",
            "Epoch 455/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.3849e-04\n",
            "Epoch 455: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4133e-04 - val_loss: 0.0066\n",
            "Epoch 456/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.3697e-04\n",
            "Epoch 456: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4772e-04 - val_loss: 0.0029\n",
            "Epoch 457/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.7875e-04\n",
            "Epoch 457: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.7875e-04 - val_loss: 0.0114\n",
            "Epoch 458/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.0466e-04\n",
            "Epoch 458: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.0418e-04 - val_loss: 0.0055\n",
            "Epoch 459/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.1238e-04\n",
            "Epoch 459: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1027e-04 - val_loss: 0.0029\n",
            "Epoch 460/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.3668e-04\n",
            "Epoch 460: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3307e-04 - val_loss: 0.0070\n",
            "Epoch 461/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 2.8582e-04\n",
            "Epoch 461: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.8686e-04 - val_loss: 0.0034\n",
            "Epoch 462/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.0463e-04\n",
            "Epoch 462: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.0463e-04 - val_loss: 0.0059\n",
            "Epoch 463/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.0516e-04\n",
            "Epoch 463: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.0386e-04 - val_loss: 0.0026\n",
            "Epoch 464/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.1944e-04\n",
            "Epoch 464: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.1630e-04 - val_loss: 0.0043\n",
            "Epoch 465/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.0850e-04\n",
            "Epoch 465: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.0850e-04 - val_loss: 0.0041\n",
            "Epoch 466/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.1801e-04\n",
            "Epoch 466: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.1801e-04 - val_loss: 0.0020\n",
            "Epoch 467/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.1837e-04\n",
            "Epoch 467: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.1588e-04 - val_loss: 0.0059\n",
            "Epoch 468/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 2.9857e-04\n",
            "Epoch 468: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.9729e-04 - val_loss: 0.0037\n",
            "Epoch 469/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.2281e-04\n",
            "Epoch 469: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2122e-04 - val_loss: 0.0053\n",
            "Epoch 470/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.3703e-04\n",
            "Epoch 470: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3703e-04 - val_loss: 0.0033\n",
            "Epoch 471/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 2.8526e-04\n",
            "Epoch 471: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.8735e-04 - val_loss: 0.0027\n",
            "Epoch 472/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.0983e-04\n",
            "Epoch 472: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0825e-04 - val_loss: 0.0023\n",
            "Epoch 473/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 2.9085e-04\n",
            "Epoch 473: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.9276e-04 - val_loss: 5.7305e-04\n",
            "Epoch 474/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.7469e-04\n",
            "Epoch 474: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.6944e-04 - val_loss: 0.0109\n",
            "Epoch 475/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.5065e-04\n",
            "Epoch 475: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4808e-04 - val_loss: 0.0040\n",
            "Epoch 476/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.1798e-04\n",
            "Epoch 476: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1798e-04 - val_loss: 0.0071\n",
            "Epoch 477/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.2111e-04\n",
            "Epoch 477: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1976e-04 - val_loss: 0.0077\n",
            "Epoch 478/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.2153e-04\n",
            "Epoch 478: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2153e-04 - val_loss: 0.0019\n",
            "Epoch 479/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.4086e-04\n",
            "Epoch 479: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3366e-04 - val_loss: 0.0032\n",
            "Epoch 480/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 2.9062e-04\n",
            "Epoch 480: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.9157e-04 - val_loss: 0.0028\n",
            "Epoch 481/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.5712e-04\n",
            "Epoch 481: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.5817e-04 - val_loss: 0.0084\n",
            "Epoch 482/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 2.9861e-04\n",
            "Epoch 482: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 2.9682e-04 - val_loss: 0.0038\n",
            "Epoch 483/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.6229e-04\n",
            "Epoch 483: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 3.6229e-04 - val_loss: 9.3525e-04\n",
            "Epoch 484/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.3631e-04\n",
            "Epoch 484: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.3688e-04 - val_loss: 9.0099e-04\n",
            "Epoch 485/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.2826e-04\n",
            "Epoch 485: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.2734e-04 - val_loss: 0.0050\n",
            "Epoch 486/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.0203e-04\n",
            "Epoch 486: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0093e-04 - val_loss: 0.0061\n",
            "Epoch 487/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.1829e-04\n",
            "Epoch 487: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2069e-04 - val_loss: 0.0032\n",
            "Epoch 488/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.2422e-04\n",
            "Epoch 488: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1932e-04 - val_loss: 0.0052\n",
            "Epoch 489/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 2.7917e-04\n",
            "Epoch 489: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.7917e-04 - val_loss: 0.0036\n",
            "Epoch 490/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.0049e-04\n",
            "Epoch 490: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.0049e-04 - val_loss: 0.0045\n",
            "Epoch 491/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 2.8825e-04\n",
            "Epoch 491: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.8664e-04 - val_loss: 0.0053\n",
            "Epoch 492/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 2.7362e-04\n",
            "Epoch 492: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.7158e-04 - val_loss: 0.0052\n",
            "Epoch 493/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 2.7009e-04\n",
            "Epoch 493: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.7352e-04 - val_loss: 0.0031\n",
            "Epoch 494/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 2.8226e-04\n",
            "Epoch 494: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.8456e-04 - val_loss: 0.0049\n",
            "Epoch 495/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 2.7719e-04\n",
            "Epoch 495: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 2.7846e-04 - val_loss: 0.0019\n",
            "Epoch 496/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.0404e-04\n",
            "Epoch 496: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0404e-04 - val_loss: 0.0048\n",
            "Epoch 497/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 2.7754e-04\n",
            "Epoch 497: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 2.7722e-04 - val_loss: 0.0031\n",
            "Epoch 498/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.3485e-04\n",
            "Epoch 498: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3405e-04 - val_loss: 0.0042\n",
            "Epoch 499/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 2.8910e-04\n",
            "Epoch 499: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 2.9135e-04 - val_loss: 0.0037\n",
            "Epoch 500/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.5589e-04\n",
            "Epoch 500: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.5589e-04 - val_loss: 0.0023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(filepath='best_model_oclh.h5', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
        "\n",
        "# Train the model with ModelCheckpoint callback\n",
        "history_oclh = model_oclh.fit(X_train_oclh, y_train_oclh, epochs=500, batch_size=16, validation_data=(X_test_oclh, y_test_oclh), callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlRc5oyx84MF",
        "outputId": "640d15b4-9771-45d2-b788-9ef9b329fd94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0511\n",
            "Epoch 1: val_loss improved from inf to 0.00244, saving model to best_model_oclh.h5\n",
            "61/61 [==============================] - 4s 19ms/step - loss: 0.0511 - val_loss: 0.0024\n",
            "Epoch 2/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0113\n",
            "Epoch 2: val_loss did not improve from 0.00244\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 0.0111 - val_loss: 0.0078\n",
            "Epoch 3/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0061\n",
            "Epoch 3: val_loss did not improve from 0.00244\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 0.0061 - val_loss: 0.0090\n",
            "Epoch 4/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0052\n",
            "Epoch 4: val_loss improved from 0.00244 to 0.00183, saving model to best_model_oclh.h5\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 0.0052 - val_loss: 0.0018\n",
            "Epoch 5/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.0048\n",
            "Epoch 5: val_loss improved from 0.00183 to 0.00169, saving model to best_model_oclh.h5\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0017\n",
            "Epoch 6/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0038\n",
            "Epoch 6: val_loss did not improve from 0.00169\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0039 - val_loss: 0.0038\n",
            "Epoch 7/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0033\n",
            "Epoch 7: val_loss did not improve from 0.00169\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0033 - val_loss: 0.0059\n",
            "Epoch 8/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0030\n",
            "Epoch 8: val_loss did not improve from 0.00169\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.0030 - val_loss: 0.0047\n",
            "Epoch 9/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0032\n",
            "Epoch 9: val_loss did not improve from 0.00169\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0032 - val_loss: 0.0031\n",
            "Epoch 10/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.0025\n",
            "Epoch 10: val_loss improved from 0.00169 to 0.00116, saving model to best_model_oclh.h5\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0025 - val_loss: 0.0012\n",
            "Epoch 11/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0024\n",
            "Epoch 11: val_loss did not improve from 0.00116\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0024 - val_loss: 0.0015\n",
            "Epoch 12/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0025\n",
            "Epoch 12: val_loss did not improve from 0.00116\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0025 - val_loss: 0.0021\n",
            "Epoch 13/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0022\n",
            "Epoch 13: val_loss did not improve from 0.00116\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0031\n",
            "Epoch 14/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0022\n",
            "Epoch 14: val_loss improved from 0.00116 to 0.00094, saving model to best_model_oclh.h5\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0021 - val_loss: 9.3629e-04\n",
            "Epoch 15/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0019\n",
            "Epoch 15: val_loss did not improve from 0.00094\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.0019 - val_loss: 0.0017\n",
            "Epoch 16/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0019\n",
            "Epoch 16: val_loss did not improve from 0.00094\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.0019 - val_loss: 0.0065\n",
            "Epoch 17/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0019\n",
            "Epoch 17: val_loss did not improve from 0.00094\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 18/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0021\n",
            "Epoch 18: val_loss did not improve from 0.00094\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0021 - val_loss: 0.0010\n",
            "Epoch 19/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0016\n",
            "Epoch 19: val_loss did not improve from 0.00094\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0018\n",
            "Epoch 20/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0017\n",
            "Epoch 20: val_loss did not improve from 0.00094\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 0.0017 - val_loss: 0.0011\n",
            "Epoch 21/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0018\n",
            "Epoch 21: val_loss did not improve from 0.00094\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 0.0018 - val_loss: 0.0011\n",
            "Epoch 22/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0020\n",
            "Epoch 22: val_loss did not improve from 0.00094\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.0020 - val_loss: 9.5322e-04\n",
            "Epoch 23/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0015\n",
            "Epoch 23: val_loss did not improve from 0.00094\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.0015 - val_loss: 0.0023\n",
            "Epoch 24/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0014\n",
            "Epoch 24: val_loss did not improve from 0.00094\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 25/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0015\n",
            "Epoch 25: val_loss did not improve from 0.00094\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.0015 - val_loss: 0.0011\n",
            "Epoch 26/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0016\n",
            "Epoch 26: val_loss improved from 0.00094 to 0.00072, saving model to best_model_oclh.h5\n",
            "61/61 [==============================] - 2s 29ms/step - loss: 0.0016 - val_loss: 7.2457e-04\n",
            "Epoch 27/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0016\n",
            "Epoch 27: val_loss did not improve from 0.00072\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0016 - val_loss: 0.0033\n",
            "Epoch 28/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0014\n",
            "Epoch 28: val_loss did not improve from 0.00072\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 0.0015 - val_loss: 0.0022\n",
            "Epoch 29/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0014\n",
            "Epoch 29: val_loss did not improve from 0.00072\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 0.0014 - val_loss: 8.5450e-04\n",
            "Epoch 30/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0012\n",
            "Epoch 30: val_loss did not improve from 0.00072\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 0.0012 - val_loss: 0.0034\n",
            "Epoch 31/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0015\n",
            "Epoch 31: val_loss did not improve from 0.00072\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.0015 - val_loss: 0.0010\n",
            "Epoch 32/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0014\n",
            "Epoch 32: val_loss did not improve from 0.00072\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 0.0014 - val_loss: 0.0047\n",
            "Epoch 33/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0013\n",
            "Epoch 33: val_loss did not improve from 0.00072\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 34/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0013\n",
            "Epoch 34: val_loss improved from 0.00072 to 0.00072, saving model to best_model_oclh.h5\n",
            "61/61 [==============================] - 2s 25ms/step - loss: 0.0013 - val_loss: 7.2336e-04\n",
            "Epoch 35/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 0.0013\n",
            "Epoch 35: val_loss did not improve from 0.00072\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 0.0013 - val_loss: 0.0013\n",
            "Epoch 36/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0012\n",
            "Epoch 36: val_loss did not improve from 0.00072\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.0012 - val_loss: 0.0043\n",
            "Epoch 37/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0013\n",
            "Epoch 37: val_loss improved from 0.00072 to 0.00066, saving model to best_model_oclh.h5\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.0013 - val_loss: 6.5762e-04\n",
            "Epoch 38/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 0.0011\n",
            "Epoch 38: val_loss did not improve from 0.00066\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0023\n",
            "Epoch 39/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 0.0013\n",
            "Epoch 39: val_loss did not improve from 0.00066\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0048\n",
            "Epoch 40/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 9.9369e-04\n",
            "Epoch 40: val_loss did not improve from 0.00066\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 0.0010 - val_loss: 0.0016\n",
            "Epoch 41/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0012\n",
            "Epoch 41: val_loss did not improve from 0.00066\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0011 - val_loss: 0.0049\n",
            "Epoch 42/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 9.5039e-04\n",
            "Epoch 42: val_loss improved from 0.00066 to 0.00061, saving model to best_model_oclh.h5\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 9.7212e-04 - val_loss: 6.0627e-04\n",
            "Epoch 43/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0012\n",
            "Epoch 43: val_loss did not improve from 0.00061\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 0.0012 - val_loss: 0.0012\n",
            "Epoch 44/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0012\n",
            "Epoch 44: val_loss improved from 0.00061 to 0.00059, saving model to best_model_oclh.h5\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.0012 - val_loss: 5.8655e-04\n",
            "Epoch 45/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 0.0010    \n",
            "Epoch 45: val_loss did not improve from 0.00059\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.0010 - val_loss: 9.7851e-04\n",
            "Epoch 46/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 9.4810e-04\n",
            "Epoch 46: val_loss did not improve from 0.00059\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 9.7011e-04 - val_loss: 0.0020\n",
            "Epoch 47/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0011\n",
            "Epoch 47: val_loss did not improve from 0.00059\n",
            "61/61 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 0.0012\n",
            "Epoch 48/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 0.0010\n",
            "Epoch 48: val_loss did not improve from 0.00059\n",
            "61/61 [==============================] - 2s 25ms/step - loss: 0.0010 - val_loss: 0.0013\n",
            "Epoch 49/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 9.7019e-04\n",
            "Epoch 49: val_loss did not improve from 0.00059\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 9.7019e-04 - val_loss: 0.0024\n",
            "Epoch 50/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 9.8825e-04\n",
            "Epoch 50: val_loss did not improve from 0.00059\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 9.8242e-04 - val_loss: 0.0023\n",
            "Epoch 51/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 8.5927e-04\n",
            "Epoch 51: val_loss improved from 0.00059 to 0.00054, saving model to best_model_oclh.h5\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 8.6085e-04 - val_loss: 5.3889e-04\n",
            "Epoch 52/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 9.9848e-04\n",
            "Epoch 52: val_loss did not improve from 0.00054\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 9.8896e-04 - val_loss: 6.4430e-04\n",
            "Epoch 53/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 0.0010\n",
            "Epoch 53: val_loss did not improve from 0.00054\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 0.0010 - val_loss: 0.0021\n",
            "Epoch 54/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 8.0523e-04\n",
            "Epoch 54: val_loss did not improve from 0.00054\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 8.1146e-04 - val_loss: 0.0014\n",
            "Epoch 55/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 0.0011\n",
            "Epoch 55: val_loss did not improve from 0.00054\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.0011 - val_loss: 0.0065\n",
            "Epoch 56/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 8.8807e-04\n",
            "Epoch 56: val_loss did not improve from 0.00054\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 8.8135e-04 - val_loss: 5.9677e-04\n",
            "Epoch 57/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 8.2542e-04\n",
            "Epoch 57: val_loss did not improve from 0.00054\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 8.1902e-04 - val_loss: 0.0049\n",
            "Epoch 58/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 9.1258e-04\n",
            "Epoch 58: val_loss did not improve from 0.00054\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 9.0648e-04 - val_loss: 0.0016\n",
            "Epoch 59/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 7.9171e-04\n",
            "Epoch 59: val_loss did not improve from 0.00054\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 7.8969e-04 - val_loss: 9.8981e-04\n",
            "Epoch 60/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 9.5321e-04\n",
            "Epoch 60: val_loss did not improve from 0.00054\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 9.3281e-04 - val_loss: 9.2197e-04\n",
            "Epoch 61/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 7.8535e-04\n",
            "Epoch 61: val_loss improved from 0.00054 to 0.00050, saving model to best_model_oclh.h5\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 7.9936e-04 - val_loss: 5.0414e-04\n",
            "Epoch 62/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 7.8102e-04\n",
            "Epoch 62: val_loss did not improve from 0.00050\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 7.7802e-04 - val_loss: 7.7984e-04\n",
            "Epoch 63/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 7.4463e-04\n",
            "Epoch 63: val_loss did not improve from 0.00050\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 7.4136e-04 - val_loss: 5.5940e-04\n",
            "Epoch 64/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 6.7555e-04\n",
            "Epoch 64: val_loss did not improve from 0.00050\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 6.7536e-04 - val_loss: 0.0014\n",
            "Epoch 65/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 7.5228e-04\n",
            "Epoch 65: val_loss did not improve from 0.00050\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 7.4388e-04 - val_loss: 5.6006e-04\n",
            "Epoch 66/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 7.3341e-04\n",
            "Epoch 66: val_loss did not improve from 0.00050\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 7.3341e-04 - val_loss: 0.0011\n",
            "Epoch 67/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 7.3589e-04\n",
            "Epoch 67: val_loss did not improve from 0.00050\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 7.3589e-04 - val_loss: 0.0014\n",
            "Epoch 68/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 8.1891e-04\n",
            "Epoch 68: val_loss did not improve from 0.00050\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 8.1185e-04 - val_loss: 6.8184e-04\n",
            "Epoch 69/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 7.0654e-04\n",
            "Epoch 69: val_loss did not improve from 0.00050\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 7.0477e-04 - val_loss: 0.0014\n",
            "Epoch 70/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 7.5483e-04\n",
            "Epoch 70: val_loss did not improve from 0.00050\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 7.5261e-04 - val_loss: 5.3422e-04\n",
            "Epoch 71/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 7.4010e-04\n",
            "Epoch 71: val_loss improved from 0.00050 to 0.00048, saving model to best_model_oclh.h5\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 7.4099e-04 - val_loss: 4.7947e-04\n",
            "Epoch 72/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 7.1387e-04\n",
            "Epoch 72: val_loss improved from 0.00048 to 0.00040, saving model to best_model_oclh.h5\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 7.1613e-04 - val_loss: 4.0069e-04\n",
            "Epoch 73/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 6.6899e-04\n",
            "Epoch 73: val_loss did not improve from 0.00040\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 6.6467e-04 - val_loss: 0.0013\n",
            "Epoch 74/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 7.7601e-04\n",
            "Epoch 74: val_loss did not improve from 0.00040\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 7.6029e-04 - val_loss: 0.0020\n",
            "Epoch 75/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 5.9962e-04\n",
            "Epoch 75: val_loss did not improve from 0.00040\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 6.0054e-04 - val_loss: 4.5769e-04\n",
            "Epoch 76/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 6.8204e-04\n",
            "Epoch 76: val_loss did not improve from 0.00040\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 6.7736e-04 - val_loss: 0.0010\n",
            "Epoch 77/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 6.6832e-04\n",
            "Epoch 77: val_loss did not improve from 0.00040\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 6.7309e-04 - val_loss: 4.0805e-04\n",
            "Epoch 78/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 6.7190e-04\n",
            "Epoch 78: val_loss did not improve from 0.00040\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 6.7190e-04 - val_loss: 5.3730e-04\n",
            "Epoch 79/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 6.8136e-04\n",
            "Epoch 79: val_loss did not improve from 0.00040\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 6.8043e-04 - val_loss: 4.9184e-04\n",
            "Epoch 80/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 6.1320e-04\n",
            "Epoch 80: val_loss did not improve from 0.00040\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 6.0991e-04 - val_loss: 8.6989e-04\n",
            "Epoch 81/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 7.2034e-04\n",
            "Epoch 81: val_loss did not improve from 0.00040\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 7.3130e-04 - val_loss: 0.0011\n",
            "Epoch 82/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 6.9524e-04\n",
            "Epoch 82: val_loss did not improve from 0.00040\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 7.0940e-04 - val_loss: 0.0021\n",
            "Epoch 83/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 8.4319e-04\n",
            "Epoch 83: val_loss improved from 0.00040 to 0.00038, saving model to best_model_oclh.h5\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 8.1686e-04 - val_loss: 3.7677e-04\n",
            "Epoch 84/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 6.6682e-04\n",
            "Epoch 84: val_loss did not improve from 0.00038\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 6.5585e-04 - val_loss: 0.0022\n",
            "Epoch 85/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 5.9652e-04\n",
            "Epoch 85: val_loss did not improve from 0.00038\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 5.9400e-04 - val_loss: 6.9218e-04\n",
            "Epoch 86/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 6.1214e-04\n",
            "Epoch 86: val_loss did not improve from 0.00038\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 6.1194e-04 - val_loss: 0.0016\n",
            "Epoch 87/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 5.7604e-04\n",
            "Epoch 87: val_loss did not improve from 0.00038\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 5.8422e-04 - val_loss: 0.0025\n",
            "Epoch 88/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 5.9262e-04\n",
            "Epoch 88: val_loss did not improve from 0.00038\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 5.9034e-04 - val_loss: 5.6492e-04\n",
            "Epoch 89/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 5.2688e-04\n",
            "Epoch 89: val_loss did not improve from 0.00038\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 5.1889e-04 - val_loss: 4.6544e-04\n",
            "Epoch 90/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 5.5079e-04\n",
            "Epoch 90: val_loss improved from 0.00038 to 0.00035, saving model to best_model_oclh.h5\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 5.4537e-04 - val_loss: 3.5196e-04\n",
            "Epoch 91/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 5.6299e-04\n",
            "Epoch 91: val_loss did not improve from 0.00035\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 5.6299e-04 - val_loss: 0.0017\n",
            "Epoch 92/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 5.3279e-04\n",
            "Epoch 92: val_loss did not improve from 0.00035\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 5.3279e-04 - val_loss: 9.3447e-04\n",
            "Epoch 93/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 5.8060e-04\n",
            "Epoch 93: val_loss did not improve from 0.00035\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 5.7621e-04 - val_loss: 4.6799e-04\n",
            "Epoch 94/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 5.5920e-04\n",
            "Epoch 94: val_loss did not improve from 0.00035\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 5.5653e-04 - val_loss: 4.6010e-04\n",
            "Epoch 95/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 5.3588e-04\n",
            "Epoch 95: val_loss did not improve from 0.00035\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 5.4387e-04 - val_loss: 5.6432e-04\n",
            "Epoch 96/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 5.4571e-04\n",
            "Epoch 96: val_loss did not improve from 0.00035\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 5.4749e-04 - val_loss: 9.0648e-04\n",
            "Epoch 97/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 5.5325e-04\n",
            "Epoch 97: val_loss did not improve from 0.00035\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 5.5529e-04 - val_loss: 9.6900e-04\n",
            "Epoch 98/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 5.7693e-04\n",
            "Epoch 98: val_loss did not improve from 0.00035\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 5.7138e-04 - val_loss: 7.3159e-04\n",
            "Epoch 99/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.9053e-04\n",
            "Epoch 99: val_loss did not improve from 0.00035\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 4.9830e-04 - val_loss: 8.2935e-04\n",
            "Epoch 100/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 5.3052e-04\n",
            "Epoch 100: val_loss did not improve from 0.00035\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 5.3135e-04 - val_loss: 0.0025\n",
            "Epoch 101/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 5.5178e-04\n",
            "Epoch 101: val_loss did not improve from 0.00035\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 5.4094e-04 - val_loss: 7.6497e-04\n",
            "Epoch 102/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 5.7386e-04\n",
            "Epoch 102: val_loss improved from 0.00035 to 0.00034, saving model to best_model_oclh.h5\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 5.7169e-04 - val_loss: 3.4231e-04\n",
            "Epoch 103/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 5.3021e-04\n",
            "Epoch 103: val_loss did not improve from 0.00034\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 5.3021e-04 - val_loss: 6.0557e-04\n",
            "Epoch 104/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 5.3581e-04\n",
            "Epoch 104: val_loss did not improve from 0.00034\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.3581e-04 - val_loss: 0.0012\n",
            "Epoch 105/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 5.4333e-04\n",
            "Epoch 105: val_loss did not improve from 0.00034\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 5.4084e-04 - val_loss: 5.4376e-04\n",
            "Epoch 106/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 7.5056e-04\n",
            "Epoch 106: val_loss did not improve from 0.00034\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 7.5056e-04 - val_loss: 0.0034\n",
            "Epoch 107/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 5.5090e-04\n",
            "Epoch 107: val_loss did not improve from 0.00034\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.5090e-04 - val_loss: 8.0707e-04\n",
            "Epoch 108/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 5.3477e-04\n",
            "Epoch 108: val_loss did not improve from 0.00034\n",
            "61/61 [==============================] - 2s 26ms/step - loss: 5.3626e-04 - val_loss: 8.9588e-04\n",
            "Epoch 109/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 5.5810e-04\n",
            "Epoch 109: val_loss did not improve from 0.00034\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 5.5810e-04 - val_loss: 0.0012\n",
            "Epoch 110/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.7304e-04\n",
            "Epoch 110: val_loss did not improve from 0.00034\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 4.7304e-04 - val_loss: 0.0014\n",
            "Epoch 111/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 5.6267e-04\n",
            "Epoch 111: val_loss did not improve from 0.00034\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 5.6280e-04 - val_loss: 7.0255e-04\n",
            "Epoch 112/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.8485e-04\n",
            "Epoch 112: val_loss did not improve from 0.00034\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 4.9033e-04 - val_loss: 6.7105e-04\n",
            "Epoch 113/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.9832e-04\n",
            "Epoch 113: val_loss improved from 0.00034 to 0.00033, saving model to best_model_oclh.h5\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 4.9027e-04 - val_loss: 3.2663e-04\n",
            "Epoch 114/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.7880e-04\n",
            "Epoch 114: val_loss did not improve from 0.00033\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 4.8397e-04 - val_loss: 0.0018\n",
            "Epoch 115/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.8445e-04\n",
            "Epoch 115: val_loss improved from 0.00033 to 0.00030, saving model to best_model_oclh.h5\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 4.7923e-04 - val_loss: 2.9928e-04\n",
            "Epoch 116/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.7535e-04\n",
            "Epoch 116: val_loss did not improve from 0.00030\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 4.7545e-04 - val_loss: 3.1998e-04\n",
            "Epoch 117/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 5.0126e-04\n",
            "Epoch 117: val_loss did not improve from 0.00030\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.9946e-04 - val_loss: 3.7392e-04\n",
            "Epoch 118/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 4.7186e-04\n",
            "Epoch 118: val_loss did not improve from 0.00030\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.6781e-04 - val_loss: 0.0021\n",
            "Epoch 119/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.6048e-04\n",
            "Epoch 119: val_loss did not improve from 0.00030\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.6167e-04 - val_loss: 0.0011\n",
            "Epoch 120/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 5.2909e-04\n",
            "Epoch 120: val_loss improved from 0.00030 to 0.00029, saving model to best_model_oclh.h5\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 5.2909e-04 - val_loss: 2.9065e-04\n",
            "Epoch 121/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.7377e-04\n",
            "Epoch 121: val_loss did not improve from 0.00029\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.7878e-04 - val_loss: 0.0022\n",
            "Epoch 122/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.6712e-04\n",
            "Epoch 122: val_loss did not improve from 0.00029\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 4.6472e-04 - val_loss: 3.7737e-04\n",
            "Epoch 123/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.6561e-04\n",
            "Epoch 123: val_loss improved from 0.00029 to 0.00027, saving model to best_model_oclh.h5\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.6420e-04 - val_loss: 2.6867e-04\n",
            "Epoch 124/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.5613e-04\n",
            "Epoch 124: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 4.5359e-04 - val_loss: 3.1826e-04\n",
            "Epoch 125/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.5515e-04\n",
            "Epoch 125: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 4.5685e-04 - val_loss: 9.8129e-04\n",
            "Epoch 126/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 4.5949e-04\n",
            "Epoch 126: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.6184e-04 - val_loss: 7.6103e-04\n",
            "Epoch 127/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 5.1045e-04\n",
            "Epoch 127: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 5.0997e-04 - val_loss: 5.4157e-04\n",
            "Epoch 128/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.9184e-04\n",
            "Epoch 128: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9184e-04 - val_loss: 3.7136e-04\n",
            "Epoch 129/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.4410e-04\n",
            "Epoch 129: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.4182e-04 - val_loss: 0.0013\n",
            "Epoch 130/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 4.8326e-04\n",
            "Epoch 130: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.6357e-04 - val_loss: 4.0786e-04\n",
            "Epoch 131/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 4.0005e-04\n",
            "Epoch 131: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.9251e-04 - val_loss: 7.4864e-04\n",
            "Epoch 132/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.8228e-04\n",
            "Epoch 132: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.8430e-04 - val_loss: 4.4498e-04\n",
            "Epoch 133/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.0326e-04\n",
            "Epoch 133: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.0785e-04 - val_loss: 4.8914e-04\n",
            "Epoch 134/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 5.1982e-04\n",
            "Epoch 134: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 5.1766e-04 - val_loss: 3.2854e-04\n",
            "Epoch 135/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.9318e-04\n",
            "Epoch 135: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 4.9156e-04 - val_loss: 9.0506e-04\n",
            "Epoch 136/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.5698e-04\n",
            "Epoch 136: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 4.5486e-04 - val_loss: 3.3166e-04\n",
            "Epoch 137/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.7051e-04\n",
            "Epoch 137: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 4.7051e-04 - val_loss: 2.7381e-04\n",
            "Epoch 138/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.5534e-04\n",
            "Epoch 138: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 4.5548e-04 - val_loss: 5.0401e-04\n",
            "Epoch 139/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 5.3812e-04\n",
            "Epoch 139: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.3763e-04 - val_loss: 8.9834e-04\n",
            "Epoch 140/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.7215e-04\n",
            "Epoch 140: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.7176e-04 - val_loss: 7.0023e-04\n",
            "Epoch 141/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.3693e-04\n",
            "Epoch 141: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.4218e-04 - val_loss: 3.1295e-04\n",
            "Epoch 142/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.1268e-04\n",
            "Epoch 142: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 4.1268e-04 - val_loss: 3.3677e-04\n",
            "Epoch 143/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.4188e-04\n",
            "Epoch 143: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 4.4188e-04 - val_loss: 6.0348e-04\n",
            "Epoch 144/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.6508e-04\n",
            "Epoch 144: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 4.6927e-04 - val_loss: 9.3253e-04\n",
            "Epoch 145/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.3139e-04\n",
            "Epoch 145: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2936e-04 - val_loss: 3.5219e-04\n",
            "Epoch 146/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.2203e-04\n",
            "Epoch 146: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.1857e-04 - val_loss: 4.8305e-04\n",
            "Epoch 147/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.7619e-04\n",
            "Epoch 147: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 4.7384e-04 - val_loss: 4.1317e-04\n",
            "Epoch 148/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.5603e-04\n",
            "Epoch 148: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.5500e-04 - val_loss: 3.0606e-04\n",
            "Epoch 149/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.8737e-04\n",
            "Epoch 149: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.8688e-04 - val_loss: 3.3563e-04\n",
            "Epoch 150/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.2083e-04\n",
            "Epoch 150: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2035e-04 - val_loss: 9.4457e-04\n",
            "Epoch 151/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.8833e-04\n",
            "Epoch 151: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 3.9178e-04 - val_loss: 4.7919e-04\n",
            "Epoch 152/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.1520e-04\n",
            "Epoch 152: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 4.1617e-04 - val_loss: 3.1098e-04\n",
            "Epoch 153/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.1071e-04\n",
            "Epoch 153: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 4.0972e-04 - val_loss: 3.6458e-04\n",
            "Epoch 154/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.8751e-04\n",
            "Epoch 154: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 3.8751e-04 - val_loss: 3.1626e-04\n",
            "Epoch 155/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.8600e-04\n",
            "Epoch 155: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.8623e-04 - val_loss: 0.0027\n",
            "Epoch 156/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.0461e-04\n",
            "Epoch 156: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 4.0176e-04 - val_loss: 0.0014\n",
            "Epoch 157/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.2590e-04\n",
            "Epoch 157: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 23ms/step - loss: 4.2590e-04 - val_loss: 8.5628e-04\n",
            "Epoch 158/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.9052e-04\n",
            "Epoch 158: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.8955e-04 - val_loss: 9.0911e-04\n",
            "Epoch 159/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.9366e-04\n",
            "Epoch 159: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 3.9047e-04 - val_loss: 5.7530e-04\n",
            "Epoch 160/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.1506e-04\n",
            "Epoch 160: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 4.1407e-04 - val_loss: 0.0019\n",
            "Epoch 161/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.0144e-04\n",
            "Epoch 161: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 4.0231e-04 - val_loss: 0.0011\n",
            "Epoch 162/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.5717e-04\n",
            "Epoch 162: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 4.4455e-04 - val_loss: 5.0419e-04\n",
            "Epoch 163/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.7471e-04\n",
            "Epoch 163: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.8948e-04 - val_loss: 0.0017\n",
            "Epoch 164/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.9923e-04\n",
            "Epoch 164: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.9321e-04 - val_loss: 5.7710e-04\n",
            "Epoch 165/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.5750e-04\n",
            "Epoch 165: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.5750e-04 - val_loss: 0.0021\n",
            "Epoch 166/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.9820e-04\n",
            "Epoch 166: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.9820e-04 - val_loss: 0.0014\n",
            "Epoch 167/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.3046e-04\n",
            "Epoch 167: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 4.2676e-04 - val_loss: 3.0113e-04\n",
            "Epoch 168/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.7573e-04\n",
            "Epoch 168: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.8912e-04 - val_loss: 3.1622e-04\n",
            "Epoch 169/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.6445e-04\n",
            "Epoch 169: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 18ms/step - loss: 3.6681e-04 - val_loss: 9.9965e-04\n",
            "Epoch 170/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.7892e-04\n",
            "Epoch 170: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.8086e-04 - val_loss: 0.0014\n",
            "Epoch 171/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.5192e-04\n",
            "Epoch 171: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.5252e-04 - val_loss: 0.0012\n",
            "Epoch 172/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.9315e-04\n",
            "Epoch 172: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.1063e-04 - val_loss: 3.4096e-04\n",
            "Epoch 173/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.9227e-04\n",
            "Epoch 173: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.8640e-04 - val_loss: 3.0762e-04\n",
            "Epoch 174/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.1344e-04\n",
            "Epoch 174: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.1758e-04 - val_loss: 0.0022\n",
            "Epoch 175/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6509e-04\n",
            "Epoch 175: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6318e-04 - val_loss: 0.0017\n",
            "Epoch 176/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.8101e-04\n",
            "Epoch 176: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.7979e-04 - val_loss: 0.0049\n",
            "Epoch 177/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.9058e-04\n",
            "Epoch 177: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9187e-04 - val_loss: 0.0012\n",
            "Epoch 178/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.6565e-04\n",
            "Epoch 178: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.6337e-04 - val_loss: 4.8821e-04\n",
            "Epoch 179/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.1411e-04\n",
            "Epoch 179: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.1349e-04 - val_loss: 0.0012\n",
            "Epoch 180/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.9664e-04\n",
            "Epoch 180: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.9853e-04 - val_loss: 2.9968e-04\n",
            "Epoch 181/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.7926e-04\n",
            "Epoch 181: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.9099e-04 - val_loss: 5.1765e-04\n",
            "Epoch 182/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.8827e-04\n",
            "Epoch 182: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.8827e-04 - val_loss: 4.6755e-04\n",
            "Epoch 183/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.5850e-04\n",
            "Epoch 183: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5850e-04 - val_loss: 9.3228e-04\n",
            "Epoch 184/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.9845e-04\n",
            "Epoch 184: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.9845e-04 - val_loss: 5.8791e-04\n",
            "Epoch 185/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.9391e-04\n",
            "Epoch 185: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.9400e-04 - val_loss: 0.0020\n",
            "Epoch 186/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.8784e-04\n",
            "Epoch 186: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.8784e-04 - val_loss: 0.0017\n",
            "Epoch 187/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.7607e-04\n",
            "Epoch 187: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.7218e-04 - val_loss: 6.4768e-04\n",
            "Epoch 188/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.0679e-04\n",
            "Epoch 188: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 4.0847e-04 - val_loss: 0.0030\n",
            "Epoch 189/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.9097e-04\n",
            "Epoch 189: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9398e-04 - val_loss: 0.0011\n",
            "Epoch 190/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.9978e-04\n",
            "Epoch 190: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9978e-04 - val_loss: 0.0025\n",
            "Epoch 191/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.2595e-04\n",
            "Epoch 191: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.2595e-04 - val_loss: 0.0012\n",
            "Epoch 192/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.6346e-04\n",
            "Epoch 192: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6668e-04 - val_loss: 5.2643e-04\n",
            "Epoch 193/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.6786e-04\n",
            "Epoch 193: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6786e-04 - val_loss: 4.2725e-04\n",
            "Epoch 194/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.1595e-04\n",
            "Epoch 194: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.1591e-04 - val_loss: 0.0012\n",
            "Epoch 195/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.8025e-04\n",
            "Epoch 195: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.8210e-04 - val_loss: 0.0011\n",
            "Epoch 196/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.0745e-04\n",
            "Epoch 196: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.0745e-04 - val_loss: 7.6526e-04\n",
            "Epoch 197/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.8750e-04\n",
            "Epoch 197: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.8750e-04 - val_loss: 4.9004e-04\n",
            "Epoch 198/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 4.4529e-04\n",
            "Epoch 198: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.3782e-04 - val_loss: 0.0014\n",
            "Epoch 199/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.8656e-04\n",
            "Epoch 199: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.8367e-04 - val_loss: 0.0022\n",
            "Epoch 200/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.4767e-04\n",
            "Epoch 200: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4767e-04 - val_loss: 0.0013\n",
            "Epoch 201/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.4378e-04\n",
            "Epoch 201: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4815e-04 - val_loss: 9.9812e-04\n",
            "Epoch 202/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6172e-04\n",
            "Epoch 202: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6106e-04 - val_loss: 0.0019\n",
            "Epoch 203/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.2604e-04\n",
            "Epoch 203: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.2970e-04 - val_loss: 0.0024\n",
            "Epoch 204/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.4588e-04\n",
            "Epoch 204: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4518e-04 - val_loss: 0.0021\n",
            "Epoch 205/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.6912e-04\n",
            "Epoch 205: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.6753e-04 - val_loss: 0.0041\n",
            "Epoch 206/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.8767e-04\n",
            "Epoch 206: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.9663e-04 - val_loss: 0.0012\n",
            "Epoch 207/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.1069e-04\n",
            "Epoch 207: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 4.0867e-04 - val_loss: 0.0017\n",
            "Epoch 208/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6036e-04\n",
            "Epoch 208: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.6040e-04 - val_loss: 0.0013\n",
            "Epoch 209/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.1411e-04\n",
            "Epoch 209: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.1411e-04 - val_loss: 0.0017\n",
            "Epoch 210/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.3794e-04\n",
            "Epoch 210: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.3643e-04 - val_loss: 0.0054\n",
            "Epoch 211/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.2048e-04\n",
            "Epoch 211: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.2048e-04 - val_loss: 0.0025\n",
            "Epoch 212/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.9397e-04\n",
            "Epoch 212: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9397e-04 - val_loss: 0.0017\n",
            "Epoch 213/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.8340e-04\n",
            "Epoch 213: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.9090e-04 - val_loss: 0.0023\n",
            "Epoch 214/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.7127e-04\n",
            "Epoch 214: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 23ms/step - loss: 3.7274e-04 - val_loss: 0.0014\n",
            "Epoch 215/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.9328e-04\n",
            "Epoch 215: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.8979e-04 - val_loss: 0.0010\n",
            "Epoch 216/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.4419e-04\n",
            "Epoch 216: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4077e-04 - val_loss: 6.2494e-04\n",
            "Epoch 217/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.0747e-04\n",
            "Epoch 217: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.0775e-04 - val_loss: 9.5072e-04\n",
            "Epoch 218/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.1427e-04\n",
            "Epoch 218: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.1329e-04 - val_loss: 0.0011\n",
            "Epoch 219/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.7454e-04\n",
            "Epoch 219: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7288e-04 - val_loss: 0.0015\n",
            "Epoch 220/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.9242e-04\n",
            "Epoch 220: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.9030e-04 - val_loss: 0.0013\n",
            "Epoch 221/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.0440e-04\n",
            "Epoch 221: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9721e-04 - val_loss: 8.9621e-04\n",
            "Epoch 222/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.1549e-04\n",
            "Epoch 222: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.1708e-04 - val_loss: 0.0023\n",
            "Epoch 223/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 5.0349e-04\n",
            "Epoch 223: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.9522e-04 - val_loss: 0.0014\n",
            "Epoch 224/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.4022e-04\n",
            "Epoch 224: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.4285e-04 - val_loss: 0.0046\n",
            "Epoch 225/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.8183e-04\n",
            "Epoch 225: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.7993e-04 - val_loss: 0.0016\n",
            "Epoch 226/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.5155e-04\n",
            "Epoch 226: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.5155e-04 - val_loss: 0.0028\n",
            "Epoch 227/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6414e-04\n",
            "Epoch 227: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.6560e-04 - val_loss: 0.0032\n",
            "Epoch 228/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 4.2749e-04\n",
            "Epoch 228: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.1130e-04 - val_loss: 0.0017\n",
            "Epoch 229/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 4.1068e-04\n",
            "Epoch 229: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 4.3968e-04 - val_loss: 0.0023\n",
            "Epoch 230/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.0900e-04\n",
            "Epoch 230: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.0484e-04 - val_loss: 4.3179e-04\n",
            "Epoch 231/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.2321e-04\n",
            "Epoch 231: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.1808e-04 - val_loss: 8.1585e-04\n",
            "Epoch 232/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.7947e-04\n",
            "Epoch 232: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7617e-04 - val_loss: 8.7943e-04\n",
            "Epoch 233/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.0515e-04\n",
            "Epoch 233: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.0515e-04 - val_loss: 0.0070\n",
            "Epoch 234/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.9499e-04\n",
            "Epoch 234: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9376e-04 - val_loss: 0.0019\n",
            "Epoch 235/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.7696e-04\n",
            "Epoch 235: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.7237e-04 - val_loss: 0.0018\n",
            "Epoch 236/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.5992e-04\n",
            "Epoch 236: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5838e-04 - val_loss: 0.0022\n",
            "Epoch 237/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.4810e-04\n",
            "Epoch 237: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.4779e-04 - val_loss: 0.0029\n",
            "Epoch 238/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.9016e-04\n",
            "Epoch 238: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.8701e-04 - val_loss: 0.0012\n",
            "Epoch 239/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.0430e-04\n",
            "Epoch 239: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.0037e-04 - val_loss: 0.0016\n",
            "Epoch 240/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.8097e-04\n",
            "Epoch 240: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.8098e-04 - val_loss: 0.0016\n",
            "Epoch 241/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.4468e-04\n",
            "Epoch 241: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4398e-04 - val_loss: 0.0031\n",
            "Epoch 242/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.5114e-04\n",
            "Epoch 242: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5024e-04 - val_loss: 0.0034\n",
            "Epoch 243/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.7483e-04\n",
            "Epoch 243: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.8218e-04 - val_loss: 0.0027\n",
            "Epoch 244/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6700e-04\n",
            "Epoch 244: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.7810e-04 - val_loss: 0.0030\n",
            "Epoch 245/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.6694e-04\n",
            "Epoch 245: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.6671e-04 - val_loss: 0.0027\n",
            "Epoch 246/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.9227e-04\n",
            "Epoch 246: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.0442e-04 - val_loss: 0.0025\n",
            "Epoch 247/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.1271e-04\n",
            "Epoch 247: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.1109e-04 - val_loss: 0.0025\n",
            "Epoch 248/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.9666e-04\n",
            "Epoch 248: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.9666e-04 - val_loss: 0.0028\n",
            "Epoch 249/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.6367e-04\n",
            "Epoch 249: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6241e-04 - val_loss: 0.0037\n",
            "Epoch 250/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6833e-04\n",
            "Epoch 250: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7039e-04 - val_loss: 7.6932e-04\n",
            "Epoch 251/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.7935e-04\n",
            "Epoch 251: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7935e-04 - val_loss: 8.1806e-04\n",
            "Epoch 252/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.6812e-04\n",
            "Epoch 252: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.5891e-04 - val_loss: 0.0031\n",
            "Epoch 253/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.5094e-04\n",
            "Epoch 253: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5900e-04 - val_loss: 0.0044\n",
            "Epoch 254/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.8572e-04\n",
            "Epoch 254: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.9109e-04 - val_loss: 7.7619e-04\n",
            "Epoch 255/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.5644e-04\n",
            "Epoch 255: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.5397e-04 - val_loss: 0.0027\n",
            "Epoch 256/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.2331e-04\n",
            "Epoch 256: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.2371e-04 - val_loss: 0.0010\n",
            "Epoch 257/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.5220e-04\n",
            "Epoch 257: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5593e-04 - val_loss: 0.0014\n",
            "Epoch 258/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.5365e-04\n",
            "Epoch 258: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4593e-04 - val_loss: 6.8958e-04\n",
            "Epoch 259/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.8700e-04\n",
            "Epoch 259: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9119e-04 - val_loss: 0.0012\n",
            "Epoch 260/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.1179e-04\n",
            "Epoch 260: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.0681e-04 - val_loss: 7.6183e-04\n",
            "Epoch 261/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.3191e-04\n",
            "Epoch 261: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3191e-04 - val_loss: 0.0023\n",
            "Epoch 262/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.1475e-04\n",
            "Epoch 262: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.2173e-04 - val_loss: 0.0021\n",
            "Epoch 263/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.5756e-04\n",
            "Epoch 263: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6100e-04 - val_loss: 5.4867e-04\n",
            "Epoch 264/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.1389e-04\n",
            "Epoch 264: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.0855e-04 - val_loss: 0.0038\n",
            "Epoch 265/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.8981e-04\n",
            "Epoch 265: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8492e-04 - val_loss: 0.0011\n",
            "Epoch 266/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.6828e-04\n",
            "Epoch 266: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.6473e-04 - val_loss: 0.0026\n",
            "Epoch 267/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.6003e-04\n",
            "Epoch 267: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.6371e-04 - val_loss: 0.0032\n",
            "Epoch 268/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.1659e-04\n",
            "Epoch 268: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.1624e-04 - val_loss: 0.0026\n",
            "Epoch 269/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.6865e-04\n",
            "Epoch 269: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7338e-04 - val_loss: 0.0034\n",
            "Epoch 270/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.8162e-04\n",
            "Epoch 270: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.8162e-04 - val_loss: 0.0014\n",
            "Epoch 271/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.8736e-04\n",
            "Epoch 271: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.8205e-04 - val_loss: 0.0023\n",
            "Epoch 272/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.3232e-04\n",
            "Epoch 272: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.2925e-04 - val_loss: 9.4822e-04\n",
            "Epoch 273/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.5635e-04\n",
            "Epoch 273: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5474e-04 - val_loss: 6.4621e-04\n",
            "Epoch 274/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.5736e-04\n",
            "Epoch 274: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6311e-04 - val_loss: 9.7833e-04\n",
            "Epoch 275/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.3497e-04\n",
            "Epoch 275: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3359e-04 - val_loss: 0.0024\n",
            "Epoch 276/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6080e-04\n",
            "Epoch 276: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5873e-04 - val_loss: 6.6848e-04\n",
            "Epoch 277/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.6031e-04\n",
            "Epoch 277: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.6031e-04 - val_loss: 5.5287e-04\n",
            "Epoch 278/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.8443e-04\n",
            "Epoch 278: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.8291e-04 - val_loss: 0.0059\n",
            "Epoch 279/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 4.6968e-04\n",
            "Epoch 279: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.5788e-04 - val_loss: 0.0021\n",
            "Epoch 280/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6747e-04\n",
            "Epoch 280: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6734e-04 - val_loss: 0.0013\n",
            "Epoch 281/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.6706e-04\n",
            "Epoch 281: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6854e-04 - val_loss: 0.0019\n",
            "Epoch 282/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.6721e-04\n",
            "Epoch 282: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6578e-04 - val_loss: 0.0029\n",
            "Epoch 283/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.7657e-04\n",
            "Epoch 283: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7779e-04 - val_loss: 0.0013\n",
            "Epoch 284/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.5824e-04\n",
            "Epoch 284: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6186e-04 - val_loss: 5.8819e-04\n",
            "Epoch 285/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.8635e-04\n",
            "Epoch 285: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.8635e-04 - val_loss: 0.0022\n",
            "Epoch 286/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.4045e-04\n",
            "Epoch 286: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.4168e-04 - val_loss: 0.0032\n",
            "Epoch 287/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.6595e-04\n",
            "Epoch 287: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.6848e-04 - val_loss: 4.0527e-04\n",
            "Epoch 288/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.9231e-04\n",
            "Epoch 288: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.8887e-04 - val_loss: 0.0021\n",
            "Epoch 289/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.8010e-04\n",
            "Epoch 289: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.7949e-04 - val_loss: 0.0012\n",
            "Epoch 290/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.9674e-04\n",
            "Epoch 290: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.8866e-04 - val_loss: 0.0044\n",
            "Epoch 291/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.7088e-04\n",
            "Epoch 291: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7726e-04 - val_loss: 7.7329e-04\n",
            "Epoch 292/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.8094e-04\n",
            "Epoch 292: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7287e-04 - val_loss: 0.0037\n",
            "Epoch 293/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.7134e-04\n",
            "Epoch 293: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7134e-04 - val_loss: 0.0032\n",
            "Epoch 294/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.9451e-04\n",
            "Epoch 294: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.9251e-04 - val_loss: 0.0027\n",
            "Epoch 295/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.7458e-04\n",
            "Epoch 295: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7333e-04 - val_loss: 0.0032\n",
            "Epoch 296/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.6425e-04\n",
            "Epoch 296: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6425e-04 - val_loss: 0.0024\n",
            "Epoch 297/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.5939e-04\n",
            "Epoch 297: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5238e-04 - val_loss: 0.0013\n",
            "Epoch 298/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.7002e-04\n",
            "Epoch 298: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6976e-04 - val_loss: 0.0011\n",
            "Epoch 299/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.7993e-04\n",
            "Epoch 299: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6784e-04 - val_loss: 0.0018\n",
            "Epoch 300/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6653e-04\n",
            "Epoch 300: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7031e-04 - val_loss: 9.1344e-04\n",
            "Epoch 301/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.5707e-04\n",
            "Epoch 301: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.5392e-04 - val_loss: 0.0023\n",
            "Epoch 302/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.4042e-04\n",
            "Epoch 302: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4042e-04 - val_loss: 0.0015\n",
            "Epoch 303/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.6598e-04\n",
            "Epoch 303: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6549e-04 - val_loss: 0.0028\n",
            "Epoch 304/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.4513e-04\n",
            "Epoch 304: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4856e-04 - val_loss: 5.4500e-04\n",
            "Epoch 305/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.6216e-04\n",
            "Epoch 305: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.6152e-04 - val_loss: 0.0014\n",
            "Epoch 306/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.3144e-04\n",
            "Epoch 306: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.3071e-04 - val_loss: 0.0017\n",
            "Epoch 307/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.7813e-04\n",
            "Epoch 307: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.7971e-04 - val_loss: 0.0010\n",
            "Epoch 308/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6873e-04\n",
            "Epoch 308: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.6720e-04 - val_loss: 0.0011\n",
            "Epoch 309/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.4354e-04\n",
            "Epoch 309: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.5517e-04 - val_loss: 0.0017\n",
            "Epoch 310/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.8038e-04\n",
            "Epoch 310: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.8103e-04 - val_loss: 0.0053\n",
            "Epoch 311/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.8991e-04\n",
            "Epoch 311: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.8831e-04 - val_loss: 0.0033\n",
            "Epoch 312/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.2322e-04\n",
            "Epoch 312: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.2322e-04 - val_loss: 0.0042\n",
            "Epoch 313/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.2008e-04\n",
            "Epoch 313: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.1999e-04 - val_loss: 0.0030\n",
            "Epoch 314/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.7722e-04\n",
            "Epoch 314: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.7969e-04 - val_loss: 9.6090e-04\n",
            "Epoch 315/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.5451e-04\n",
            "Epoch 315: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5425e-04 - val_loss: 0.0037\n",
            "Epoch 316/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.2693e-04\n",
            "Epoch 316: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2704e-04 - val_loss: 0.0028\n",
            "Epoch 317/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.7051e-04\n",
            "Epoch 317: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6571e-04 - val_loss: 0.0042\n",
            "Epoch 318/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.8725e-04\n",
            "Epoch 318: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.8542e-04 - val_loss: 0.0015\n",
            "Epoch 319/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.4427e-04\n",
            "Epoch 319: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4275e-04 - val_loss: 0.0014\n",
            "Epoch 320/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.9858e-04\n",
            "Epoch 320: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.9858e-04 - val_loss: 0.0016\n",
            "Epoch 321/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.5462e-04\n",
            "Epoch 321: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6077e-04 - val_loss: 0.0029\n",
            "Epoch 322/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.1706e-04\n",
            "Epoch 322: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.1009e-04 - val_loss: 0.0018\n",
            "Epoch 323/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.3172e-04\n",
            "Epoch 323: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2694e-04 - val_loss: 0.0031\n",
            "Epoch 324/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.0974e-04\n",
            "Epoch 324: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1169e-04 - val_loss: 0.0031\n",
            "Epoch 325/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.2580e-04\n",
            "Epoch 325: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.2270e-04 - val_loss: 0.0022\n",
            "Epoch 326/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.3188e-04\n",
            "Epoch 326: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.3650e-04 - val_loss: 7.1626e-04\n",
            "Epoch 327/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.7627e-04\n",
            "Epoch 327: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.7645e-04 - val_loss: 7.3871e-04\n",
            "Epoch 328/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.4273e-04\n",
            "Epoch 328: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.4285e-04 - val_loss: 0.0018\n",
            "Epoch 329/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 4.2150e-04\n",
            "Epoch 329: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 4.1490e-04 - val_loss: 0.0016\n",
            "Epoch 330/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.1521e-04\n",
            "Epoch 330: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.1487e-04 - val_loss: 6.9637e-04\n",
            "Epoch 331/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 4.0627e-04\n",
            "Epoch 331: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.9849e-04 - val_loss: 0.0017\n",
            "Epoch 332/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.6648e-04\n",
            "Epoch 332: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.6648e-04 - val_loss: 0.0068\n",
            "Epoch 333/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.9861e-04\n",
            "Epoch 333: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.9797e-04 - val_loss: 0.0026\n",
            "Epoch 334/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.4435e-04\n",
            "Epoch 334: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.4435e-04 - val_loss: 0.0057\n",
            "Epoch 335/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.2213e-04\n",
            "Epoch 335: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.1257e-04 - val_loss: 0.0029\n",
            "Epoch 336/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.6073e-04\n",
            "Epoch 336: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5841e-04 - val_loss: 0.0018\n",
            "Epoch 337/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.8190e-04\n",
            "Epoch 337: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 23ms/step - loss: 3.8190e-04 - val_loss: 9.8890e-04\n",
            "Epoch 338/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.1698e-04\n",
            "Epoch 338: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.1764e-04 - val_loss: 0.0012\n",
            "Epoch 339/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.6527e-04\n",
            "Epoch 339: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.6205e-04 - val_loss: 0.0022\n",
            "Epoch 340/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.7788e-04\n",
            "Epoch 340: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7623e-04 - val_loss: 0.0021\n",
            "Epoch 341/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.5051e-04\n",
            "Epoch 341: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4739e-04 - val_loss: 0.0034\n",
            "Epoch 342/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.4307e-04\n",
            "Epoch 342: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4275e-04 - val_loss: 0.0013\n",
            "Epoch 343/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.4522e-04\n",
            "Epoch 343: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.4522e-04 - val_loss: 0.0023\n",
            "Epoch 344/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.3773e-04\n",
            "Epoch 344: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.3664e-04 - val_loss: 0.0022\n",
            "Epoch 345/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.9599e-04\n",
            "Epoch 345: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.9599e-04 - val_loss: 0.0031\n",
            "Epoch 346/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.6640e-04\n",
            "Epoch 346: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.6640e-04 - val_loss: 0.0027\n",
            "Epoch 347/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.4117e-04\n",
            "Epoch 347: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.4475e-04 - val_loss: 0.0014\n",
            "Epoch 348/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.3331e-04\n",
            "Epoch 348: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3161e-04 - val_loss: 0.0034\n",
            "Epoch 349/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.3354e-04\n",
            "Epoch 349: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3294e-04 - val_loss: 0.0071\n",
            "Epoch 350/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.4760e-04\n",
            "Epoch 350: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4760e-04 - val_loss: 0.0027\n",
            "Epoch 351/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.6964e-04\n",
            "Epoch 351: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.6908e-04 - val_loss: 0.0028\n",
            "Epoch 352/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.6280e-04\n",
            "Epoch 352: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.6422e-04 - val_loss: 0.0012\n",
            "Epoch 353/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.0021e-04\n",
            "Epoch 353: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.0151e-04 - val_loss: 0.0030\n",
            "Epoch 354/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.5782e-04\n",
            "Epoch 354: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5775e-04 - val_loss: 0.0018\n",
            "Epoch 355/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.2799e-04\n",
            "Epoch 355: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.2201e-04 - val_loss: 0.0020\n",
            "Epoch 356/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.5458e-04\n",
            "Epoch 356: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5326e-04 - val_loss: 0.0028\n",
            "Epoch 357/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.1859e-04\n",
            "Epoch 357: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.1450e-04 - val_loss: 9.7508e-04\n",
            "Epoch 358/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.3437e-04\n",
            "Epoch 358: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3070e-04 - val_loss: 0.0019\n",
            "Epoch 359/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.2873e-04\n",
            "Epoch 359: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3321e-04 - val_loss: 0.0043\n",
            "Epoch 360/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.6516e-04\n",
            "Epoch 360: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6158e-04 - val_loss: 0.0015\n",
            "Epoch 361/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.2608e-04\n",
            "Epoch 361: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3261e-04 - val_loss: 0.0023\n",
            "Epoch 362/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.6578e-04\n",
            "Epoch 362: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5748e-04 - val_loss: 8.7990e-04\n",
            "Epoch 363/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.5048e-04\n",
            "Epoch 363: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4855e-04 - val_loss: 0.0039\n",
            "Epoch 364/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 4.1057e-04\n",
            "Epoch 364: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 4.0308e-04 - val_loss: 0.0030\n",
            "Epoch 365/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.8232e-04\n",
            "Epoch 365: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.8606e-04 - val_loss: 0.0027\n",
            "Epoch 366/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6654e-04\n",
            "Epoch 366: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.6409e-04 - val_loss: 0.0025\n",
            "Epoch 367/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.2940e-04\n",
            "Epoch 367: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.2876e-04 - val_loss: 0.0013\n",
            "Epoch 368/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.0813e-04\n",
            "Epoch 368: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1115e-04 - val_loss: 0.0021\n",
            "Epoch 369/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.4416e-04\n",
            "Epoch 369: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4247e-04 - val_loss: 0.0024\n",
            "Epoch 370/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.8270e-04\n",
            "Epoch 370: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.8270e-04 - val_loss: 0.0022\n",
            "Epoch 371/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.7973e-04\n",
            "Epoch 371: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7973e-04 - val_loss: 0.0012\n",
            "Epoch 372/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.4494e-04\n",
            "Epoch 372: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4147e-04 - val_loss: 0.0013\n",
            "Epoch 373/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.2974e-04\n",
            "Epoch 373: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3017e-04 - val_loss: 0.0016\n",
            "Epoch 374/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.8024e-04\n",
            "Epoch 374: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7277e-04 - val_loss: 0.0029\n",
            "Epoch 375/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.0080e-04\n",
            "Epoch 375: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 2.9706e-04 - val_loss: 0.0026\n",
            "Epoch 376/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6130e-04\n",
            "Epoch 376: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5837e-04 - val_loss: 5.9321e-04\n",
            "Epoch 377/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.3145e-04\n",
            "Epoch 377: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2984e-04 - val_loss: 0.0068\n",
            "Epoch 378/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.7481e-04\n",
            "Epoch 378: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.8981e-04 - val_loss: 9.8483e-04\n",
            "Epoch 379/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.5962e-04\n",
            "Epoch 379: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.6162e-04 - val_loss: 0.0068\n",
            "Epoch 380/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.5195e-04\n",
            "Epoch 380: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.5508e-04 - val_loss: 0.0022\n",
            "Epoch 381/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 4.2745e-04\n",
            "Epoch 381: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 4.2745e-04 - val_loss: 0.0015\n",
            "Epoch 382/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.0788e-04\n",
            "Epoch 382: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.0875e-04 - val_loss: 0.0031\n",
            "Epoch 383/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.2854e-04\n",
            "Epoch 383: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.2874e-04 - val_loss: 7.5509e-04\n",
            "Epoch 384/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.7556e-04\n",
            "Epoch 384: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.7372e-04 - val_loss: 0.0020\n",
            "Epoch 385/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.1679e-04\n",
            "Epoch 385: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.1580e-04 - val_loss: 0.0014\n",
            "Epoch 386/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.3456e-04\n",
            "Epoch 386: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.3634e-04 - val_loss: 0.0016\n",
            "Epoch 387/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.7080e-04\n",
            "Epoch 387: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.7726e-04 - val_loss: 0.0032\n",
            "Epoch 388/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.7342e-04\n",
            "Epoch 388: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6324e-04 - val_loss: 0.0016\n",
            "Epoch 389/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.3240e-04\n",
            "Epoch 389: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3148e-04 - val_loss: 0.0012\n",
            "Epoch 390/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.3845e-04\n",
            "Epoch 390: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3959e-04 - val_loss: 0.0036\n",
            "Epoch 391/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.2824e-04\n",
            "Epoch 391: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.2249e-04 - val_loss: 0.0038\n",
            "Epoch 392/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.4971e-04\n",
            "Epoch 392: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4971e-04 - val_loss: 0.0017\n",
            "Epoch 393/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.3940e-04\n",
            "Epoch 393: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3940e-04 - val_loss: 0.0016\n",
            "Epoch 394/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.3405e-04\n",
            "Epoch 394: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3048e-04 - val_loss: 0.0042\n",
            "Epoch 395/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.5102e-04\n",
            "Epoch 395: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4749e-04 - val_loss: 0.0029\n",
            "Epoch 396/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.5413e-04\n",
            "Epoch 396: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5413e-04 - val_loss: 0.0023\n",
            "Epoch 397/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.4639e-04\n",
            "Epoch 397: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4668e-04 - val_loss: 0.0019\n",
            "Epoch 398/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.6450e-04\n",
            "Epoch 398: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5759e-04 - val_loss: 0.0017\n",
            "Epoch 399/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.2830e-04\n",
            "Epoch 399: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2771e-04 - val_loss: 0.0023\n",
            "Epoch 400/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.4247e-04\n",
            "Epoch 400: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4176e-04 - val_loss: 7.5260e-04\n",
            "Epoch 401/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.3241e-04\n",
            "Epoch 401: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3173e-04 - val_loss: 0.0019\n",
            "Epoch 402/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6721e-04\n",
            "Epoch 402: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.6251e-04 - val_loss: 0.0020\n",
            "Epoch 403/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.5801e-04\n",
            "Epoch 403: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.5801e-04 - val_loss: 0.0018\n",
            "Epoch 404/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.7781e-04\n",
            "Epoch 404: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.7348e-04 - val_loss: 0.0025\n",
            "Epoch 405/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.5525e-04\n",
            "Epoch 405: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.5525e-04 - val_loss: 6.7475e-04\n",
            "Epoch 406/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.5160e-04\n",
            "Epoch 406: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5160e-04 - val_loss: 0.0018\n",
            "Epoch 407/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.7796e-04\n",
            "Epoch 407: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.7745e-04 - val_loss: 0.0038\n",
            "Epoch 408/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.3855e-04\n",
            "Epoch 408: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3443e-04 - val_loss: 0.0015\n",
            "Epoch 409/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.4502e-04\n",
            "Epoch 409: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4502e-04 - val_loss: 0.0041\n",
            "Epoch 410/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.3075e-04\n",
            "Epoch 410: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3230e-04 - val_loss: 0.0027\n",
            "Epoch 411/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.5516e-04\n",
            "Epoch 411: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 3.5337e-04 - val_loss: 0.0025\n",
            "Epoch 412/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.4070e-04\n",
            "Epoch 412: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3907e-04 - val_loss: 0.0024\n",
            "Epoch 413/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.7367e-04\n",
            "Epoch 413: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.7310e-04 - val_loss: 0.0038\n",
            "Epoch 414/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.4900e-04\n",
            "Epoch 414: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4239e-04 - val_loss: 0.0017\n",
            "Epoch 415/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.3556e-04\n",
            "Epoch 415: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3585e-04 - val_loss: 0.0013\n",
            "Epoch 416/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.6597e-04\n",
            "Epoch 416: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.6310e-04 - val_loss: 0.0023\n",
            "Epoch 417/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.1499e-04\n",
            "Epoch 417: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.1671e-04 - val_loss: 0.0014\n",
            "Epoch 418/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.1892e-04\n",
            "Epoch 418: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.2212e-04 - val_loss: 0.0035\n",
            "Epoch 419/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.3715e-04\n",
            "Epoch 419: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3607e-04 - val_loss: 0.0041\n",
            "Epoch 420/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.6869e-04\n",
            "Epoch 420: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6869e-04 - val_loss: 0.0018\n",
            "Epoch 421/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.2594e-04\n",
            "Epoch 421: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3121e-04 - val_loss: 9.0678e-04\n",
            "Epoch 422/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.6899e-04\n",
            "Epoch 422: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6687e-04 - val_loss: 0.0022\n",
            "Epoch 423/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.6765e-04\n",
            "Epoch 423: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.6324e-04 - val_loss: 0.0034\n",
            "Epoch 424/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.5448e-04\n",
            "Epoch 424: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.5448e-04 - val_loss: 0.0018\n",
            "Epoch 425/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.2223e-04\n",
            "Epoch 425: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.2247e-04 - val_loss: 0.0021\n",
            "Epoch 426/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.8084e-04\n",
            "Epoch 426: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.7841e-04 - val_loss: 0.0024\n",
            "Epoch 427/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.3207e-04\n",
            "Epoch 427: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.3723e-04 - val_loss: 0.0016\n",
            "Epoch 428/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.4593e-04\n",
            "Epoch 428: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.4431e-04 - val_loss: 0.0014\n",
            "Epoch 429/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.4036e-04\n",
            "Epoch 429: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3786e-04 - val_loss: 0.0021\n",
            "Epoch 430/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.2141e-04\n",
            "Epoch 430: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3113e-04 - val_loss: 0.0021\n",
            "Epoch 431/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.6582e-04\n",
            "Epoch 431: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6239e-04 - val_loss: 0.0030\n",
            "Epoch 432/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.1448e-04\n",
            "Epoch 432: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.1429e-04 - val_loss: 0.0037\n",
            "Epoch 433/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.1714e-04\n",
            "Epoch 433: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1830e-04 - val_loss: 0.0015\n",
            "Epoch 434/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.7038e-04\n",
            "Epoch 434: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6772e-04 - val_loss: 0.0021\n",
            "Epoch 435/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.6751e-04\n",
            "Epoch 435: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6446e-04 - val_loss: 0.0012\n",
            "Epoch 436/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.1633e-04\n",
            "Epoch 436: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.1772e-04 - val_loss: 0.0021\n",
            "Epoch 437/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.6827e-04\n",
            "Epoch 437: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6827e-04 - val_loss: 6.2064e-04\n",
            "Epoch 438/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.6295e-04\n",
            "Epoch 438: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6295e-04 - val_loss: 0.0033\n",
            "Epoch 439/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.0751e-04\n",
            "Epoch 439: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.0686e-04 - val_loss: 0.0014\n",
            "Epoch 440/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.4518e-04\n",
            "Epoch 440: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4589e-04 - val_loss: 0.0018\n",
            "Epoch 441/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.6647e-04\n",
            "Epoch 441: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.6647e-04 - val_loss: 0.0011\n",
            "Epoch 442/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 4.0907e-04\n",
            "Epoch 442: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 4.0457e-04 - val_loss: 6.0380e-04\n",
            "Epoch 443/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.4728e-04\n",
            "Epoch 443: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.4944e-04 - val_loss: 0.0010\n",
            "Epoch 444/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.2345e-04\n",
            "Epoch 444: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 16ms/step - loss: 3.2128e-04 - val_loss: 0.0016\n",
            "Epoch 445/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.4402e-04\n",
            "Epoch 445: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.4057e-04 - val_loss: 0.0024\n",
            "Epoch 446/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.4570e-04\n",
            "Epoch 446: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.5789e-04 - val_loss: 0.0020\n",
            "Epoch 447/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.5679e-04\n",
            "Epoch 447: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.5011e-04 - val_loss: 0.0014\n",
            "Epoch 448/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.4536e-04\n",
            "Epoch 448: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4536e-04 - val_loss: 0.0024\n",
            "Epoch 449/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.4188e-04\n",
            "Epoch 449: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.4069e-04 - val_loss: 0.0017\n",
            "Epoch 450/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.1449e-04\n",
            "Epoch 450: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2324e-04 - val_loss: 8.6364e-04\n",
            "Epoch 451/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.3015e-04\n",
            "Epoch 451: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3080e-04 - val_loss: 0.0016\n",
            "Epoch 452/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.2610e-04\n",
            "Epoch 452: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.2781e-04 - val_loss: 0.0016\n",
            "Epoch 453/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.3708e-04\n",
            "Epoch 453: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3367e-04 - val_loss: 0.0026\n",
            "Epoch 454/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.7372e-04\n",
            "Epoch 454: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.8243e-04 - val_loss: 8.3971e-04\n",
            "Epoch 455/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.3376e-04\n",
            "Epoch 455: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3904e-04 - val_loss: 0.0022\n",
            "Epoch 456/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.3727e-04\n",
            "Epoch 456: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3598e-04 - val_loss: 0.0022\n",
            "Epoch 457/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.3151e-04\n",
            "Epoch 457: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2929e-04 - val_loss: 9.2212e-04\n",
            "Epoch 458/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.6066e-04\n",
            "Epoch 458: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.5540e-04 - val_loss: 0.0011\n",
            "Epoch 459/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.3804e-04\n",
            "Epoch 459: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.3720e-04 - val_loss: 5.1519e-04\n",
            "Epoch 460/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.6050e-04\n",
            "Epoch 460: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5817e-04 - val_loss: 0.0012\n",
            "Epoch 461/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6790e-04\n",
            "Epoch 461: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.7020e-04 - val_loss: 0.0023\n",
            "Epoch 462/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.4569e-04\n",
            "Epoch 462: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4475e-04 - val_loss: 0.0017\n",
            "Epoch 463/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.2597e-04\n",
            "Epoch 463: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.2586e-04 - val_loss: 0.0016\n",
            "Epoch 464/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.0385e-04\n",
            "Epoch 464: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.0904e-04 - val_loss: 0.0038\n",
            "Epoch 465/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.5212e-04\n",
            "Epoch 465: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.5305e-04 - val_loss: 0.0017\n",
            "Epoch 466/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.5793e-04\n",
            "Epoch 466: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.6025e-04 - val_loss: 7.6103e-04\n",
            "Epoch 467/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.5793e-04\n",
            "Epoch 467: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 17ms/step - loss: 3.5681e-04 - val_loss: 0.0031\n",
            "Epoch 468/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.8365e-04\n",
            "Epoch 468: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.8319e-04 - val_loss: 0.0022\n",
            "Epoch 469/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.7733e-04\n",
            "Epoch 469: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.7562e-04 - val_loss: 4.9802e-04\n",
            "Epoch 470/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.3626e-04\n",
            "Epoch 470: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3902e-04 - val_loss: 0.0017\n",
            "Epoch 471/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.4772e-04\n",
            "Epoch 471: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4971e-04 - val_loss: 0.0012\n",
            "Epoch 472/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.1164e-04\n",
            "Epoch 472: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1072e-04 - val_loss: 6.6081e-04\n",
            "Epoch 473/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.5132e-04\n",
            "Epoch 473: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4845e-04 - val_loss: 8.2758e-04\n",
            "Epoch 474/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.9248e-04\n",
            "Epoch 474: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.9019e-04 - val_loss: 0.0058\n",
            "Epoch 475/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.6497e-04\n",
            "Epoch 475: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.6101e-04 - val_loss: 0.0015\n",
            "Epoch 476/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.2850e-04\n",
            "Epoch 476: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2648e-04 - val_loss: 0.0027\n",
            "Epoch 477/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.5942e-04\n",
            "Epoch 477: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.5942e-04 - val_loss: 4.8919e-04\n",
            "Epoch 478/500\n",
            "56/61 [==========================>...] - ETA: 0s - loss: 3.8645e-04\n",
            "Epoch 478: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.7792e-04 - val_loss: 0.0043\n",
            "Epoch 479/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.3611e-04\n",
            "Epoch 479: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.3367e-04 - val_loss: 8.2078e-04\n",
            "Epoch 480/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.6584e-04\n",
            "Epoch 480: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.6508e-04 - val_loss: 8.9454e-04\n",
            "Epoch 481/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.6076e-04\n",
            "Epoch 481: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.5967e-04 - val_loss: 0.0011\n",
            "Epoch 482/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 4.0882e-04\n",
            "Epoch 482: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 4.0823e-04 - val_loss: 0.0054\n",
            "Epoch 483/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.7692e-04\n",
            "Epoch 483: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.7692e-04 - val_loss: 0.0019\n",
            "Epoch 484/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.2790e-04\n",
            "Epoch 484: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.2846e-04 - val_loss: 0.0014\n",
            "Epoch 485/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.4639e-04\n",
            "Epoch 485: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.4537e-04 - val_loss: 0.0033\n",
            "Epoch 486/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.4512e-04\n",
            "Epoch 486: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.4045e-04 - val_loss: 0.0026\n",
            "Epoch 487/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.1575e-04\n",
            "Epoch 487: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 3.1381e-04 - val_loss: 0.0024\n",
            "Epoch 488/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.6654e-04\n",
            "Epoch 488: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 3.6623e-04 - val_loss: 0.0013\n",
            "Epoch 489/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.6839e-04\n",
            "Epoch 489: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.6839e-04 - val_loss: 0.0037\n",
            "Epoch 490/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.6338e-04\n",
            "Epoch 490: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.6125e-04 - val_loss: 0.0025\n",
            "Epoch 491/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.5298e-04\n",
            "Epoch 491: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.5298e-04 - val_loss: 0.0018\n",
            "Epoch 492/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.2374e-04\n",
            "Epoch 492: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2379e-04 - val_loss: 0.0047\n",
            "Epoch 493/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.5750e-04\n",
            "Epoch 493: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.5858e-04 - val_loss: 0.0014\n",
            "Epoch 494/500\n",
            "61/61 [==============================] - ETA: 0s - loss: 3.1951e-04\n",
            "Epoch 494: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.1951e-04 - val_loss: 0.0014\n",
            "Epoch 495/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.6205e-04\n",
            "Epoch 495: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.6023e-04 - val_loss: 0.0017\n",
            "Epoch 496/500\n",
            "57/61 [===========================>..] - ETA: 0s - loss: 3.2006e-04\n",
            "Epoch 496: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.1876e-04 - val_loss: 0.0022\n",
            "Epoch 497/500\n",
            "60/61 [============================>.] - ETA: 0s - loss: 3.2347e-04\n",
            "Epoch 497: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.2273e-04 - val_loss: 0.0017\n",
            "Epoch 498/500\n",
            "55/61 [==========================>...] - ETA: 0s - loss: 3.1555e-04\n",
            "Epoch 498: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.2397e-04 - val_loss: 0.0048\n",
            "Epoch 499/500\n",
            "59/61 [============================>.] - ETA: 0s - loss: 3.5044e-04\n",
            "Epoch 499: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 3.4872e-04 - val_loss: 0.0034\n",
            "Epoch 500/500\n",
            "58/61 [===========================>..] - ETA: 0s - loss: 3.3225e-04\n",
            "Epoch 500: val_loss did not improve from 0.00027\n",
            "61/61 [==============================] - 1s 12ms/step - loss: 3.3227e-04 - val_loss: 0.0021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Assuming you have prepared the new data for prediction as 'X_new'\n",
        "\n",
        "# Load the best model saved during training\n",
        "best_model = load_model('best_model.h5')\n",
        "\n",
        "# Make predictions using the loaded model\n",
        "y_pred = best_model.predict(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXB-oh14_deX",
        "outputId": "e11a4299-8073-4855-97c8-870c35f17d98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n"
      ],
      "metadata": {
        "id": "lvwMtzUN3mJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_oc = load_model('best_model_oc.h5')\n",
        "\n",
        "# Make predictions using the loaded model\n",
        "y_pred_oc = best_model_oc.predict(X_test_oc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKZDw_7W2Ost",
        "outputId": "3c63ea5a-ccc2-4661-b713-dc422a7effdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_ocl = load_model('best_model_ocl.h5')\n",
        "\n",
        "# Make predictions using the loaded model\n",
        "y_pred_ocl = best_model_ocl.predict(X_test_ocl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzpmoKOi55tv",
        "outputId": "82425f8b-1bdf-41e6-e500-3a9c970ed669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_oclh = load_model('best_model_oclh.h5')\n",
        "\n",
        "# Make predictions using the loaded model\n",
        "y_pred_oclh = best_model_oclh.predict(X_test_oclh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTGeqZP39Bqr",
        "outputId": "706a4275-ca5b-49c4-c18b-0061c5d1e39c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCY7KjJeaLOG",
        "outputId": "bc7f6c0b-9768-4fe9-f133-34ebe2fe18a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_oc = model_oc.predict(X_test_oc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HstwmGHO2UJa",
        "outputId": "572548ae-6da5-434d-870d-4d3609448dd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_ocl = model_ocl.predict(X_test_ocl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CgHltpl5_O3",
        "outputId": "b26f97cc-407d-4795-90c7-520676c3b5f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_oclh = model_oclh.predict(X_test_oclh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByXmYEu09HbM",
        "outputId": "fba2a810-b111-4cdb-b1ee-0049d043aaff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse = np.mean((y_test - y_pred)**2)\n",
        "print(\"Mean Squared Error:\", mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctC_PLSWahQd",
        "outputId": "b146e1cb-f5b1-4309-a47c-e9c37ed9ae0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.00778689936090019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse = np.mean((y_test_oc - y_pred_oc)**2)\n",
        "print(\"Mean Squared Error:\", mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiV4GbVF2YDo",
        "outputId": "ba8c5e80-33fa-4594-cfa3-5ce5787351c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.011166212217142008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse = np.mean((y_test_ocl - y_pred_ocl)**2)\n",
        "print(\"Mean Squared Error:\", mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "io6e1HCk6C0K",
        "outputId": "93a89946-1b4f-44e9-b19d-a0027581b902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.009066194603140084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse = np.mean((y_test_oclh - y_pred_oclh)**2)\n",
        "print(\"Mean Squared Error:\", mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvg2VnVM9MlT",
        "outputId": "5acda8cc-558e-43b7-bd74-2de3051b09a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.007613428963595096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score"
      ],
      "metadata": {
        "id": "bA9un9DpvVoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_val = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"R-squared :\", r2_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "8XeH8sBovpM4",
        "outputId": "7e6233b6-9ee5-496e-bdc3-889a8b184bf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-59ac9d8b9b22>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr2_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"R-squared :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r2_val = r2_score(y_test_oc, y_pred_oc)\n",
        "\n",
        "print(\"R-squared :\", r2_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jH7OB9cD2chf",
        "outputId": "8a75d2d8-6ce4-4394-8265-311d94ef7d48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R-squared : -0.036104112121917664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r2_val = r2_score(y_test_ocl, y_pred_ocl)\n",
        "\n",
        "print(\"R-squared :\", r2_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzhAT_zD6GLs",
        "outputId": "4be377f7-227c-48ce-d57a-037504cb5917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R-squared : 0.4897063770718614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r2_val = r2_score(y_test_oclh, y_pred_oclh)\n",
        "\n",
        "print(\"R-squared :\", r2_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Em7IHIko9QeM",
        "outputId": "8b189324-2829-41a9-a789-ba8326e24266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R-squared : 0.5472667040831455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_orig = scaler3.inverse_transform(y_pred.reshape(-1,1))\n",
        "y_test_orig = scaler3.inverse_transform(y_test.reshape(-1,1))\n",
        "y_train_orig= scaler3.inverse_transform(y_train.reshape(-1,1))"
      ],
      "metadata": {
        "id": "8GSKl1RVb0mR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_orig_oc = scaler3.inverse_transform(y_pred_oc.reshape(-1,1))\n",
        "y_test_orig_oc = scaler3.inverse_transform(y_test_oc.reshape(-1,1))\n",
        "y_train_orig_oc= scaler3.inverse_transform(y_train_oc.reshape(-1,1))"
      ],
      "metadata": {
        "id": "D8Pkqb6t2hkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_orig_ocl = scaler3.inverse_transform(y_pred_ocl.reshape(-1,1))\n",
        "y_test_orig_ocl = scaler3.inverse_transform(y_test_ocl.reshape(-1,1))\n",
        "y_train_orig_ocl= scaler3.inverse_transform(y_train_ocl.reshape(-1,1))"
      ],
      "metadata": {
        "id": "addGNBTf6JR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_orig_oclh = scaler3.inverse_transform(y_pred_oclh.reshape(-1,1))\n",
        "y_test_orig_oclh = scaler3.inverse_transform(y_test_oclh.reshape(-1,1))\n",
        "y_train_orig_oclh= scaler3.inverse_transform(y_train_oclh.reshape(-1,1))"
      ],
      "metadata": {
        "id": "WtobUoCP9T1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_index_train = np.arange(len(y_train))\n",
        "\n",
        "# Calculate the time_index for y_test and y_pred starting from the appropriate offset\n",
        "time_index_test = np.arange(len(y_test)) + len(y_train)\n",
        "time_index_pred = np.arange(len(y_pred)) + len(y_train)\n",
        "\n",
        "# Plot the true values (y_train), the test values (y_test), and the predicted values (y_pred)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(time_index_train, y_train_orig, label='Training Data', color='blue')\n",
        "plt.plot(time_index_test, y_test_orig, label='Test Data', color='green')\n",
        "plt.plot(time_index_pred, y_pred_orig, label='Predictions', color='red', linestyle='dashed')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Value')\n",
        "plt.title('True Values vs. Predictions')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PIEDcSew6wSk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "f7043850-74a5-4944-a780-b01eb941c14d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time_index_train = np.arange(len(y_train_oc))\n",
        "\n",
        "# Calculate the time_index for y_test and y_pred starting from the appropriate offset\n",
        "time_index_test = np.arange(len(y_test_oc)) + len(y_train_oc)\n",
        "time_index_pred = np.arange(len(y_pred_oc)) + len(y_train_oc)\n",
        "\n",
        "# Plot the true values (y_train), the test values (y_test), and the predicted values (y_pred)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(time_index_train, y_train_orig_oc, label='Training Data', color='blue')\n",
        "plt.plot(time_index_test, y_test_orig_oc, label='Test Data', color='green')\n",
        "plt.plot(time_index_pred, y_pred_orig_oc, label='Predictions', color='red', linestyle='dashed')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Value')\n",
        "plt.title('True Values vs. Predictions -- Open , Close')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "V7dnEglGe6g3",
        "outputId": "94de6271-632e-4e15-c1d4-c3f0d8275682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time_index_train = np.arange(len(y_train_ocl))\n",
        "\n",
        "# Calculate the time_index for y_test and y_pred starting from the appropriate offset\n",
        "time_index_test = np.arange(len(y_test_ocl)) + len(y_train_ocl)\n",
        "time_index_pred = np.arange(len(y_pred_ocl)) + len(y_train_ocl)\n",
        "\n",
        "# Plot the true values (y_train), the test values (y_test), and the predicted values (y_pred)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(time_index_train, y_train_orig_ocl, label='Training Data', color='blue')\n",
        "plt.plot(time_index_test, y_test_orig_ocl, label='Test Data', color='green')\n",
        "plt.plot(time_index_pred, y_pred_orig_ocl, label='Predictions', color='red', linestyle='dashed')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Value')\n",
        "plt.title('True Values vs. Predictions -- Open , Close , Low')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "I20OaxmK4hcM",
        "outputId": "cace005f-d048-431c-c13f-ec584988d471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time_index_train = np.arange(len(y_train_oclh))\n",
        "\n",
        "# Calculate the time_index for y_test and y_pred starting from the appropriate offset\n",
        "time_index_test = np.arange(len(y_test_oclh)) + len(y_train_oclh)\n",
        "time_index_pred = np.arange(len(y_pred_oclh)) + len(y_train_oclh)\n",
        "\n",
        "# Plot the true values (y_train), the test values (y_test), and the predicted values (y_pred)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(time_index_train, y_train_orig_oclh, label='Training Data', color='blue')\n",
        "plt.plot(time_index_test, y_test_orig_oclh, label='Test Data', color='green')\n",
        "plt.plot(time_index_pred, y_pred_orig_oclh, label='Predictions', color='red', linestyle='dashed')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Value')\n",
        "plt.title('True Values vs. Predictions -- Open , Close , Low , High')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "rmgTDJCB6Yo3",
        "outputId": "eb4e2047-4e4e-406c-dbe3-fe5dab68d186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WSU8YTy_9jSh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}